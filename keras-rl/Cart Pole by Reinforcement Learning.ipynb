{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipple Lecture #12 - Reinforcement Learning\n",
    "Now, you have seen quite some information relating to Reinforcement Learning. In this notebook, you will have the chance to program your own Deep Reinforcement Learning model. At least... tune its parameters. The programming of the game-environment, state-transitions, reward-calculations and training of the model has already been prepared for you. It is your job to focus on one task and one task only: keep your pole straight up!\n",
    "\n",
    "During the lecture, we have not been able to discuss all elements of a DRL-model, as there are many aspects which can be tuned to perfection (or far from it). Some additional explanation will be given in the notebook where deemed necessary, but don't be shy to ask more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing relevant modules\n",
    "Let's get started. First, import necessary modules (and suppress some unwanted warnings). The 'gym' package is imported to be able to create a Cart Pole environment for you to play with. Further on, 'keras' enables the usage of a neural network, while 'keras-rl' contains a whole bunch of interesting Reinforcement Learning functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting variables\n",
    "Then, set the relevant variables. Get the environment and extract the number of actions available in the Cartpole problem. The seed settings can be useful to compare your results over different runs. However, both a neural network as the RL framework itself still contain a high level of randomization, which may make comparison of distinct runs difficult. Keep this in mind when trying different parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "np.random.seed(123)\n",
    "env.seed(123)\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, build a neural network model. Initially, it is set to a simple feed-forward neural net, with a single hidden layer and 4 nodes. Try different settings by yourself, to find your optimal set-up! Unfortunately, until the day of today, there are no clear rules for choosing how many layers or nodes to use. Google may give you some idea, but most decisions still follow the famous method of trial-and-error.\n",
    "\n",
    "Try tuning the number of hidden layers, the number of nodes per hidden layer, and the type of activation functions in the hidden and output layers. Use the 'print(model.summary())' to get an overview of the complexity of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LennartvanHam\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dense(4))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, configure and compile your agent. The memory is set to Sequential Memory, storing the result of performed actions and obtained rewards. Try using different types of action-selection policies, memory sizes, learning rates, training steps, or w/e you can think of. Settings you can tune:\n",
    "\n",
    "* **policy**: the way in which actions are selected over time, following some balancing method. This RL-concept is very important, incorporating a trade-off between exploring unknown parts of the environment, and exploiting known information. (possible policies: EpsGreedyQPolicy, LinearAnnealedPolicy, SoftmaxPolicy, GreedyQPolicy, BoltzmannQPolicy, MaxBoltzmannQPolicy, BoltzmannGumbelQPolicy)\n",
    "* **memory limit**: the number of previous actions+rewards that are taken into account while learning, at a certain moment in time.\n",
    "* **window_length**: actually not sure... just keep it at 1 to avoid errors ;)\n",
    "* **target_model_update**: in theory denoted by $\\alpha$, the network's learning rate. It determines how quickly the algorithm wants to converge to found target values (such as Q-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = EpsGreedyQPolicy()\n",
    "memory = SequentialMemory(limit=10000, window_length=1)\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to learn something! There are four settings you can consider changing, however, only one which has an effect on your training performance:\n",
    "\n",
    "* **nb_steps**: the larger, the more time your bot gets for trying to find a good strategy, but the longer you'll have to wait.\n",
    "* **verbose**: printing running status. 0 for no logging, 1 for interval logging, 2 for episode logging\n",
    "* **visualize**: you can visualize the training for show, but this mostly slows down training\n",
    "* **log_interval**: if verbose=1, the number of steps that are considered to be an interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 2 (10 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 3 (20 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 4 (30 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 5 (40 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 6 (50 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 7 (60 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 8 (70 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 9 (80 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 10 (90 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 11 (100 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 12 (110 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 13 (120 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 14 (130 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 15 (140 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 16 (150 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 17 (160 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 18 (170 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 19 (180 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 184.000 [184.000, 184.000]\n",
      "\n",
      "Interval 20 (190 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 21 (200 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 22 (210 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 23 (220 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 24 (230 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 25 (240 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 26 (250 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 27 (260 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 28 (270 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 29 (280 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 30 (290 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 31 (300 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 32 (310 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 33 (320 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 34 (330 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 35 (340 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 36 (350 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 37 (360 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 38 (370 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 39 (380 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000]\n",
      "\n",
      "Interval 40 (390 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 41 (400 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 42 (410 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 43 (420 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 44 (430 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 45 (440 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 46 (450 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 47 (460 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 2ms/step - reward: 1.0000\n",
      "Interval 48 (470 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 95.000 [95.000, 95.000]\n",
      "\n",
      "Interval 49 (480 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 50 (490 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 51 (500 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 52 (510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 53 (520 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 54 (530 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 55 (540 steps performed)\n",
      "10/10 [==============================] - 0s 1000us/step - reward: 1.0000\n",
      "Interval 56 (550 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 57 (560 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 58 (570 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 97.000 [97.000, 97.000]\n",
      "\n",
      "Interval 59 (580 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 60 (590 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 61 (600 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 62 (610 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 63 (620 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 64 (630 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 65 (640 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 66 (650 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 67 (660 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 68 (670 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 69 (680 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 70 (690 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 71 (700 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 72 (710 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 73 (720 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 74 (730 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 75 (740 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 76 (750 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 77 (760 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 78 (770 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000]\n",
      "\n",
      "Interval 79 (780 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 80 (790 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 81 (800 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 82 (810 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 83 (820 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 84 (830 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 85 (840 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 86 (850 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 87 (860 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 88 (870 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 89 (880 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 90 (890 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 91 (900 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 92 (910 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 93 (920 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 94 (930 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 95 (940 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 96 (950 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 97 (960 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 185.000 [185.000, 185.000]\n",
      "\n",
      "Interval 98 (970 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 99 (980 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 100 (990 steps performed)\n",
      "10/10 [==============================] - 0s 1ms/step - reward: 1.0000\n",
      "Interval 101 (1000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 102 (1010 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 103 (1020 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 60.000 [60.000, 60.000] - loss: 0.331 - mean_absolute_error: 10.432 - mean_q: 21.019\n",
      "\n",
      "Interval 104 (1030 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 105 (1040 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 106 (1050 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 107 (1060 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 108 (1070 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 109 (1080 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 110 (1090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 111 (1100 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 112 (1110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 92.000 [92.000, 92.000] - loss: 0.719 - mean_absolute_error: 10.227 - mean_q: 20.650\n",
      "\n",
      "Interval 113 (1120 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 114 (1130 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 115 (1140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 116 (1150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 117 (1160 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 51.000 [51.000, 51.000] - loss: 0.337 - mean_absolute_error: 10.531 - mean_q: 21.206\n",
      "\n",
      "Interval 118 (1170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 119 (1180 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 120 (1190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 121 (1200 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 122 (1210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 123 (1220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 124 (1230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 125 (1240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 126 (1250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 127 (1260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 101.000 [101.000, 101.000] - loss: 0.291 - mean_absolute_error: 10.773 - mean_q: 21.703\n",
      "\n",
      "Interval 128 (1270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 129 (1280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 130 (1290 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 131 (1300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 132 (1310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 133 (1320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 134 (1330 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 66.000 [66.000, 66.000] - loss: 0.297 - mean_absolute_error: 10.685 - mean_q: 21.566\n",
      "\n",
      "Interval 135 (1340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 136 (1350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 137 (1360 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 138 (1370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 139 (1380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 57.000 [57.000, 57.000] - loss: 2.514 - mean_absolute_error: 10.960 - mean_q: 21.932\n",
      "\n",
      "Interval 140 (1390 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 141 (1400 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 142 (1410 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 143 (1420 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 144 (1430 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 145 (1440 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 58.000 [58.000, 58.000] - loss: 0.487 - mean_absolute_error: 10.642 - mean_q: 21.384\n",
      "\n",
      "Interval 146 (1450 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 147 (1460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 148 (1470 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 149 (1480 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 150 (1490 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 48.000 [48.000, 48.000] - loss: 0.483 - mean_absolute_error: 11.404 - mean_q: 22.781\n",
      "\n",
      "Interval 151 (1500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 152 (1510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 153 (1520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 154 (1530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 155 (1540 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 156 (1550 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 157 (1560 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 69.000 [69.000, 69.000] - loss: 1.960 - mean_absolute_error: 11.267 - mean_q: 22.466\n",
      "\n",
      "Interval 158 (1570 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 159 (1580 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 160 (1590 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 161 (1600 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 162 (1610 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 163 (1620 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 4ms/step - reward: 1.0000\n",
      "Interval 164 (1630 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 165 (1640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 166 (1650 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 167 (1660 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 168 (1670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 169 (1680 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 170 (1690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 171 (1700 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 172 (1710 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 173 (1720 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 174 (1730 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 175 (1740 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 176 (1750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 177 (1760 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 0.317 - mean_absolute_error: 10.971 - mean_q: 22.120\n",
      "\n",
      "Interval 178 (1770 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 179 (1780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 180 (1790 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 181 (1800 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 182 (1810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 54.000 [54.000, 54.000] - loss: 0.331 - mean_absolute_error: 11.973 - mean_q: 24.221\n",
      "\n",
      "Interval 183 (1820 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 184 (1830 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 185 (1840 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 186 (1850 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 187 (1860 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 188 (1870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 57.000 [57.000, 57.000] - loss: 1.973 - mean_absolute_error: 11.457 - mean_q: 23.013\n",
      "\n",
      "Interval 189 (1880 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 190 (1890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 191 (1900 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 192 (1910 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 193 (1920 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 194 (1930 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 195 (1940 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 196 (1950 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 197 (1960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 198 (1970 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 98.000 [98.000, 98.000] - loss: 1.620 - mean_absolute_error: 11.894 - mean_q: 23.841\n",
      "\n",
      "Interval 199 (1980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 200 (1990 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 201 (2000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 202 (2010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 203 (2020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 51.000 [51.000, 51.000] - loss: 0.342 - mean_absolute_error: 10.964 - mean_q: 22.160\n",
      "\n",
      "Interval 204 (2030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 205 (2040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 206 (2050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 207 (2060 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 208 (2070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 209 (2080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 210 (2090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 68.000 [68.000, 68.000] - loss: 0.526 - mean_absolute_error: 11.992 - mean_q: 24.078\n",
      "\n",
      "Interval 211 (2100 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 212 (2110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 213 (2120 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 214 (2130 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 215 (2140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 216 (2150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 63.000 [63.000, 63.000] - loss: 0.352 - mean_absolute_error: 12.123 - mean_q: 24.339\n",
      "\n",
      "Interval 217 (2160 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 218 (2170 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 219 (2180 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 220 (2190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 221 (2200 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 222 (2210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 223 (2220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 224 (2230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 225 (2240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 226 (2250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 100.000 [100.000, 100.000] - loss: 1.553 - mean_absolute_error: 12.138 - mean_q: 24.387\n",
      "\n",
      "Interval 227 (2260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 228 (2270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 229 (2280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 230 (2290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 231 (2300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 232 (2310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 233 (2320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 234 (2330 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 235 (2340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 236 (2350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 106.000 [106.000, 106.000] - loss: 6.340 - mean_absolute_error: 12.266 - mean_q: 24.202\n",
      "\n",
      "Interval 237 (2360 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 238 (2370 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 239 (2380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 240 (2390 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 241 (2400 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 242 (2410 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 243 (2420 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 64.000 [64.000, 64.000] - loss: 0.360 - mean_absolute_error: 12.674 - mean_q: 25.538\n",
      "\n",
      "Interval 244 (2430 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 245 (2440 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 246 (2450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 247 (2460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 248 (2470 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 249 (2480 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 250 (2490 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 72.000 [72.000, 72.000] - loss: 1.787 - mean_absolute_error: 12.395 - mean_q: 24.939\n",
      "\n",
      "Interval 251 (2500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 252 (2510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 253 (2520 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 254 (2530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 255 (2540 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 256 (2550 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 257 (2560 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 66.000 [66.000, 66.000] - loss: 0.387 - mean_absolute_error: 12.974 - mean_q: 26.192\n",
      "\n",
      "Interval 258 (2570 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 259 (2580 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 260 (2590 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 261 (2600 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 262 (2610 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 263 (2620 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 60.000 [60.000, 60.000] - loss: 0.550 - mean_absolute_error: 12.940 - mean_q: 26.007\n",
      "\n",
      "Interval 264 (2630 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 265 (2640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 266 (2650 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 267 (2660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 268 (2670 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 269 (2680 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 270 (2690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 271 (2700 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 81.000 [81.000, 81.000] - loss: 0.395 - mean_absolute_error: 13.424 - mean_q: 26.859\n",
      "\n",
      "Interval 272 (2710 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 273 (2720 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 274 (2730 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 275 (2740 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 276 (2750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 277 (2760 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 278 (2770 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 279 (2780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 280 (2790 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 89.000 [89.000, 89.000] - loss: 1.252 - mean_absolute_error: 13.573 - mean_q: 27.272\n",
      "\n",
      "Interval 281 (2800 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 282 (2810 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 283 (2820 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 284 (2830 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 285 (2840 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 286 (2850 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 287 (2860 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 75.000 [75.000, 75.000] - loss: 0.395 - mean_absolute_error: 13.288 - mean_q: 26.713\n",
      "\n",
      "Interval 288 (2870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 289 (2880 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 290 (2890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 291 (2900 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 292 (2910 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 293 (2920 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 294 (2930 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 295 (2940 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 296 (2950 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 297 (2960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 298 (2970 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 299 (2980 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 116.000 [116.000, 116.000] - loss: 1.671 - mean_absolute_error: 13.548 - mean_q: 27.159\n",
      "\n",
      "Interval 300 (2990 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 301 (3000 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 302 (3010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 303 (3020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 304 (3030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 305 (3040 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 306 (3050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 307 (3060 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 308 (3070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 309 (3080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 310 (3090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 109.000 [109.000, 109.000] - loss: 1.824 - mean_absolute_error: 14.370 - mean_q: 28.689\n",
      "\n",
      "Interval 311 (3100 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 312 (3110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 313 (3120 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 314 (3130 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 315 (3140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 316 (3150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 317 (3160 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 4ms/step - reward: 1.0000\n",
      "Interval 318 (3170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 87.000 [87.000, 87.000] - loss: 1.655 - mean_absolute_error: 13.872 - mean_q: 27.867\n",
      "\n",
      "Interval 319 (3180 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 320 (3190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 321 (3200 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 322 (3210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 323 (3220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 324 (3230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 325 (3240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 326 (3250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 79.000 [79.000, 79.000] - loss: 4.930 - mean_absolute_error: 14.635 - mean_q: 29.074\n",
      "\n",
      "Interval 327 (3260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 328 (3270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 329 (3280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 330 (3290 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 331 (3300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 332 (3310 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 333 (3320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 334 (3330 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 335 (3340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 336 (3350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 96.000 [96.000, 96.000] - loss: 0.773 - mean_absolute_error: 14.205 - mean_q: 28.609\n",
      "\n",
      "Interval 337 (3360 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 338 (3370 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 339 (3380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 340 (3390 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 341 (3400 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 342 (3410 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 343 (3420 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 344 (3430 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 345 (3440 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 346 (3450 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 98.000 [98.000, 98.000] - loss: 1.637 - mean_absolute_error: 14.480 - mean_q: 29.125\n",
      "\n",
      "Interval 347 (3460 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 348 (3470 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 349 (3480 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 350 (3490 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 351 (3500 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 352 (3510 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 353 (3520 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 354 (3530 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 87.000 [87.000, 87.000] - loss: 1.720 - mean_absolute_error: 14.417 - mean_q: 28.944\n",
      "\n",
      "Interval 355 (3540 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 356 (3550 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 357 (3560 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 358 (3570 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 359 (3580 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 360 (3590 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 361 (3600 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 362 (3610 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 363 (3620 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 364 (3630 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 99.000 [99.000, 99.000] - loss: 4.915 - mean_absolute_error: 15.120 - mean_q: 30.194\n",
      "\n",
      "Interval 365 (3640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 366 (3650 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 367 (3660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 368 (3670 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 369 (3680 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 370 (3690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 371 (3700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 372 (3710 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 373 (3720 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 374 (3730 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 375 (3740 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 112.000 [112.000, 112.000] - loss: 0.619 - mean_absolute_error: 14.951 - mean_q: 30.196\n",
      "\n",
      "Interval 376 (3750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 377 (3760 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 378 (3770 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 379 (3780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 380 (3790 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 381 (3800 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 382 (3810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 383 (3820 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 384 (3830 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 385 (3840 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 386 (3850 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 103.000 [103.000, 103.000] - loss: 0.984 - mean_absolute_error: 15.492 - mean_q: 31.147\n",
      "\n",
      "Interval 387 (3860 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 388 (3870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 389 (3880 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 390 (3890 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 391 (3900 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 392 (3910 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 393 (3920 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 394 (3930 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 395 (3940 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 396 (3950 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 397 (3960 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 112.000 [112.000, 112.000] - loss: 2.163 - mean_absolute_error: 15.721 - mean_q: 31.543\n",
      "\n",
      "Interval 398 (3970 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 399 (3980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 400 (3990 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 401 (4000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 402 (4010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 403 (4020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 404 (4030 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 405 (4040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 406 (4050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 407 (4060 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 408 (4070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 409 (4080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 121.000 [121.000, 121.000] - loss: 2.761 - mean_absolute_error: 15.932 - mean_q: 31.946\n",
      "\n",
      "Interval 410 (4090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 411 (4100 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 412 (4110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 413 (4120 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 414 (4130 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 415 (4140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 416 (4150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 417 (4160 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 418 (4170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 419 (4180 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 420 (4190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 109.000 [109.000, 109.000] - loss: 2.852 - mean_absolute_error: 15.617 - mean_q: 31.371\n",
      "\n",
      "Interval 421 (4200 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 422 (4210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 423 (4220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 424 (4230 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 425 (4240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 426 (4250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 427 (4260 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 428 (4270 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 429 (4280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 430 (4290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 431 (4300 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 432 (4310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 124.000 [124.000, 124.000] - loss: 1.779 - mean_absolute_error: 15.738 - mean_q: 31.706\n",
      "\n",
      "Interval 433 (4320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 434 (4330 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 435 (4340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 436 (4350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 437 (4360 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 438 (4370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 439 (4380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 440 (4390 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 441 (4400 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 442 (4410 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 443 (4420 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 444 (4430 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 116.000 [116.000, 116.000] - loss: 2.050 - mean_absolute_error: 15.856 - mean_q: 31.909\n",
      "\n",
      "Interval 445 (4440 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 4ms/step - reward: 1.0000\n",
      "Interval 446 (4450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 447 (4460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 448 (4470 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 449 (4480 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 450 (4490 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 451 (4500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 452 (4510 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 453 (4520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 454 (4530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 455 (4540 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 456 (4550 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 120.000 [120.000, 120.000] - loss: 1.260 - mean_absolute_error: 16.205 - mean_q: 32.532\n",
      "\n",
      "Interval 457 (4560 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 458 (4570 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 459 (4580 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 460 (4590 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 461 (4600 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 462 (4610 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 4ms/step - reward: 1.0000\n",
      "Interval 463 (4620 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 464 (4630 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 465 (4640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 466 (4650 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 467 (4660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 115.000 [115.000, 115.000] - loss: 0.682 - mean_absolute_error: 16.565 - mean_q: 33.349\n",
      "\n",
      "Interval 468 (4670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 469 (4680 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 470 (4690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 471 (4700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 472 (4710 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 473 (4720 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 4ms/step - reward: 1.0000\n",
      "Interval 474 (4730 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 475 (4740 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 476 (4750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 477 (4760 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 478 (4770 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 479 (4780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 118.000 [118.000, 118.000] - loss: 0.315 - mean_absolute_error: 16.576 - mean_q: 33.545\n",
      "\n",
      "Interval 480 (4790 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 481 (4800 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 482 (4810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 483 (4820 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 484 (4830 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 485 (4840 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 486 (4850 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 487 (4860 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 488 (4870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 489 (4880 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 490 (4890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 106.000 [106.000, 106.000] - loss: 0.817 - mean_absolute_error: 16.482 - mean_q: 33.245\n",
      "\n",
      "Interval 491 (4900 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 492 (4910 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 493 (4920 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 494 (4930 steps performed)\n",
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 495 (4940 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 496 (4950 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 497 (4960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 498 (4970 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 499 (4980 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 500 (4990 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 501 (5000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 502 (5010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 122.000 [122.000, 122.000] - loss: 0.681 - mean_absolute_error: 17.163 - mean_q: 34.735\n",
      "\n",
      "Interval 503 (5020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 504 (5030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 505 (5040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 506 (5050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 507 (5060 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 508 (5070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 509 (5080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 510 (5090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 511 (5100 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 512 (5110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 513 (5120 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 107.000 [107.000, 107.000] - loss: 3.743 - mean_absolute_error: 17.615 - mean_q: 35.566\n",
      "\n",
      "Interval 514 (5130 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 515 (5140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 516 (5150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 517 (5160 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 518 (5170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 519 (5180 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 520 (5190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 521 (5200 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 522 (5210 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 523 (5220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 524 (5230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 114.000 [114.000, 114.000] - loss: 1.083 - mean_absolute_error: 18.158 - mean_q: 36.661\n",
      "\n",
      "Interval 525 (5240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 526 (5250 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 527 (5260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 528 (5270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 529 (5280 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 530 (5290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 531 (5300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 532 (5310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 533 (5320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 534 (5330 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 535 (5340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 112.000 [112.000, 112.000] - loss: 5.931 - mean_absolute_error: 18.063 - mean_q: 36.087\n",
      "\n",
      "Interval 536 (5350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 537 (5360 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 0.496 - mean_absolute_error: 17.604 - mean_q: 35.556\n",
      "\n",
      "Interval 538 (5370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 539 (5380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 2.340 - mean_absolute_error: 17.537 - mean_q: 35.222\n",
      "\n",
      "Interval 540 (5390 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 541 (5400 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 542 (5410 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 543 (5420 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 544 (5430 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 545 (5440 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 546 (5450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 547 (5460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 548 (5470 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 549 (5480 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 550 (5490 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 104.000 [104.000, 104.000] - loss: 4.143 - mean_absolute_error: 17.474 - mean_q: 34.995\n",
      "\n",
      "Interval 551 (5500 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 552 (5510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 553 (5520 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 554 (5530 steps performed)\n",
      "10/10 [==============================] - 0s 9ms/step - reward: 1.0000\n",
      "Interval 555 (5540 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 556 (5550 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 557 (5560 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 558 (5570 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 559 (5580 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 560 (5590 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - reward: 1.0000\n",
      "Interval 561 (5600 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 111.000 [111.000, 111.000] - loss: 1.991 - mean_absolute_error: 18.202 - mean_q: 36.534\n",
      "\n",
      "Interval 562 (5610 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 563 (5620 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 564 (5630 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 565 (5640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 566 (5650 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 567 (5660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 568 (5670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 569 (5680 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 570 (5690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 571 (5700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 104.000 [104.000, 104.000] - loss: 0.640 - mean_absolute_error: 19.070 - mean_q: 38.258\n",
      "\n",
      "Interval 572 (5710 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 573 (5720 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 574 (5730 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 25.000 [25.000, 25.000] - loss: 1.519 - mean_absolute_error: 18.050 - mean_q: 36.309\n",
      "\n",
      "Interval 575 (5740 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 576 (5750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 577 (5760 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 578 (5770 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 579 (5780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 580 (5790 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 581 (5800 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 582 (5810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 583 (5820 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 584 (5830 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 107.000 [107.000, 107.000] - loss: 0.785 - mean_absolute_error: 18.492 - mean_q: 37.203\n",
      "\n",
      "Interval 585 (5840 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 586 (5850 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 3.754 - mean_absolute_error: 18.219 - mean_q: 36.499\n",
      "\n",
      "Interval 587 (5860 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 588 (5870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 589 (5880 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 590 (5890 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 591 (5900 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 592 (5910 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 593 (5920 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 594 (5930 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 595 (5940 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 596 (5950 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 597 (5960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 598 (5970 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 116.000 [116.000, 116.000] - loss: 13.740 - mean_absolute_error: 18.737 - mean_q: 36.918\n",
      "\n",
      "Interval 599 (5980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 600 (5990 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 601 (6000 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 602 (6010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 603 (6020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 604 (6030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 605 (6040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 606 (6050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 607 (6060 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 608 (6070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 104.000 [104.000, 104.000] - loss: 5.091 - mean_absolute_error: 19.531 - mean_q: 39.055\n",
      "\n",
      "Interval 609 (6080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 610 (6090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 611 (6100 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 612 (6110 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 613 (6120 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 614 (6130 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 615 (6140 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 616 (6150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 617 (6160 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 618 (6170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 619 (6180 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 107.000 [107.000, 107.000] - loss: 11.742 - mean_absolute_error: 19.080 - mean_q: 37.902\n",
      "\n",
      "Interval 620 (6190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 621 (6200 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 622 (6210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 623 (6220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 624 (6230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 625 (6240 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 626 (6250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 627 (6260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 628 (6270 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 629 (6280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 104.000 [104.000, 104.000] - loss: 1.048 - mean_absolute_error: 19.215 - mean_q: 38.762\n",
      "\n",
      "Interval 630 (6290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 631 (6300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 2.036 - mean_absolute_error: 19.517 - mean_q: 39.140\n",
      "\n",
      "Interval 632 (6310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 633 (6320 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 634 (6330 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 635 (6340 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 636 (6350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 637 (6360 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 638 (6370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 639 (6380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 640 (6390 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 641 (6400 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 97.000 [97.000, 97.000] - loss: 7.107 - mean_absolute_error: 20.269 - mean_q: 40.477\n",
      "\n",
      "Interval 642 (6410 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 0.984 - mean_absolute_error: 20.053 - mean_q: 40.333\n",
      "\n",
      "Interval 643 (6420 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 644 (6430 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 645 (6440 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 646 (6450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 647 (6460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 648 (6470 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 649 (6480 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 650 (6490 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 651 (6500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 652 (6510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 653 (6520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 103.000 [103.000, 103.000] - loss: 0.911 - mean_absolute_error: 19.798 - mean_q: 39.846\n",
      "\n",
      "Interval 654 (6530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 9.483 - mean_absolute_error: 20.005 - mean_q: 40.058\n",
      "\n",
      "Interval 655 (6540 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 656 (6550 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 0.626 - mean_absolute_error: 20.527 - mean_q: 41.312\n",
      "\n",
      "Interval 657 (6560 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 658 (6570 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 21.000 [21.000, 21.000] - loss: 3.778 - mean_absolute_error: 20.445 - mean_q: 40.986\n",
      "\n",
      "Interval 659 (6580 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 660 (6590 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 9.750 - mean_absolute_error: 20.278 - mean_q: 40.489\n",
      "\n",
      "Interval 661 (6600 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 1.172 - mean_absolute_error: 20.283 - mean_q: 40.742\n",
      "\n",
      "Interval 662 (6610 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 663 (6620 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 7.817 - mean_absolute_error: 20.469 - mean_q: 40.910\n",
      "\n",
      "Interval 664 (6630 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 665 (6640 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 15.000 [15.000, 15.000] - loss: 9.648 - mean_absolute_error: 20.582 - mean_q: 40.835\n",
      "\n",
      "Interval 666 (6650 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 667 (6660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 668 (6670 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 669 (6680 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 670 (6690 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 671 (6700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 672 (6710 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 673 (6720 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 674 (6730 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 675 (6740 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 103.000 [103.000, 103.000] - loss: 1.206 - mean_absolute_error: 19.520 - mean_q: 39.323\n",
      "\n",
      "Interval 676 (6750 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 677 (6760 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 6.878 - mean_absolute_error: 20.393 - mean_q: 40.684\n",
      "\n",
      "Interval 678 (6770 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 679 (6780 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 6.521 - mean_absolute_error: 19.766 - mean_q: 39.543\n",
      "\n",
      "Interval 680 (6790 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 2.809 - mean_absolute_error: 20.406 - mean_q: 40.731\n",
      "\n",
      "Interval 681 (6800 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 682 (6810 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 3.582 - mean_absolute_error: 21.165 - mean_q: 42.361\n",
      "\n",
      "Interval 683 (6820 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 684 (6830 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 685 (6840 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 686 (6850 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 687 (6860 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 688 (6870 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 689 (6880 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 690 (6890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 691 (6900 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 692 (6910 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 102.000 [102.000, 102.000] - loss: 7.623 - mean_absolute_error: 20.294 - mean_q: 40.424\n",
      "\n",
      "Interval 693 (6920 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 694 (6930 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 26.839 - mean_absolute_error: 21.008 - mean_q: 41.010\n",
      "\n",
      "Interval 695 (6940 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 696 (6950 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 697 (6960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 24.000 [24.000, 24.000] - loss: 3.063 - mean_absolute_error: 21.386 - mean_q: 42.948\n",
      "\n",
      "Interval 698 (6970 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 2.824 - mean_absolute_error: 20.188 - mean_q: 40.406\n",
      "\n",
      "Interval 699 (6980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 700 (6990 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 4.815 - mean_absolute_error: 20.439 - mean_q: 40.891\n",
      "\n",
      "Interval 701 (7000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 702 (7010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 19.000 [19.000, 19.000] - loss: 5.031 - mean_absolute_error: 20.860 - mean_q: 41.672\n",
      "\n",
      "Interval 703 (7020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 704 (7030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 6.345 - mean_absolute_error: 20.362 - mean_q: 40.762\n",
      "\n",
      "Interval 705 (7040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 706 (7050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 707 (7060 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 708 (7070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 709 (7080 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 710 (7090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 711 (7100 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 712 (7110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 713 (7120 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 714 (7130 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 100.000 [100.000, 100.000] - loss: 7.645 - mean_absolute_error: 21.097 - mean_q: 41.985\n",
      "\n",
      "Interval 715 (7140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 716 (7150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 1.345 - mean_absolute_error: 21.030 - mean_q: 42.306\n",
      "\n",
      "Interval 717 (7160 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 718 (7170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 719 (7180 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 720 (7190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 721 (7200 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 722 (7210 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 723 (7220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 724 (7230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 725 (7240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 726 (7250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 104.000 [104.000, 104.000] - loss: 4.563 - mean_absolute_error: 22.095 - mean_q: 44.075\n",
      "\n",
      "Interval 727 (7260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 728 (7270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 729 (7280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 730 (7290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 731 (7300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 732 (7310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 733 (7320 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 734 (7330 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 735 (7340 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 736 (7350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 105.000 [105.000, 105.000] - loss: 13.859 - mean_absolute_error: 21.180 - mean_q: 41.993\n",
      "\n",
      "Interval 737 (7360 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 738 (7370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 8.767 - mean_absolute_error: 20.738 - mean_q: 41.320\n",
      "\n",
      "Interval 739 (7380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 740 (7390 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 18.000 [18.000, 18.000] - loss: 14.381 - mean_absolute_error: 21.821 - mean_q: 43.196\n",
      "\n",
      "Interval 741 (7400 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 742 (7410 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 743 (7420 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 744 (7430 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 745 (7440 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 746 (7450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 747 (7460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 748 (7470 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 749 (7480 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 750 (7490 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 751 (7500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 108.000 [108.000, 108.000] - loss: 10.385 - mean_absolute_error: 21.041 - mean_q: 41.793\n",
      "\n",
      "Interval 752 (7510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 753 (7520 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 754 (7530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 755 (7540 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 756 (7550 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 757 (7560 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 758 (7570 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 759 (7580 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 760 (7590 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 761 (7600 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 762 (7610 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 111.000 [111.000, 111.000] - loss: 7.263 - mean_absolute_error: 21.537 - mean_q: 42.824\n",
      "\n",
      "Interval 763 (7620 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 764 (7630 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 23.000 [23.000, 23.000] - loss: 10.456 - mean_absolute_error: 21.426 - mean_q: 42.480\n",
      "\n",
      "Interval 765 (7640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 766 (7650 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 767 (7660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 768 (7670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 769 (7680 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 770 (7690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 771 (7700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 772 (7710 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 773 (7720 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 774 (7730 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 775 (7740 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 108.000 [108.000, 108.000] - loss: 5.165 - mean_absolute_error: 22.047 - mean_q: 44.149\n",
      "\n",
      "Interval 776 (7750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 777 (7760 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 778 (7770 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 779 (7780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 780 (7790 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 781 (7800 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 782 (7810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 783 (7820 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 784 (7830 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 785 (7840 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 786 (7850 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 107.000 [107.000, 107.000] - loss: 7.266 - mean_absolute_error: 21.229 - mean_q: 42.124\n",
      "\n",
      "Interval 787 (7860 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 16.000 [16.000, 16.000] - loss: 1.719 - mean_absolute_error: 22.068 - mean_q: 44.085\n",
      "\n",
      "Interval 788 (7870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 789 (7880 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 790 (7890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 791 (7900 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 792 (7910 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 793 (7920 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 794 (7930 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 795 (7940 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 796 (7950 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 797 (7960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 798 (7970 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 799 (7980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 113.000 [113.000, 113.000] - loss: 12.466 - mean_absolute_error: 21.838 - mean_q: 43.138\n",
      "\n",
      "Interval 800 (7990 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 801 (8000 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 4ms/step - reward: 1.0000\n",
      "Interval 802 (8010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 803 (8020 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 804 (8030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 805 (8040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 806 (8050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 807 (8060 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 808 (8070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 809 (8080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 103.000 [103.000, 103.000] - loss: 5.130 - mean_absolute_error: 20.937 - mean_q: 41.739\n",
      "\n",
      "Interval 810 (8090 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 811 (8100 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 20.000 [20.000, 20.000] - loss: 6.842 - mean_absolute_error: 20.856 - mean_q: 41.496\n",
      "\n",
      "Interval 812 (8110 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 813 (8120 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 814 (8130 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 815 (8140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 816 (8150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 817 (8160 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 818 (8170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 819 (8180 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 820 (8190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 821 (8200 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 822 (8210 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 114.000 [114.000, 114.000] - loss: 9.700 - mean_absolute_error: 22.085 - mean_q: 43.736\n",
      "\n",
      "Interval 823 (8220 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 824 (8230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 825 (8240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 826 (8250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 827 (8260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 828 (8270 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 829 (8280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 830 (8290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 831 (8300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 832 (8310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 833 (8320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 834 (8330 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 114.000 [114.000, 114.000] - loss: 0.524 - mean_absolute_error: 21.940 - mean_q: 44.005\n",
      "\n",
      "Interval 835 (8340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 836 (8350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 837 (8360 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 838 (8370 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 839 (8380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 840 (8390 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 841 (8400 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 842 (8410 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 843 (8420 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 844 (8430 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 845 (8440 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 110.000 [110.000, 110.000] - loss: 12.405 - mean_absolute_error: 21.224 - mean_q: 42.020\n",
      "\n",
      "Interval 846 (8450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 847 (8460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 848 (8470 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 849 (8480 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 850 (8490 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 851 (8500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 852 (8510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 853 (8520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 854 (8530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 855 (8540 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 856 (8550 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 110.000 [110.000, 110.000] - loss: 3.794 - mean_absolute_error: 22.167 - mean_q: 44.124\n",
      "\n",
      "Interval 857 (8560 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 858 (8570 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 859 (8580 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 860 (8590 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 861 (8600 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 862 (8610 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 863 (8620 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 864 (8630 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 865 (8640 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 866 (8650 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 867 (8660 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 111.000 [111.000, 111.000] - loss: 1.572 - mean_absolute_error: 20.581 - mean_q: 40.948\n",
      "\n",
      "Interval 868 (8670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 869 (8680 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 870 (8690 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 871 (8700 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 872 (8710 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 873 (8720 steps performed)\n",
      "10/10 [==============================] - 0s 8ms/step - reward: 1.0000\n",
      "Interval 874 (8730 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 875 (8740 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 876 (8750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 877 (8760 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 878 (8770 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 879 (8780 steps performed)\n",
      "10/10 [==============================] - 0s 8ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 117.000 [117.000, 117.000] - loss: 5.892 - mean_absolute_error: 21.170 - mean_q: 41.885\n",
      "\n",
      "Interval 880 (8790 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 881 (8800 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 882 (8810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 883 (8820 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 884 (8830 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 885 (8840 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 886 (8850 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 887 (8860 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 888 (8870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 889 (8880 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 890 (8890 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 891 (8900 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 122.000 [122.000, 122.000] - loss: 6.019 - mean_absolute_error: 21.665 - mean_q: 43.219\n",
      "\n",
      "Interval 892 (8910 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 893 (8920 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 894 (8930 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 895 (8940 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 896 (8950 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 897 (8960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 898 (8970 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 899 (8980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 900 (8990 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 3ms/step - reward: 1.0000\n",
      "Interval 901 (9000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 902 (9010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 903 (9020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 122.000 [122.000, 122.000] - loss: 10.963 - mean_absolute_error: 22.241 - mean_q: 44.030\n",
      "\n",
      "Interval 904 (9030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 905 (9040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 906 (9050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 907 (9060 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 908 (9070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 909 (9080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 910 (9090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 911 (9100 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 912 (9110 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 913 (9120 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 914 (9130 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 915 (9140 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 122.000 [122.000, 122.000] - loss: 4.696 - mean_absolute_error: 21.250 - mean_q: 42.321\n",
      "\n",
      "Interval 916 (9150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 917 (9160 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 918 (9170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 919 (9180 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 920 (9190 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 921 (9200 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 922 (9210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 923 (9220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 924 (9230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 925 (9240 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 926 (9250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 927 (9260 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 928 (9270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 129.000 [129.000, 129.000] - loss: 9.001 - mean_absolute_error: 21.287 - mean_q: 42.143\n",
      "\n",
      "Interval 929 (9280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 930 (9290 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 931 (9300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 932 (9310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 933 (9320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 934 (9330 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 935 (9340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 936 (9350 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 937 (9360 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 938 (9370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 939 (9380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 940 (9390 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 120.000 [120.000, 120.000] - loss: 16.634 - mean_absolute_error: 21.591 - mean_q: 42.673\n",
      "\n",
      "Interval 941 (9400 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 942 (9410 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 943 (9420 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 944 (9430 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 945 (9440 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 946 (9450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 947 (9460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 948 (9470 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 949 (9480 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 950 (9490 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 951 (9500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 952 (9510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 953 (9520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 954 (9530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 140.000 [140.000, 140.000] - loss: 6.253 - mean_absolute_error: 21.816 - mean_q: 43.401\n",
      "\n",
      "Interval 955 (9540 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 4ms/step - reward: 1.0000\n",
      "Interval 956 (9550 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 957 (9560 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 958 (9570 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 959 (9580 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 960 (9590 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 961 (9600 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 962 (9610 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 963 (9620 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 964 (9630 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 965 (9640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 966 (9650 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 967 (9660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 133.000 [133.000, 133.000] - loss: 19.191 - mean_absolute_error: 21.940 - mean_q: 43.130\n",
      "\n",
      "Interval 968 (9670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 969 (9680 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 970 (9690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 971 (9700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 972 (9710 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 973 (9720 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 974 (9730 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 975 (9740 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 976 (9750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 977 (9760 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 978 (9770 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 979 (9780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 980 (9790 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 129.000 [129.000, 129.000] - loss: 6.711 - mean_absolute_error: 21.677 - mean_q: 43.143\n",
      "\n",
      "Interval 981 (9800 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 982 (9810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 983 (9820 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 984 (9830 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 985 (9840 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 986 (9850 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 987 (9860 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 988 (9870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 989 (9880 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 990 (9890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 991 (9900 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 992 (9910 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 993 (9920 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 994 (9930 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 995 (9940 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 147.000 [147.000, 147.000] - loss: 16.144 - mean_absolute_error: 22.529 - mean_q: 44.240\n",
      "\n",
      "Interval 996 (9950 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 997 (9960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 998 (9970 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 999 (9980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1000 (9990 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1001 (10000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1002 (10010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1003 (10020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1004 (10030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1005 (10040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1006 (10050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1007 (10060 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1008 (10070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1009 (10080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1010 (10090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 155.000 [155.000, 155.000] - loss: 7.041 - mean_absolute_error: 21.493 - mean_q: 42.736\n",
      "\n",
      "Interval 1011 (10100 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1012 (10110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1013 (10120 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1014 (10130 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1015 (10140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1016 (10150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1017 (10160 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1018 (10170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1019 (10180 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1020 (10190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1021 (10200 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1022 (10210 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1023 (10220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1024 (10230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1025 (10240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1026 (10250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1027 (10260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1028 (10270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1029 (10280 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1030 (10290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 1.205 - mean_absolute_error: 20.492 - mean_q: 41.006\n",
      "\n",
      "Interval 1031 (10300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1032 (10310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1033 (10320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1034 (10330 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1035 (10340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1036 (10350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1037 (10360 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1038 (10370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1039 (10380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1040 (10390 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1041 (10400 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1042 (10410 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1043 (10420 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1044 (10430 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1045 (10440 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1046 (10450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1047 (10460 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1048 (10470 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1049 (10480 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1050 (10490 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 1.722 - mean_absolute_error: 20.348 - mean_q: 40.665\n",
      "\n",
      "Interval 1051 (10500 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1052 (10510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1053 (10520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1054 (10530 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1055 (10540 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1056 (10550 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1057 (10560 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1058 (10570 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1059 (10580 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1060 (10590 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1061 (10600 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1062 (10610 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1063 (10620 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1064 (10630 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1065 (10640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1066 (10650 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1067 (10660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1068 (10670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1069 (10680 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1070 (10690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 3.079 - mean_absolute_error: 21.802 - mean_q: 43.539\n",
      "\n",
      "Interval 1071 (10700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1072 (10710 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1073 (10720 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1074 (10730 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1075 (10740 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1076 (10750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1077 (10760 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1078 (10770 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1079 (10780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1080 (10790 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1081 (10800 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1082 (10810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1083 (10820 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1084 (10830 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1085 (10840 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1086 (10850 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1087 (10860 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1088 (10870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1089 (10880 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1090 (10890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 12.735 - mean_absolute_error: 21.263 - mean_q: 42.303\n",
      "\n",
      "Interval 1091 (10900 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1092 (10910 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1093 (10920 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1094 (10930 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1095 (10940 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1096 (10950 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1097 (10960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1098 (10970 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1099 (10980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1100 (10990 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1101 (11000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1102 (11010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1103 (11020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1104 (11030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1105 (11040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1106 (11050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1107 (11060 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1108 (11070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1109 (11080 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1110 (11090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 195.000 [195.000, 195.000] - loss: 1.180 - mean_absolute_error: 22.900 - mean_q: 46.056\n",
      "\n",
      "Interval 1111 (11100 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1112 (11110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1113 (11120 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1114 (11130 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1115 (11140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1116 (11150 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1117 (11160 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1118 (11170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1119 (11180 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1120 (11190 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1121 (11200 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1122 (11210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1123 (11220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1124 (11230 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1125 (11240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1126 (11250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1127 (11260 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1128 (11270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 184.000 [184.000, 184.000] - loss: 4.572 - mean_absolute_error: 23.370 - mean_q: 46.819\n",
      "\n",
      "Interval 1129 (11280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1130 (11290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1131 (11300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1132 (11310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1133 (11320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1134 (11330 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1135 (11340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1136 (11350 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1137 (11360 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1138 (11370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1139 (11380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1140 (11390 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1141 (11400 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1142 (11410 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1143 (11420 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1144 (11430 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1145 (11440 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1146 (11450 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1147 (11460 steps performed)\n",
      "10/10 [==============================] - 0s 8ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 185.000 [185.000, 185.000] - loss: 2.782 - mean_absolute_error: 23.267 - mean_q: 46.728\n",
      "\n",
      "Interval 1148 (11470 steps performed)\n",
      "10/10 [==============================] - 0s 8ms/step - reward: 1.0000\n",
      "Interval 1149 (11480 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1150 (11490 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1151 (11500 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1152 (11510 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1153 (11520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1154 (11530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1155 (11540 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1156 (11550 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1157 (11560 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1158 (11570 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1159 (11580 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1160 (11590 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1161 (11600 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1162 (11610 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1163 (11620 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1164 (11630 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 176.000 [176.000, 176.000] - loss: 7.125 - mean_absolute_error: 23.765 - mean_q: 47.705\n",
      "\n",
      "Interval 1165 (11640 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1166 (11650 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1167 (11660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1168 (11670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1169 (11680 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1170 (11690 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1171 (11700 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1172 (11710 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1173 (11720 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1174 (11730 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1175 (11740 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1176 (11750 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1177 (11760 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1178 (11770 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1179 (11780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1180 (11790 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1181 (11800 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 163.000 [163.000, 163.000] - loss: 0.232 - mean_absolute_error: 25.176 - mean_q: 50.711\n",
      "\n",
      "Interval 1182 (11810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1183 (11820 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1184 (11830 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1185 (11840 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1186 (11850 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1187 (11860 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1188 (11870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1189 (11880 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1190 (11890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1191 (11900 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1192 (11910 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1193 (11920 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1194 (11930 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1195 (11940 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1196 (11950 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1197 (11960 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1198 (11970 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1199 (11980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1200 (11990 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 196.000 [196.000, 196.000] - loss: 14.628 - mean_absolute_error: 24.750 - mean_q: 49.340\n",
      "\n",
      "Interval 1201 (12000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1202 (12010 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1203 (12020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1204 (12030 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1205 (12040 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1206 (12050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1207 (12060 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1208 (12070 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1209 (12080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1210 (12090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1211 (12100 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1212 (12110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1213 (12120 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1214 (12130 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1215 (12140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1216 (12150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1217 (12160 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1218 (12170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1219 (12180 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1220 (12190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 8.189 - mean_absolute_error: 24.886 - mean_q: 49.506\n",
      "\n",
      "Interval 1221 (12200 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1222 (12210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1223 (12220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1224 (12230 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1225 (12240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1226 (12250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1227 (12260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1228 (12270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1229 (12280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1230 (12290 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1231 (12300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1232 (12310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1233 (12320 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1234 (12330 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1235 (12340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1236 (12350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1237 (12360 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1238 (12370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1239 (12380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1240 (12390 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 0.886 - mean_absolute_error: 25.452 - mean_q: 51.056\n",
      "\n",
      "Interval 1241 (12400 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1242 (12410 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1243 (12420 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1244 (12430 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1245 (12440 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1246 (12450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1247 (12460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1248 (12470 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1249 (12480 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1250 (12490 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1251 (12500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1252 (12510 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1253 (12520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1254 (12530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1255 (12540 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1256 (12550 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1257 (12560 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1258 (12570 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1259 (12580 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 183.000 [183.000, 183.000] - loss: 1.161 - mean_absolute_error: 25.504 - mean_q: 51.176\n",
      "\n",
      "Interval 1260 (12590 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1261 (12600 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1262 (12610 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1263 (12620 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1264 (12630 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1265 (12640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1266 (12650 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1267 (12660 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1268 (12670 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1269 (12680 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1270 (12690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1271 (12700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1272 (12710 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1273 (12720 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1274 (12730 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1275 (12740 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1276 (12750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1277 (12760 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1278 (12770 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1279 (12780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 2.094 - mean_absolute_error: 26.817 - mean_q: 53.759\n",
      "\n",
      "Interval 1280 (12790 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1281 (12800 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1282 (12810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1283 (12820 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1284 (12830 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1285 (12840 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1286 (12850 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1287 (12860 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1288 (12870 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1289 (12880 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1290 (12890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1291 (12900 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1292 (12910 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1293 (12920 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1294 (12930 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1295 (12940 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1296 (12950 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1297 (12960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1298 (12970 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1299 (12980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 14.212 - mean_absolute_error: 27.223 - mean_q: 54.012\n",
      "\n",
      "Interval 1300 (12990 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1301 (13000 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1302 (13010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1303 (13020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1304 (13030 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1305 (13040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1306 (13050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1307 (13060 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1308 (13070 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1309 (13080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1310 (13090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1311 (13100 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1312 (13110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1313 (13120 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1314 (13130 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1315 (13140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1316 (13150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1317 (13160 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1318 (13170 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1319 (13180 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 12.193 - mean_absolute_error: 26.612 - mean_q: 52.825\n",
      "\n",
      "Interval 1320 (13190 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1321 (13200 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1322 (13210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1323 (13220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1324 (13230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1325 (13240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1326 (13250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1327 (13260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1328 (13270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1329 (13280 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1330 (13290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1331 (13300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1332 (13310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1333 (13320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1334 (13330 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1335 (13340 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1336 (13350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1337 (13360 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1338 (13370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1339 (13380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 21.889 - mean_absolute_error: 27.712 - mean_q: 54.515\n",
      "\n",
      "Interval 1340 (13390 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1341 (13400 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1342 (13410 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1343 (13420 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1344 (13430 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1345 (13440 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1346 (13450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1347 (13460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1348 (13470 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1349 (13480 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1350 (13490 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1351 (13500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1352 (13510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1353 (13520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1354 (13530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1355 (13540 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1356 (13550 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1357 (13560 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1358 (13570 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1359 (13580 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 5.480 - mean_absolute_error: 27.827 - mean_q: 55.513\n",
      "\n",
      "Interval 1360 (13590 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1361 (13600 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1362 (13610 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1363 (13620 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1364 (13630 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1365 (13640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1366 (13650 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1367 (13660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1368 (13670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1369 (13680 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1370 (13690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1371 (13700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1372 (13710 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1373 (13720 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1374 (13730 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1375 (13740 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1376 (13750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1377 (13760 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1378 (13770 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1379 (13780 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 22.041 - mean_absolute_error: 28.136 - mean_q: 55.347\n",
      "\n",
      "Interval 1380 (13790 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1381 (13800 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1382 (13810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1383 (13820 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1384 (13830 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1385 (13840 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1386 (13850 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1387 (13860 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1388 (13870 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1389 (13880 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1390 (13890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1391 (13900 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1392 (13910 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1393 (13920 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1394 (13930 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1395 (13940 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1396 (13950 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1397 (13960 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1398 (13970 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1399 (13980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 6.144 - mean_absolute_error: 28.245 - mean_q: 56.082\n",
      "\n",
      "Interval 1400 (13990 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1401 (14000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1402 (14010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1403 (14020 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1404 (14030 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1405 (14040 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1406 (14050 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1407 (14060 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1408 (14070 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1409 (14080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1410 (14090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1411 (14100 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1412 (14110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1413 (14120 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1414 (14130 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1415 (14140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1416 (14150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1417 (14160 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1418 (14170 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1419 (14180 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 20.163 - mean_absolute_error: 29.737 - mean_q: 58.804\n",
      "\n",
      "Interval 1420 (14190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1421 (14200 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1422 (14210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1423 (14220 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1424 (14230 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1425 (14240 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1426 (14250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1427 (14260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1428 (14270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1429 (14280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1430 (14290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1431 (14300 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1432 (14310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1433 (14320 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1434 (14330 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1435 (14340 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1436 (14350 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1437 (14360 steps performed)\n",
      "10/10 [==============================] - 0s 8ms/step - reward: 1.0000\n",
      "Interval 1438 (14370 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1439 (14380 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 25.513 - mean_absolute_error: 29.724 - mean_q: 58.536\n",
      "\n",
      "Interval 1440 (14390 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1441 (14400 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1442 (14410 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1443 (14420 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1444 (14430 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1445 (14440 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1446 (14450 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1447 (14460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1448 (14470 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1449 (14480 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1450 (14490 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1451 (14500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1452 (14510 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1453 (14520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1454 (14530 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1455 (14540 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 163.000 [163.000, 163.000] - loss: 1.184 - mean_absolute_error: 29.634 - mean_q: 58.985\n",
      "\n",
      "Interval 1456 (14550 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1457 (14560 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1458 (14570 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1459 (14580 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1460 (14590 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1461 (14600 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1462 (14610 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1463 (14620 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1464 (14630 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1465 (14640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1466 (14650 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1467 (14660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1468 (14670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 128.000 [128.000, 128.000] - loss: 16.616 - mean_absolute_error: 29.620 - mean_q: 58.517\n",
      "\n",
      "Interval 1469 (14680 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1470 (14690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1471 (14700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1472 (14710 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1473 (14720 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1474 (14730 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1475 (14740 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1476 (14750 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1477 (14760 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1478 (14770 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1479 (14780 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 109.000 [109.000, 109.000] - loss: 12.070 - mean_absolute_error: 28.449 - mean_q: 56.399\n",
      "\n",
      "Interval 1480 (14790 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1481 (14800 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1482 (14810 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1483 (14820 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1484 (14830 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1485 (14840 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1486 (14850 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1487 (14860 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1488 (14870 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1489 (14880 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1490 (14890 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1491 (14900 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1492 (14910 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1493 (14920 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1494 (14930 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1495 (14940 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1496 (14950 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1497 (14960 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1498 (14970 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1499 (14980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 1.159 - mean_absolute_error: 29.532 - mean_q: 58.767\n",
      "\n",
      "Interval 1500 (14990 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1501 (15000 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1502 (15010 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1503 (15020 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1504 (15030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1505 (15040 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1506 (15050 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1507 (15060 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1508 (15070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1509 (15080 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1510 (15090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1511 (15100 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 124.000 [124.000, 124.000] - loss: 6.124 - mean_absolute_error: 29.447 - mean_q: 58.329\n",
      "\n",
      "Interval 1512 (15110 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1513 (15120 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1514 (15130 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1515 (15140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1516 (15150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1517 (15160 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1518 (15170 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1519 (15180 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1520 (15190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1521 (15200 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1522 (15210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1523 (15220 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1524 (15230 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1525 (15240 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1526 (15250 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1527 (15260 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 157.000 [157.000, 157.000] - loss: 14.857 - mean_absolute_error: 29.412 - mean_q: 58.041\n",
      "\n",
      "Interval 1528 (15270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1529 (15280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1530 (15290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1531 (15300 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1532 (15310 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1533 (15320 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1534 (15330 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1535 (15340 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1536 (15350 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1537 (15360 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1538 (15370 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1539 (15380 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 123.000 [123.000, 123.000] - loss: 11.315 - mean_absolute_error: 29.289 - mean_q: 57.825\n",
      "\n",
      "Interval 1540 (15390 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1541 (15400 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1542 (15410 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1543 (15420 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1544 (15430 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1545 (15440 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1546 (15450 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1547 (15460 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1548 (15470 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1549 (15480 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1550 (15490 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1551 (15500 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1552 (15510 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1553 (15520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1554 (15530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 153.000 [153.000, 153.000] - loss: 12.622 - mean_absolute_error: 30.790 - mean_q: 60.740\n",
      "\n",
      "Interval 1555 (15540 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1556 (15550 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1557 (15560 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1558 (15570 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1559 (15580 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1560 (15590 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1561 (15600 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1562 (15610 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1563 (15620 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1564 (15630 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1565 (15640 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1566 (15650 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1567 (15660 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1568 (15670 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1569 (15680 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1570 (15690 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 159.000 [159.000, 159.000] - loss: 11.228 - mean_absolute_error: 29.755 - mean_q: 58.650\n",
      "\n",
      "Interval 1571 (15700 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1572 (15710 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1573 (15720 steps performed)\n",
      "10/10 [==============================] - 0s 8ms/step - reward: 1.0000\n",
      "Interval 1574 (15730 steps performed)\n",
      "10/10 [==============================] - 0s 8ms/step - reward: 1.0000\n",
      "Interval 1575 (15740 steps performed)\n",
      "10/10 [==============================] - 0s 8ms/step - reward: 1.0000\n",
      "Interval 1576 (15750 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1577 (15760 steps performed)\n",
      "10/10 [==============================] - 0s 9ms/step - reward: 1.0000\n",
      "Interval 1578 (15770 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1579 (15780 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1580 (15790 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1581 (15800 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1582 (15810 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1583 (15820 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 130.000 [130.000, 130.000] - loss: 10.461 - mean_absolute_error: 30.137 - mean_q: 59.601\n",
      "\n",
      "Interval 1584 (15830 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1585 (15840 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1586 (15850 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1587 (15860 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1588 (15870 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1589 (15880 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1590 (15890 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1591 (15900 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1592 (15910 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1593 (15920 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1594 (15930 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1595 (15940 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1596 (15950 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1597 (15960 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1598 (15970 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1599 (15980 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 156.000 [156.000, 156.000] - loss: 1.163 - mean_absolute_error: 29.163 - mean_q: 57.798\n",
      "\n",
      "Interval 1600 (15990 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1601 (16000 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1602 (16010 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1603 (16020 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1604 (16030 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1605 (16040 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1606 (16050 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1607 (16060 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1608 (16070 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1609 (16080 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1610 (16090 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1611 (16100 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1612 (16110 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1613 (16120 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1614 (16130 steps performed)\n",
      "10/10 [==============================] - ETA: 0s - reward: 1.000 - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1615 (16140 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1616 (16150 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 170.000 [170.000, 170.000] - loss: 9.818 - mean_absolute_error: 29.913 - mean_q: 59.022\n",
      "\n",
      "Interval 1617 (16160 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1618 (16170 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1619 (16180 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1620 (16190 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1621 (16200 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1622 (16210 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1623 (16220 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1624 (16230 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1625 (16240 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1626 (16250 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1627 (16260 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1628 (16270 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 120.000 [120.000, 120.000] - loss: 21.682 - mean_absolute_error: 29.707 - mean_q: 58.403\n",
      "\n",
      "Interval 1629 (16280 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1630 (16290 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1631 (16300 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1632 (16310 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1633 (16320 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1634 (16330 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1635 (16340 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1636 (16350 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1637 (16360 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1638 (16370 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1639 (16380 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1640 (16390 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1641 (16400 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 136.000 [136.000, 136.000] - loss: 13.997 - mean_absolute_error: 30.009 - mean_q: 58.955\n",
      "\n",
      "Interval 1642 (16410 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1643 (16420 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1644 (16430 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1645 (16440 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1646 (16450 steps performed)\n",
      "10/10 [==============================] - 0s 10ms/step - reward: 1.0000\n",
      "Interval 1647 (16460 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1648 (16470 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1649 (16480 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1650 (16490 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1651 (16500 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1652 (16510 steps performed)\n",
      "10/10 [==============================] - 0s 3ms/step - reward: 1.0000\n",
      "Interval 1653 (16520 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1654 (16530 steps performed)\n",
      "10/10 [==============================] - 0s 4ms/step - reward: 1.0000\n",
      "Interval 1655 (16540 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1656 (16550 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1657 (16560 steps performed)\n",
      "10/10 [==============================] - 0s 8ms/step - reward: 1.0000\n",
      "1 episodes - episode_reward: 151.000 [151.000, 151.000] - loss: 1.040 - mean_absolute_error: 30.062 - mean_q: 59.639\n",
      "\n",
      "Interval 1658 (16570 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1659 (16580 steps performed)\n",
      "10/10 [==============================] - 0s 7ms/step - reward: 1.0000\n",
      "Interval 1660 (16590 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1661 (16600 steps performed)\n",
      "10/10 [==============================] - 0s 6ms/step - reward: 1.0000\n",
      "Interval 1662 (16610 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1663 (16620 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1664 (16630 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n",
      "Interval 1665 (16640 steps performed)\n",
      "10/10 [==============================] - 0s 5ms/step - reward: 1.0000\n"
     ]
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=50000, verbose=1, visualize=False, log_interval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below code to test your DRL model. The larger the reward and number of steps per episode, the better your model performs. Running about 10 episodes will give you a proper overall status.\n",
    "\n",
    "**NOTE:** Don't close the graph after/while running it. This will reset the kernel and cause you having to re-run everything. You can simply re-run the below code instead, each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: 115.000, steps: 115\n",
      "Episode 2: reward: 72.000, steps: 72\n",
      "Episode 3: reward: 200.000, steps: 200\n",
      "Episode 4: reward: 200.000, steps: 200\n",
      "Episode 5: reward: 73.000, steps: 73\n",
      "Episode 6: reward: 200.000, steps: 200\n",
      "Episode 7: reward: 108.000, steps: 108\n",
      "Episode 8: reward: 200.000, steps: 200\n",
      "Episode 9: reward: 94.000, steps: 94\n",
      "Episode 10: reward: 200.000, steps: 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e330286d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn.test(env, nb_episodes=10, visualize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
