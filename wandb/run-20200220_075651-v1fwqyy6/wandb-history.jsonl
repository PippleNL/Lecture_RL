{"step": 9, "episode": 1, "duration": 0.23867780000000494, "episode_steps": 9, "sps": 37.70773821444564, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.16191159973209868, "obs_min": -2.882146374456019, "obs_max": 1.7493737865778334, "loss": NaN, "mae": NaN, "mean_q": NaN, "_runtime": 579.8386270999908, "_timestamp": 1582185413.2121089, "_step": 0}
{"step": 20, "episode": 2, "duration": 1.05473470000004, "episode_steps": 11, "sps": 10.429162897550999, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.08770055753954359, "obs_min": -2.7154319070278476, "obs_max": 1.8071698255497022, "loss": 0.6661207477251688, "mae": 0.9834301670392355, "mean_q": 0.8588227563434176, "_runtime": 580.9010729789734, "_timestamp": 1582185414.2745547, "_step": 1}
{"step": 29, "episode": 3, "duration": 0.058994100000063554, "episode_steps": 9, "sps": 152.557628644056, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.11077951752015847, "obs_min": -2.225823684949646, "obs_max": 1.422672819270184, "loss": 0.7526023387908936, "mae": 0.9991564154624939, "mean_q": 1.0499060153961182, "_runtime": 580.9791777133942, "_timestamp": 1582185414.3526595, "_step": 2}
{"step": 39, "episode": 4, "duration": 0.12767459999997754, "episode_steps": 10, "sps": 78.32411458506044, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.1524645016251861, "obs_min": -2.770248548892709, "obs_max": 1.7379318776413772, "loss": 0.6932898759841919, "mae": 0.9091434478759766, "mean_q": 1.1160320043563843, "_runtime": 581.1197900772095, "_timestamp": 1582185414.4932718, "_step": 3}
{"step": 47, "episode": 5, "duration": 0.06455460000006497, "episode_steps": 8, "sps": 123.92610286473696, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13801240874262907, "obs_min": -2.563367859456072, "obs_max": 1.6044162335499457, "loss": 0.615299642086029, "mae": 0.8673059940338135, "mean_q": 1.3093689680099487, "_runtime": 581.2135307788849, "_timestamp": 1582185414.5870125, "_step": 4}
{"step": 56, "episode": 6, "duration": 0.05617780000000039, "episode_steps": 9, "sps": 160.20563283004918, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.12352575750529961, "obs_min": -2.761808527178321, "obs_max": 1.7677038732598396, "loss": 0.5885019302368164, "mae": 0.7863752841949463, "mean_q": 1.3104157447814941, "_runtime": 581.2760469913483, "_timestamp": 1582185414.6495287, "_step": 5}
{"step": 65, "episode": 7, "duration": 0.11902870000005805, "episode_steps": 9, "sps": 75.61201626158741, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.1394178181279121, "obs_min": -2.7984229196413786, "obs_max": 1.803674166928711, "loss": 0.5270716547966003, "mae": 0.7427170872688293, "mean_q": 1.4790438413619995, "_runtime": 581.4166443347931, "_timestamp": 1582185414.790126, "_step": 6}
{"step": 74, "episode": 8, "duration": 0.0587762999999768, "episode_steps": 9, "sps": 153.1229424105218, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13844782204888295, "obs_min": -2.8166755398401757, "obs_max": 1.7573622882211342, "loss": 0.5584653615951538, "mae": 0.7138150334358215, "mean_q": 1.5762419700622559, "_runtime": 581.4947662353516, "_timestamp": 1582185414.868248, "_step": 7}
{"step": 83, "episode": 9, "duration": 0.09605279999993854, "episode_steps": 9, "sps": 93.69846584384587, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.11795240898187087, "obs_min": -2.7407886987423464, "obs_max": 1.8047122684066061, "loss": 0.44578632712364197, "mae": 0.6021880507469177, "mean_q": 1.6015799045562744, "_runtime": 581.6041324138641, "_timestamp": 1582185414.9776142, "_step": 8}
{"step": 94, "episode": 10, "duration": 0.07389209999996638, "episode_steps": 11, "sps": 148.86571094887012, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.12426704542242013, "obs_min": -2.71926295818212, "obs_max": 1.7429313110145965, "loss": 0.537839949131012, "mae": 0.6239160299301147, "mean_q": 1.7098952531814575, "_runtime": 581.6978750228882, "_timestamp": 1582185415.0713568, "_step": 9}
{"step": 103, "episode": 11, "duration": 0.08680299999991803, "episode_steps": 9, "sps": 103.68305242916142, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14259677376966162, "obs_min": -2.801669680145508, "obs_max": 1.7339559246845002, "loss": 0.4873902499675751, "mae": 0.5846670269966125, "mean_q": 1.8162341117858887, "_runtime": 581.8072514533997, "_timestamp": 1582185415.1807332, "_step": 10}
{"step": 112, "episode": 12, "duration": 0.09579850000000079, "episode_steps": 9, "sps": 93.94719123994558, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13610207125490298, "obs_min": -2.794754030147289, "obs_max": 1.8015528903675007, "loss": 0.5230259299278259, "mae": 0.5620858073234558, "mean_q": 1.8816250562667847, "_runtime": 581.916627407074, "_timestamp": 1582185415.2901092, "_step": 11}
{"step": 121, "episode": 13, "duration": 0.09989980000000287, "episode_steps": 9, "sps": 90.09027045098931, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14362367320127434, "obs_min": -2.8807037608770236, "obs_max": 1.8038797001425235, "loss": 0.626652717590332, "mae": 0.6124470233917236, "mean_q": 1.9761791229248047, "_runtime": 582.0260074138641, "_timestamp": 1582185415.3994892, "_step": 12}
{"step": 130, "episode": 14, "duration": 0.11912770000003547, "episode_steps": 9, "sps": 75.54917957785905, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14193205454341953, "obs_min": -2.812409525259429, "obs_max": 1.7775502400095635, "loss": 0.581981897354126, "mae": 0.5565890073776245, "mean_q": 1.8907809257507324, "_runtime": 582.1822221279144, "_timestamp": 1582185415.5557039, "_step": 13}
{"step": 140, "episode": 15, "duration": 0.08508510000001479, "episode_steps": 10, "sps": 117.52939116247452, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15679793720641083, "obs_min": -3.068967598537639, "obs_max": 1.9483266209670798, "loss": 0.5961359143257141, "mae": 0.5493295192718506, "mean_q": 2.0772111415863037, "_runtime": 582.2759785652161, "_timestamp": 1582185415.6494603, "_step": 14}
{"step": 150, "episode": 16, "duration": 0.07659540000008747, "episode_steps": 10, "sps": 130.55614305805022, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13219675622833363, "obs_min": -3.015821011057961, "obs_max": 1.9616649456589925, "loss": 0.5618814826011658, "mae": 0.5165669322013855, "mean_q": 2.065924644470215, "_runtime": 582.3540794849396, "_timestamp": 1582185415.7275612, "_step": 15}
{"step": 159, "episode": 17, "duration": 0.08143140000004223, "episode_steps": 9, "sps": 110.52247658759806, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.16735631394366582, "obs_min": -2.8726168451026037, "obs_max": 1.7795084560897525, "loss": 0.583428144454956, "mae": 0.5233762264251709, "mean_q": 2.166001319885254, "_runtime": 582.4478240013123, "_timestamp": 1582185415.8213058, "_step": 16}
{"step": 168, "episode": 18, "duration": 0.07164030000001276, "episode_steps": 9, "sps": 125.62761462470701, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15166943492302165, "obs_min": -2.8346734579118316, "obs_max": 1.7512034595622028, "loss": 0.5353763103485107, "mae": 0.5275433659553528, "mean_q": 2.2961459159851074, "_runtime": 582.5415644645691, "_timestamp": 1582185415.9150462, "_step": 17}
{"step": 179, "episode": 19, "duration": 0.07359410000003663, "episode_steps": 11, "sps": 149.4685035892079, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.0924033883352705, "obs_min": -2.7739351334419147, "obs_max": 1.7845541344950633, "loss": 0.5464580059051514, "mae": 0.5578405857086182, "mean_q": 2.3094441890716553, "_runtime": 582.6353080272675, "_timestamp": 1582185416.0087898, "_step": 18}
{"step": 189, "episode": 20, "duration": 0.06936509999991358, "episode_steps": 10, "sps": 144.16471683905104, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14098117467779642, "obs_min": -3.0912610418716966, "obs_max": 1.96056247627468, "loss": 0.5418522357940674, "mae": 0.5851696729660034, "mean_q": 2.337801456451416, "_runtime": 582.7134485244751, "_timestamp": 1582185416.0869303, "_step": 19}
{"step": 199, "episode": 21, "duration": 0.0616427999999587, "episode_steps": 10, "sps": 162.22494760145062, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.10475124698969955, "obs_min": -2.978864163382826, "obs_max": 1.9739705658030546, "loss": 0.6843898892402649, "mae": 0.6820114254951477, "mean_q": 2.5722897052764893, "_runtime": 582.7915484905243, "_timestamp": 1582185416.1650302, "_step": 20}
{"step": 208, "episode": 22, "duration": 0.05555409999999483, "episode_steps": 9, "sps": 162.00424451122126, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13255269758351684, "obs_min": -2.742953427428682, "obs_max": 1.7479996465987795, "loss": 0.6364699006080627, "mae": 0.6757615208625793, "mean_q": 2.522585868835449, "_runtime": 582.8540620803833, "_timestamp": 1582185416.2275438, "_step": 21}
{"step": 219, "episode": 23, "duration": 0.06829240000001846, "episode_steps": 11, "sps": 161.07209587006793, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.11443622167351436, "obs_min": -2.7411028390995877, "obs_max": 1.795740163570261, "loss": 0.6602174043655396, "mae": 0.7471197247505188, "mean_q": 2.5837724208831787, "_runtime": 582.9477887153625, "_timestamp": 1582185416.3212705, "_step": 22}
{"step": 229, "episode": 24, "duration": 0.06575650000002042, "episode_steps": 10, "sps": 152.07622060171838, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13562496090897774, "obs_min": -3.098992904331541, "obs_max": 1.9701235040697056, "loss": 0.6809991598129272, "mae": 0.7724173665046692, "mean_q": 2.7086181640625, "_runtime": 583.0259258747101, "_timestamp": 1582185416.3994076, "_step": 23}
{"step": 238, "episode": 25, "duration": 0.15669880000007197, "episode_steps": 9, "sps": 57.43502821971749, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.17306553878196274, "obs_min": -2.8608802092796, "obs_max": 1.7477307180279875, "loss": 0.6236094236373901, "mae": 0.8130638599395752, "mean_q": 2.661524772644043, "_runtime": 583.1977763175964, "_timestamp": 1582185416.571258, "_step": 24}
{"step": 248, "episode": 26, "duration": 0.06735430000003362, "episode_steps": 10, "sps": 148.46862041465815, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13048503604159384, "obs_min": -2.9842028148967925, "obs_max": 1.968733576258563, "loss": 0.6442099809646606, "mae": 0.8209735155105591, "mean_q": 2.7804672718048096, "_runtime": 583.2758886814117, "_timestamp": 1582185416.6493704, "_step": 25}
{"step": 257, "episode": 27, "duration": 0.056387900000004265, "episode_steps": 9, "sps": 159.60871037934237, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.17483154436146597, "obs_min": -2.8888443082728044, "obs_max": 1.752269336221238, "loss": 0.8281728029251099, "mae": 0.9129925966262817, "mean_q": 2.882059097290039, "_runtime": 583.3540103435516, "_timestamp": 1582185416.727492, "_step": 26}
{"step": 267, "episode": 28, "duration": 0.06273769999995693, "episode_steps": 10, "sps": 159.39379352457718, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15603142098161824, "obs_min": -3.0258148363774806, "obs_max": 1.9064722486462786, "loss": 0.6563490033149719, "mae": 0.894288182258606, "mean_q": 2.793515920639038, "_runtime": 583.43212723732, "_timestamp": 1582185416.805609, "_step": 27}
{"step": 276, "episode": 29, "duration": 0.10116630000004534, "episode_steps": 9, "sps": 88.96243116527901, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.11950334147444666, "obs_min": -2.7907918389545165, "obs_max": 1.806666138315911, "loss": 0.6778377890586853, "mae": 0.934464156627655, "mean_q": 2.8040380477905273, "_runtime": 583.5415205955505, "_timestamp": 1582185416.9150023, "_step": 28}
{"step": 285, "episode": 30, "duration": 0.05708029999993869, "episode_steps": 9, "sps": 157.67261209225717, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13095688978542727, "obs_min": -2.759517722305575, "obs_max": 1.8038621756320117, "loss": 0.6269468069076538, "mae": 0.9253624677658081, "mean_q": 2.828364133834839, "_runtime": 583.6196339130402, "_timestamp": 1582185416.9931157, "_step": 29}
{"step": 293, "episode": 31, "duration": 0.0650089000000662, "episode_steps": 8, "sps": 123.06007331291335, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14668954101450227, "obs_min": -2.506182524670037, "obs_max": 1.534585954494033, "loss": 0.5637282133102417, "mae": 0.9304921627044678, "mean_q": 2.936023473739624, "_runtime": 583.6977376937866, "_timestamp": 1582185417.0712194, "_step": 30}
{"step": 306, "episode": 32, "duration": 0.08910809999997582, "episode_steps": 13, "sps": 145.89021648989853, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8461538461538461, "action_min": 0, "action_max": 1, "obs_mean": -0.11897542499604813, "obs_min": -2.7559854331288105, "obs_max": 1.715881759570612, "loss": 0.5453723669052124, "mae": 0.9408242702484131, "mean_q": 3.034085988998413, "_runtime": 583.7914969921112, "_timestamp": 1582185417.1649787, "_step": 31}
{"step": 316, "episode": 33, "duration": 0.07443490000002839, "episode_steps": 10, "sps": 134.34558251567725, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.1296388962028291, "obs_min": -2.550963210065308, "obs_max": 1.5904241754254935, "loss": 0.5440506935119629, "mae": 0.9604531526565552, "mean_q": 3.1186811923980713, "_runtime": 583.8852405548096, "_timestamp": 1582185417.2587223, "_step": 32}
{"step": 326, "episode": 34, "duration": 0.08576109999989967, "episode_steps": 10, "sps": 116.60298200479819, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.1383471705400548, "obs_min": -3.0674294835655203, "obs_max": 2.004989035306454, "loss": 0.7089198231697083, "mae": 1.084494948387146, "mean_q": 3.1628928184509277, "_runtime": 583.9789810180664, "_timestamp": 1582185417.3524628, "_step": 33}
{"step": 337, "episode": 35, "duration": 0.08318589999998949, "episode_steps": 11, "sps": 132.23394830135143, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.13401511653548623, "obs_min": -2.739577030418574, "obs_max": 1.7366784819164722, "loss": 0.5907216668128967, "mae": 1.0991675853729248, "mean_q": 3.1067214012145996, "_runtime": 584.0883321762085, "_timestamp": 1582185417.461814, "_step": 34}
{"step": 346, "episode": 36, "duration": 0.07573759999991125, "episode_steps": 9, "sps": 118.83133344614228, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15946351534986491, "obs_min": -2.8251281452622097, "obs_max": 1.739565815792131, "loss": 0.6143962740898132, "mae": 1.1482290029525757, "mean_q": 3.1851625442504883, "_runtime": 584.1664519309998, "_timestamp": 1582185417.5399337, "_step": 35}
{"step": 355, "episode": 37, "duration": 0.08679489999997259, "episode_steps": 9, "sps": 103.69272848984033, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.13520501312938663, "obs_min": -2.2908091780829194, "obs_max": 1.3902546232932922, "loss": 0.5298881530761719, "mae": 1.1542301177978516, "mean_q": 3.2659966945648193, "_runtime": 584.275839805603, "_timestamp": 1582185417.6493216, "_step": 36}
{"step": 365, "episode": 38, "duration": 0.07575870000005125, "episode_steps": 10, "sps": 131.99804114898006, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13065476393712583, "obs_min": -3.00440676590345, "obs_max": 1.9731467512936793, "loss": 0.6006248593330383, "mae": 1.2399097681045532, "mean_q": 3.3962645530700684, "_runtime": 584.3695631027222, "_timestamp": 1582185417.7430449, "_step": 37}
{"step": 373, "episode": 39, "duration": 0.06003750000002128, "episode_steps": 8, "sps": 133.25005205075433, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13774906731880038, "obs_min": -2.489830655978082, "obs_max": 1.562211466992707, "loss": 0.5770975351333618, "mae": 1.2831417322158813, "mean_q": 3.5115599632263184, "_runtime": 584.4320583343506, "_timestamp": 1582185417.80554, "_step": 38}
{"step": 385, "episode": 40, "duration": 0.09851079999998547, "episode_steps": 12, "sps": 121.81405490567299, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9166666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.12529961613377988, "obs_min": -3.0689556484294047, "obs_max": 1.9424094523992097, "loss": 0.6108396649360657, "mae": 1.3022288084030151, "mean_q": 3.567143201828003, "_runtime": 584.5570499897003, "_timestamp": 1582185417.9305317, "_step": 39}
{"step": 396, "episode": 41, "duration": 0.06908959999998388, "episode_steps": 11, "sps": 159.21354299348334, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.121266349121658, "obs_min": -3.3018210745325627, "obs_max": 2.1506985772005174, "loss": 0.7297430634498596, "mae": 1.4210400581359863, "mean_q": 3.5189104080200195, "_runtime": 584.6351690292358, "_timestamp": 1582185418.0086508, "_step": 40}
{"step": 407, "episode": 42, "duration": 0.06709699999998975, "episode_steps": 11, "sps": 163.9417559652694, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.14884374187757554, "obs_min": -2.835225100792633, "obs_max": 1.7142999400484658, "loss": 0.6648824214935303, "mae": 1.43567955493927, "mean_q": 3.438767433166504, "_runtime": 584.713308095932, "_timestamp": 1582185418.0867898, "_step": 41}
{"step": 417, "episode": 43, "duration": 0.0926808000000392, "episode_steps": 10, "sps": 107.89721279915334, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.09468622196172545, "obs_min": -2.6084715847194486, "obs_max": 1.7942007797697535, "loss": 0.6369800567626953, "mae": 1.47636878490448, "mean_q": 3.5144355297088623, "_runtime": 584.8226563930511, "_timestamp": 1582185418.1961381, "_step": 42}
{"step": 426, "episode": 44, "duration": 0.08715970000002926, "episode_steps": 9, "sps": 103.25873081248534, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13511178666956827, "obs_min": -2.829871783717932, "obs_max": 1.8011456946953626, "loss": 0.6729853749275208, "mae": 1.5357928276062012, "mean_q": 3.635815143585205, "_runtime": 584.9320240020752, "_timestamp": 1582185418.3055058, "_step": 43}
{"step": 439, "episode": 45, "duration": 0.1063441999999668, "episode_steps": 13, "sps": 122.24456058726341, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8461538461538461, "action_min": 0, "action_max": 1, "obs_mean": -0.07814663628622985, "obs_min": -2.742027949314543, "obs_max": 1.8000039779042616, "loss": 0.5835406184196472, "mae": 1.5568846464157104, "mean_q": 3.689408779144287, "_runtime": 585.041393995285, "_timestamp": 1582185418.4148757, "_step": 44}
{"step": 449, "episode": 46, "duration": 0.0736643999999842, "episode_steps": 10, "sps": 135.75078328204864, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.1015938319739605, "obs_min": -2.65192655663699, "obs_max": 1.7931034341401861, "loss": 0.6389588117599487, "mae": 1.5856878757476807, "mean_q": 3.778284788131714, "_runtime": 585.1351506710052, "_timestamp": 1582185418.5086324, "_step": 45}
{"step": 459, "episode": 47, "duration": 0.1407325000000128, "episode_steps": 10, "sps": 71.05679214111233, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.12973218566036437, "obs_min": -3.1117180882877666, "obs_max": 1.995496047159169, "loss": 0.5593185424804688, "mae": 1.6011066436767578, "mean_q": 3.7933287620544434, "_runtime": 585.2757534980774, "_timestamp": 1582185418.6492352, "_step": 46}
{"step": 469, "episode": 48, "duration": 0.12723610000000463, "episode_steps": 10, "sps": 78.59404681532706, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.1699168165997487, "obs_min": -3.106829746627677, "obs_max": 1.9229117240351636, "loss": 0.5841273069381714, "mae": 1.648601770401001, "mean_q": 3.85760235786438, "_runtime": 585.4320089817047, "_timestamp": 1582185418.8054907, "_step": 47}
{"step": 479, "episode": 49, "duration": 0.11524570000005951, "episode_steps": 10, "sps": 86.77113332640468, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15149996994365456, "obs_min": -3.103053968885648, "obs_max": 1.9485372985540357, "loss": 0.5707039833068848, "mae": 1.6865545511245728, "mean_q": 3.9085769653320312, "_runtime": 585.5569798946381, "_timestamp": 1582185418.9304616, "_step": 48}
{"step": 489, "episode": 50, "duration": 0.09801140000001851, "episode_steps": 10, "sps": 102.02894765300884, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.1518658230671754, "obs_min": -2.256436909206176, "obs_max": 1.351215573574009, "loss": 0.5070000886917114, "mae": 1.6838356256484985, "mean_q": 4.000965595245361, "_runtime": 585.6819908618927, "_timestamp": 1582185419.0554726, "_step": 49}
{"step": 498, "episode": 51, "duration": 0.07786820000001171, "episode_steps": 9, "sps": 115.57991580643505, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.13263401735506358, "obs_min": -2.2161122650398144, "obs_max": 1.4055460770452723, "loss": 0.5405802130699158, "mae": 1.7143305540084839, "mean_q": 4.075991630554199, "_runtime": 585.7601115703583, "_timestamp": 1582185419.1335933, "_step": 50}
{"step": 506, "episode": 52, "duration": 0.05788649999999507, "episode_steps": 8, "sps": 138.20148048337145, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.150039692050456, "obs_min": -2.5365888009309785, "obs_max": 1.5335975128885075, "loss": 0.6267440915107727, "mae": 1.764747142791748, "mean_q": 4.064243316650391, "_runtime": 585.8382298946381, "_timestamp": 1582185419.2117116, "_step": 51}
{"step": 514, "episode": 53, "duration": 0.0829466999999795, "episode_steps": 8, "sps": 96.4474777176425, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.1421130197716918, "obs_min": -2.5260954204785677, "obs_max": 1.5258771194713574, "loss": 0.5559465885162354, "mae": 1.736133337020874, "mean_q": 4.036403656005859, "_runtime": 585.9319875240326, "_timestamp": 1582185419.3054693, "_step": 52}
{"step": 524, "episode": 54, "duration": 0.0907816000000139, "episode_steps": 10, "sps": 110.1544806436378, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15998578572403815, "obs_min": -3.1348481123597502, "obs_max": 1.9516280530872048, "loss": 0.5858527421951294, "mae": 1.7791286706924438, "mean_q": 4.060280799865723, "_runtime": 586.0413410663605, "_timestamp": 1582185419.4148228, "_step": 53}
{"step": 534, "episode": 55, "duration": 0.09064340000008997, "episode_steps": 10, "sps": 110.32242832892493, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14854270946185272, "obs_min": -3.0832806835388755, "obs_max": 1.974747173059204, "loss": 0.44987934827804565, "mae": 1.74260675907135, "mean_q": 4.178425312042236, "_runtime": 586.1350653171539, "_timestamp": 1582185419.508547, "_step": 54}
{"step": 543, "episode": 56, "duration": 0.07717379999996865, "episode_steps": 9, "sps": 116.6198891334061, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.15407263026608653, "obs_min": -2.1565080642003767, "obs_max": 1.3402552135987535, "loss": 0.6173712015151978, "mae": 1.7997466325759888, "mean_q": 4.281044960021973, "_runtime": 586.2288312911987, "_timestamp": 1582185419.602313, "_step": 55}
{"step": 553, "episode": 57, "duration": 0.07319889999996576, "episode_steps": 10, "sps": 136.61407480173443, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.14114639352155553, "obs_min": -2.513482798257149, "obs_max": 1.5527805113096917, "loss": 0.5137935876846313, "mae": 1.7542356252670288, "mean_q": 4.2390666007995605, "_runtime": 586.3225591182709, "_timestamp": 1582185419.6960409, "_step": 56}
{"step": 564, "episode": 58, "duration": 0.07340469999996913, "episode_steps": 11, "sps": 149.85416465164528, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.11175949561116294, "obs_min": -2.7743114724187885, "obs_max": 1.7895336354771576, "loss": 0.5102280974388123, "mae": 1.7770203351974487, "mean_q": 4.262384414672852, "_runtime": 586.4006960391998, "_timestamp": 1582185419.7741778, "_step": 57}
{"step": 574, "episode": 59, "duration": 0.062071599999967475, "episode_steps": 10, "sps": 161.10427312982492, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.1343474859615263, "obs_min": -2.965707003300599, "obs_max": 1.9147392623322883, "loss": 0.45141562819480896, "mae": 1.776214361190796, "mean_q": 4.419362545013428, "_runtime": 586.4788105487823, "_timestamp": 1582185419.8522923, "_step": 58}
{"step": 583, "episode": 60, "duration": 0.05625180000004093, "episode_steps": 9, "sps": 159.99488016371834, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14573218628714205, "obs_min": -2.8067436234104823, "obs_max": 1.7196711377046066, "loss": 0.5206392407417297, "mae": 1.8487584590911865, "mean_q": 4.4664788246154785, "_runtime": 586.5569276809692, "_timestamp": 1582185419.9304094, "_step": 59}
{"step": 595, "episode": 61, "duration": 0.12603139999998803, "episode_steps": 12, "sps": 95.21436721325908, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8333333333333334, "action_min": 0, "action_max": 1, "obs_mean": -0.12833134454429132, "obs_min": -2.5785224056202853, "obs_max": 1.556168757255145, "loss": 0.4564366638660431, "mae": 1.8528584241867065, "mean_q": 4.480686664581299, "_runtime": 586.697546005249, "_timestamp": 1582185420.0710278, "_step": 60}
{"step": 604, "episode": 62, "duration": 0.05901479999999992, "episode_steps": 9, "sps": 152.5041176111757, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15887504769907046, "obs_min": -2.817729903084119, "obs_max": 1.7666580559750695, "loss": 0.5313948392868042, "mae": 1.8902955055236816, "mean_q": 4.475697040557861, "_runtime": 586.7600417137146, "_timestamp": 1582185420.1335235, "_step": 61}
{"step": 613, "episode": 63, "duration": 0.09319219999997586, "episode_steps": 9, "sps": 96.57460602928498, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.14258045576021613, "obs_min": -2.3580724421366095, "obs_max": 1.4158877626243107, "loss": 0.45738157629966736, "mae": 1.8917641639709473, "mean_q": 4.537130355834961, "_runtime": 586.8693902492523, "_timestamp": 1582185420.242872, "_step": 62}
{"step": 622, "episode": 64, "duration": 0.08119169999997666, "episode_steps": 9, "sps": 110.84876902445184, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14829241923126182, "obs_min": -2.830570590521011, "obs_max": 1.803511043864801, "loss": 0.4453146755695343, "mae": 1.8976936340332031, "mean_q": 4.593299865722656, "_runtime": 586.963133096695, "_timestamp": 1582185420.3366148, "_step": 63}
{"step": 630, "episode": 65, "duration": 0.06816420000006929, "episode_steps": 8, "sps": 117.36366010298468, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15550972663334547, "obs_min": -2.522561074362013, "obs_max": 1.5522931793681622, "loss": 0.43411698937416077, "mae": 1.9346694946289062, "mean_q": 4.5927276611328125, "_runtime": 587.0568788051605, "_timestamp": 1582185420.4303606, "_step": 64}
{"step": 640, "episode": 66, "duration": 0.08055679999995391, "episode_steps": 10, "sps": 124.13601334717518, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.13840274361843033, "obs_min": -2.583758981225653, "obs_max": 1.586237969849976, "loss": 0.5328271985054016, "mae": 2.012967824935913, "mean_q": 4.588311672210693, "_runtime": 587.150621175766, "_timestamp": 1582185420.524103, "_step": 65}
{"step": 648, "episode": 67, "duration": 0.06015560000003006, "episode_steps": 8, "sps": 132.98844995305512, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14736492393786205, "obs_min": -2.523693354672406, "obs_max": 1.5624440903660795, "loss": 0.45049479603767395, "mae": 2.0170183181762695, "mean_q": 4.669728755950928, "_runtime": 587.2131311893463, "_timestamp": 1582185420.586613, "_step": 66}
{"step": 658, "episode": 68, "duration": 0.062917099999936, "episode_steps": 10, "sps": 158.93930266986516, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.13038227707615319, "obs_min": -2.708686679481316, "obs_max": 1.7801248366931595, "loss": 0.43630772829055786, "mae": 2.012763500213623, "mean_q": 4.775435924530029, "_runtime": 587.2912547588348, "_timestamp": 1582185420.6647365, "_step": 67}
{"step": 667, "episode": 69, "duration": 0.05619649999994181, "episode_steps": 9, "sps": 160.15232265371188, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.14080971440072737, "obs_min": -2.2514316752084413, "obs_max": 1.3856996670824258, "loss": 0.39083707332611084, "mae": 2.021695613861084, "mean_q": 4.762611389160156, "_runtime": 587.369354724884, "_timestamp": 1582185420.7428365, "_step": 68}
{"step": 679, "episode": 70, "duration": 0.08160029999999097, "episode_steps": 12, "sps": 147.0582828739763, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8333333333333334, "action_min": 0, "action_max": 1, "obs_mean": -0.09735929282833826, "obs_min": -2.568274963179949, "obs_max": 1.5839259271899115, "loss": 0.36463332176208496, "mae": 2.0544817447662354, "mean_q": 4.848377704620361, "_runtime": 587.4631006717682, "_timestamp": 1582185420.8365824, "_step": 69}
{"step": 690, "episode": 71, "duration": 0.06893569999999727, "episode_steps": 11, "sps": 159.56898965268266, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8181818181818182, "action_min": 0, "action_max": 1, "obs_mean": -0.12703282126514723, "obs_min": -2.346261974401072, "obs_max": 1.5166774267294445, "loss": 0.4736575186252594, "mae": 2.1252005100250244, "mean_q": 4.8064165115356445, "_runtime": 587.5412380695343, "_timestamp": 1582185420.9147198, "_step": 70}
{"step": 700, "episode": 72, "duration": 0.14911319999998796, "episode_steps": 10, "sps": 67.06314397384543, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.11226693216214176, "obs_min": -2.6289201779114166, "obs_max": 1.786748594545673, "loss": 0.4369684159755707, "mae": 2.143850803375244, "mean_q": 4.761302947998047, "_runtime": 587.7130856513977, "_timestamp": 1582185421.0865674, "_step": 71}
{"step": 709, "episode": 73, "duration": 0.07011959999999817, "episode_steps": 9, "sps": 128.35212978967698, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.15732021006165142, "obs_min": -2.444327633747246, "obs_max": 1.5206016044320023, "loss": 0.3389849364757538, "mae": 2.12786602973938, "mean_q": 4.942617416381836, "_runtime": 587.7912361621857, "_timestamp": 1582185421.164718, "_step": 72}
{"step": 720, "episode": 74, "duration": 0.08904180000001816, "episode_steps": 11, "sps": 123.53748464201934, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8181818181818182, "action_min": 0, "action_max": 1, "obs_mean": -0.10606476002542563, "obs_min": -2.3224107115589225, "obs_max": 1.595936780635547, "loss": 0.4476236402988434, "mae": 2.18591046333313, "mean_q": 4.907907485961914, "_runtime": 587.9005703926086, "_timestamp": 1582185421.2740521, "_step": 73}
{"step": 730, "episode": 75, "duration": 0.06913940000004004, "episode_steps": 10, "sps": 144.63533094001696, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.1310717601399709, "obs_min": -2.4251281247532614, "obs_max": 1.5847156737205057, "loss": 0.3955894410610199, "mae": 2.176361322402954, "mean_q": 4.945462703704834, "_runtime": 587.9786894321442, "_timestamp": 1582185421.3521712, "_step": 74}
{"step": 743, "episode": 76, "duration": 0.0802821000000904, "episode_steps": 13, "sps": 161.92899787107416, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7692307692307693, "action_min": 0, "action_max": 1, "obs_mean": -0.06348795655757059, "obs_min": -2.4104825770277616, "obs_max": 1.6068658815433299, "loss": 0.3685300946235657, "mae": 2.180358409881592, "mean_q": 4.93324613571167, "_runtime": 588.072450876236, "_timestamp": 1582185421.4459326, "_step": 75}
{"step": 751, "episode": 77, "duration": 0.0505399999999554, "episode_steps": 8, "sps": 158.29046299974397, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.875, "action_min": 0, "action_max": 1, "obs_mean": -0.1430036251697413, "obs_min": -2.223066586839376, "obs_max": 1.3950288437260763, "loss": 0.39895644783973694, "mae": 2.202528953552246, "mean_q": 4.977648735046387, "_runtime": 588.1349291801453, "_timestamp": 1582185421.508411, "_step": 76}
{"step": 762, "episode": 78, "duration": 0.07341040000005705, "episode_steps": 11, "sps": 149.8425291238224, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.10911614193282367, "obs_min": -2.353265701500261, "obs_max": 1.603150627535026, "loss": 0.3472360670566559, "mae": 2.1982455253601074, "mean_q": 5.136803150177002, "_runtime": 588.2286896705627, "_timestamp": 1582185421.6021714, "_step": 77}
{"step": 773, "episode": 79, "duration": 0.13015020000000277, "episode_steps": 11, "sps": 84.51773412564688, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8181818181818182, "action_min": 0, "action_max": 1, "obs_mean": -0.11561401391664711, "obs_min": -2.465574642867091, "obs_max": 1.6004251596882333, "loss": 0.3925711512565613, "mae": 2.2129571437835693, "mean_q": 5.089303016662598, "_runtime": 588.3692905902863, "_timestamp": 1582185421.7427723, "_step": 78}
{"step": 783, "episode": 80, "duration": 0.06668720000004669, "episode_steps": 10, "sps": 149.95381422511366, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.12919736212055322, "obs_min": -2.198832221072091, "obs_max": 1.4136528200274474, "loss": 0.2937607169151306, "mae": 2.2022716999053955, "mean_q": 5.099196434020996, "_runtime": 588.4474053382874, "_timestamp": 1582185421.820887, "_step": 79}
{"step": 792, "episode": 81, "duration": 0.062461600000006, "episode_steps": 9, "sps": 144.0885279915842, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.12192413087712985, "obs_min": -2.4102383555193287, "obs_max": 1.576783758950689, "loss": 0.34265458583831787, "mae": 2.244602918624878, "mean_q": 5.293081283569336, "_runtime": 588.525542974472, "_timestamp": 1582185421.8990247, "_step": 80}
{"step": 802, "episode": 82, "duration": 0.13023889999999483, "episode_steps": 10, "sps": 76.78197527774265, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.12327174318069445, "obs_min": -2.0064826503219457, "obs_max": 1.222039548631157, "loss": 0.34806662797927856, "mae": 2.264679431915283, "mean_q": 5.1617326736450195, "_runtime": 588.6817798614502, "_timestamp": 1582185422.0552616, "_step": 81}
{"step": 811, "episode": 83, "duration": 0.06700450000005276, "episode_steps": 9, "sps": 134.31933676085805, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.13160113969485923, "obs_min": -2.2163112427928353, "obs_max": 1.3490743601155466, "loss": 0.2698473036289215, "mae": 2.278794288635254, "mean_q": 5.392399311065674, "_runtime": 588.7598857879639, "_timestamp": 1582185422.1333675, "_step": 82}
{"step": 820, "episode": 84, "duration": 0.05763230000002295, "episode_steps": 9, "sps": 156.16242974853364, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.1298499545017626, "obs_min": -2.456750435171601, "obs_max": 1.608525257568004, "loss": 0.28141117095947266, "mae": 2.3116095066070557, "mean_q": 5.300238132476807, "_runtime": 588.8380179405212, "_timestamp": 1582185422.2114997, "_step": 83}
{"step": 832, "episode": 85, "duration": 0.07775019999996857, "episode_steps": 12, "sps": 154.3404389957177, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.75, "action_min": 0, "action_max": 1, "obs_mean": -0.10234583569860693, "obs_min": -2.16381569445214, "obs_max": 1.3595688545975317, "loss": 0.3082893192768097, "mae": 2.3739476203918457, "mean_q": 5.438358783721924, "_runtime": 588.9317464828491, "_timestamp": 1582185422.3052282, "_step": 84}
{"step": 842, "episode": 86, "duration": 0.08433669999999438, "episode_steps": 10, "sps": 118.57234157846662, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.13099917383380605, "obs_min": -2.125940665950841, "obs_max": 1.378369845569592, "loss": 0.3508940041065216, "mae": 2.4161288738250732, "mean_q": 5.303627967834473, "_runtime": 589.0255100727081, "_timestamp": 1582185422.3989918, "_step": 85}
{"step": 851, "episode": 87, "duration": 0.08210899999994581, "episode_steps": 9, "sps": 109.61039593718033, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.1310184541040458, "obs_min": -2.173485217582556, "obs_max": 1.416664429010753, "loss": 0.221971333026886, "mae": 2.370352268218994, "mean_q": 5.357349872589111, "_runtime": 589.1192677021027, "_timestamp": 1582185422.4927495, "_step": 86}
{"step": 862, "episode": 88, "duration": 0.09944949999999153, "episode_steps": 11, "sps": 110.60890200554992, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.12451229813968316, "obs_min": -1.986997730362446, "obs_max": 1.1452730339853845, "loss": 0.32335641980171204, "mae": 2.3988542556762695, "mean_q": 5.367486000061035, "_runtime": 589.2442445755005, "_timestamp": 1582185422.6177263, "_step": 87}
{"step": 871, "episode": 89, "duration": 0.08176120000007359, "episode_steps": 9, "sps": 110.07666227980876, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.1256399439481622, "obs_min": -2.130578685259635, "obs_max": 1.344375934542986, "loss": 0.34878459572792053, "mae": 2.4314448833465576, "mean_q": 5.543074607849121, "_runtime": 589.3379702568054, "_timestamp": 1582185422.711452, "_step": 88}
{"step": 880, "episode": 90, "duration": 0.08121240000002672, "episode_steps": 9, "sps": 110.8205150937177, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.14198625926086128, "obs_min": -2.1962238422312788, "obs_max": 1.4107823855769555, "loss": 0.26387032866477966, "mae": 2.394747018814087, "mean_q": 5.475571632385254, "_runtime": 589.44735455513, "_timestamp": 1582185422.8208363, "_step": 89}
{"step": 894, "episode": 91, "duration": 0.1029247999999825, "episode_steps": 14, "sps": 136.0216390996376, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7142857142857143, "action_min": 0, "action_max": 1, "obs_mean": -0.09694033324310107, "obs_min": -2.1273049481359787, "obs_max": 1.232710762107146, "loss": 0.2619805932044983, "mae": 2.44511079788208, "mean_q": 5.6806111335754395, "_runtime": 589.556723356247, "_timestamp": 1582185422.930205, "_step": 90}
{"step": 903, "episode": 92, "duration": 0.07124309999994693, "episode_steps": 9, "sps": 126.3280233455128, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.1357160459242112, "obs_min": -2.159715854492891, "obs_max": 1.3469428187241563, "loss": 0.27396517992019653, "mae": 2.4904987812042236, "mean_q": 5.756522178649902, "_runtime": 589.6348230838776, "_timestamp": 1582185423.0083048, "_step": 91}
{"step": 913, "episode": 93, "duration": 0.07157429999995202, "episode_steps": 10, "sps": 139.71495355185735, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.13421873700115833, "obs_min": -2.2421521270260376, "obs_max": 1.3700830869478406, "loss": 0.3206116557121277, "mae": 2.518618583679199, "mean_q": 5.621425151824951, "_runtime": 589.7285859584808, "_timestamp": 1582185423.1020677, "_step": 92}
{"step": 922, "episode": 94, "duration": 0.06840850000003229, "episode_steps": 9, "sps": 131.56259821507197, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.1360051403751285, "obs_min": -2.125056018317453, "obs_max": 1.3466628277342185, "loss": 0.24382556974887848, "mae": 2.517575263977051, "mean_q": 5.61799430847168, "_runtime": 589.8066878318787, "_timestamp": 1582185423.1801696, "_step": 93}
{"step": 933, "episode": 95, "duration": 0.07871899999997822, "episode_steps": 11, "sps": 139.73754747904627, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.09068714358574229, "obs_min": -2.2638819088174973, "obs_max": 1.5959854985760904, "loss": 0.32319334149360657, "mae": 2.5578248500823975, "mean_q": 5.600388050079346, "_runtime": 589.9004485607147, "_timestamp": 1582185423.2739303, "_step": 94}
{"step": 943, "episode": 96, "duration": 0.08490840000001754, "episode_steps": 10, "sps": 117.7739776040761, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.11358137420041617, "obs_min": -2.201083912308955, "obs_max": 1.4174103186447642, "loss": 0.29977136850357056, "mae": 2.5840225219726562, "mean_q": 5.689274787902832, "_runtime": 589.9941892623901, "_timestamp": 1582185423.367671, "_step": 95}
{"step": 951, "episode": 97, "duration": 0.06284679999998843, "episode_steps": 8, "sps": 127.29367286801352, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.875, "action_min": 0, "action_max": 1, "obs_mean": -0.14170569235846975, "obs_min": -2.1677567175700423, "obs_max": 1.3559742269846529, "loss": 0.2987980842590332, "mae": 2.6486892700195312, "mean_q": 5.907977104187012, "_runtime": 590.0723118782043, "_timestamp": 1582185423.4457936, "_step": 96}
{"step": 962, "episode": 98, "duration": 0.07452729999999974, "episode_steps": 11, "sps": 147.59692085987334, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.1077780707680248, "obs_min": -2.0442286420184015, "obs_max": 1.3949343578703726, "loss": 0.341337651014328, "mae": 2.6514506340026855, "mean_q": 5.711686134338379, "_runtime": 590.1660373210907, "_timestamp": 1582185423.539519, "_step": 97}
{"step": 972, "episode": 99, "duration": 0.08921509999993305, "episode_steps": 10, "sps": 112.08864867054461, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.12198672479113988, "obs_min": -2.1162853322109334, "obs_max": 1.3589873254368083, "loss": 0.32220545411109924, "mae": 2.6524593830108643, "mean_q": 5.70926570892334, "_runtime": 590.2754232883453, "_timestamp": 1582185423.648905, "_step": 98}
{"step": 981, "episode": 100, "duration": 0.06959919999997055, "episode_steps": 9, "sps": 129.31183117052794, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.1718959152024707, "obs_min": -2.3106314585047127, "obs_max": 1.3325489248863824, "loss": 0.27287551760673523, "mae": 2.6626698970794678, "mean_q": 5.807858943939209, "_runtime": 590.3535273075104, "_timestamp": 1582185423.727009, "_step": 99}
{"step": 990, "episode": 101, "duration": 0.06142660000000433, "episode_steps": 9, "sps": 146.51633005895437, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.15128826824416627, "obs_min": -2.190253078095514, "obs_max": 1.3777976215241097, "loss": 0.37689128518104553, "mae": 2.673434257507324, "mean_q": 5.64178466796875, "_runtime": 590.431661605835, "_timestamp": 1582185423.8051434, "_step": 100}
{"step": 1003, "episode": 102, "duration": 0.14419170000007853, "episode_steps": 13, "sps": 90.1577552660307, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6923076923076923, "action_min": 0, "action_max": 1, "obs_mean": -0.11659354278713122, "obs_min": -2.039904180715437, "obs_max": 1.1699022078610266, "loss": 0.26018089056015015, "mae": 2.652395725250244, "mean_q": 5.735910415649414, "_runtime": 590.5878863334656, "_timestamp": 1582185423.961368, "_step": 101}
{"step": 1014, "episode": 103, "duration": 0.07609119999995073, "episode_steps": 11, "sps": 144.56336606607758, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8181818181818182, "action_min": 0, "action_max": 1, "obs_mean": -0.1086367562212493, "obs_min": -2.3174783771041274, "obs_max": 1.3834454263282077, "loss": 0.29028189182281494, "mae": 2.7052865028381348, "mean_q": 5.834898471832275, "_runtime": 590.6816263198853, "_timestamp": 1582185424.055108, "_step": 102}
{"step": 1024, "episode": 104, "duration": 0.07105870000009418, "episode_steps": 10, "sps": 140.7287214653061, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.12737308761357274, "obs_min": -2.4367823494565664, "obs_max": 1.565501040938399, "loss": 0.2717808187007904, "mae": 2.708498477935791, "mean_q": 5.886904716491699, "_runtime": 590.759744644165, "_timestamp": 1582185424.1332264, "_step": 103}
{"step": 1033, "episode": 105, "duration": 0.09417949999999564, "episode_steps": 9, "sps": 95.5621977181915, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.14873126857119182, "obs_min": -2.2033799670120935, "obs_max": 1.3539097446381916, "loss": 0.30831894278526306, "mae": 2.712272882461548, "mean_q": 5.821675777435303, "_runtime": 590.8691124916077, "_timestamp": 1582185424.2425942, "_step": 104}
{"step": 1042, "episode": 106, "duration": 0.06383219999997891, "episode_steps": 9, "sps": 140.9946704015054, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.14513635322973445, "obs_min": -2.1682687720458236, "obs_max": 1.3629591962412044, "loss": 0.2724151313304901, "mae": 2.7462587356567383, "mean_q": 6.009859085083008, "_runtime": 590.9472320079803, "_timestamp": 1582185424.3207138, "_step": 105}
{"step": 1051, "episode": 107, "duration": 0.05950370000005023, "episode_steps": 9, "sps": 151.2510986710474, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.11625567130490426, "obs_min": -2.1205184340007586, "obs_max": 1.3838534692684819, "loss": 0.29611900448799133, "mae": 2.6964821815490723, "mean_q": 5.765140056610107, "_runtime": 591.0253536701202, "_timestamp": 1582185424.3988354, "_step": 106}
{"step": 1061, "episode": 108, "duration": 0.07865089999995689, "episode_steps": 10, "sps": 127.14412676784984, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7, "action_min": 0, "action_max": 1, "obs_mean": -0.08887505719449265, "obs_min": -1.849859145954356, "obs_max": 1.2182704289182085, "loss": 0.2618798315525055, "mae": 2.7503292560577393, "mean_q": 5.995100975036621, "_runtime": 591.1190955638885, "_timestamp": 1582185424.4925773, "_step": 107}
{"step": 1072, "episode": 109, "duration": 0.06988019999994322, "episode_steps": 11, "sps": 157.41225697706844, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.1036422964659978, "obs_min": -2.2771318145262827, "obs_max": 1.5940390781742293, "loss": 0.2794804275035858, "mae": 2.774106740951538, "mean_q": 6.004393100738525, "_runtime": 591.1972343921661, "_timestamp": 1582185424.5707161, "_step": 108}
{"step": 1083, "episode": 110, "duration": 0.11053579999997964, "episode_steps": 11, "sps": 99.51527016588314, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.13350062127510862, "obs_min": -2.1623777205652166, "obs_max": 1.371955991973198, "loss": 0.21743139624595642, "mae": 2.744915246963501, "mean_q": 5.938531398773193, "_runtime": 591.3222215175629, "_timestamp": 1582185424.6957033, "_step": 109}
{"step": 1094, "episode": 111, "duration": 0.07209000000000287, "episode_steps": 11, "sps": 152.58704397280567, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.11392230112421388, "obs_min": -2.118065294918562, "obs_max": 1.3573890570131668, "loss": 0.27792802453041077, "mae": 2.8218674659729004, "mean_q": 6.026893138885498, "_runtime": 591.4003276824951, "_timestamp": 1582185424.7738094, "_step": 110}
{"step": 1103, "episode": 112, "duration": 0.0820641999999907, "episode_steps": 9, "sps": 109.67023379257971, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.130616902108643, "obs_min": -1.9389127910707913, "obs_max": 1.1964490267247943, "loss": 0.2724137306213379, "mae": 2.8388257026672363, "mean_q": 6.006993293762207, "_runtime": 591.5097141265869, "_timestamp": 1582185424.8831959, "_step": 111}
{"step": 1113, "episode": 113, "duration": 0.08046779999995124, "episode_steps": 10, "sps": 124.27331180927104, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7, "action_min": 0, "action_max": 1, "obs_mean": -0.10182882432054499, "obs_min": -2.100089278441839, "obs_max": 1.393553401400704, "loss": 0.28528422117233276, "mae": 2.898625373840332, "mean_q": 6.1422953605651855, "_runtime": 591.6034390926361, "_timestamp": 1582185424.9769208, "_step": 112}
{"step": 1124, "episode": 114, "duration": 0.06999309999991965, "episode_steps": 11, "sps": 157.15834846595774, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.13323157972655528, "obs_min": -2.078154628967614, "obs_max": 1.3330908806521697, "loss": 0.2426830679178238, "mae": 2.7972919940948486, "mean_q": 5.900946140289307, "_runtime": 591.6815752983093, "_timestamp": 1582185425.055057, "_step": 113}
{"step": 1135, "episode": 115, "duration": 0.06856679999998505, "episode_steps": 11, "sps": 160.42749552264942, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.13749983055784493, "obs_min": -2.124247689683144, "obs_max": 1.3329970809766845, "loss": 0.24869252741336823, "mae": 2.8863155841827393, "mean_q": 6.159565448760986, "_runtime": 591.7596955299377, "_timestamp": 1582185425.1331773, "_step": 114}
{"step": 1146, "episode": 116, "duration": 0.07177630000001045, "episode_steps": 11, "sps": 153.2539292217403, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.11426016061421555, "obs_min": -2.0846719278451458, "obs_max": 1.3389677837686333, "loss": 0.23072510957717896, "mae": 2.8461849689483643, "mean_q": 6.022829055786133, "_runtime": 591.8377976417542, "_timestamp": 1582185425.2112794, "_step": 115}
{"step": 1155, "episode": 117, "duration": 0.06936590000009346, "episode_steps": 9, "sps": 129.74674876254576, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6666666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.13923272243078164, "obs_min": -1.9129854283695717, "obs_max": 1.1843348103420444, "loss": 0.28166642785072327, "mae": 2.8943724632263184, "mean_q": 6.029062747955322, "_runtime": 591.9315512180328, "_timestamp": 1582185425.305033, "_step": 116}
{"step": 1164, "episode": 118, "duration": 0.1436221999999816, "episode_steps": 9, "sps": 62.664407034575106, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.14559730296261347, "obs_min": -1.9411581990397422, "obs_max": 1.1519464170932783, "loss": 0.21957087516784668, "mae": 2.802639961242676, "mean_q": 5.85191011428833, "_runtime": 592.0878109931946, "_timestamp": 1582185425.4612927, "_step": 117}
{"step": 1172, "episode": 119, "duration": 0.054932000000007974, "episode_steps": 8, "sps": 145.63460278159977, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.875, "action_min": 0, "action_max": 1, "obs_mean": -0.15382857535050165, "obs_min": -2.2343285058705726, "obs_max": 1.3818079668899206, "loss": 0.21660462021827698, "mae": 2.9308266639709473, "mean_q": 6.21842622756958, "_runtime": 592.1502954959869, "_timestamp": 1582185425.5237772, "_step": 118}
{"step": 1180, "episode": 120, "duration": 0.05505669999990914, "episode_steps": 8, "sps": 145.30474946760708, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.75, "action_min": 0, "action_max": 1, "obs_mean": -0.12966313515979677, "obs_min": -1.8960710386467066, "obs_max": 1.219351342537824, "loss": 0.3221126198768616, "mae": 2.8803303241729736, "mean_q": 5.928346633911133, "_runtime": 592.2283980846405, "_timestamp": 1582185425.6018798, "_step": 119}
{"step": 1189, "episode": 121, "duration": 0.07828229999995528, "episode_steps": 9, "sps": 114.96851778761152, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.1571945241467988, "obs_min": -2.1734754322017587, "obs_max": 1.3336054634314465, "loss": 0.22194677591323853, "mae": 2.8814616203308105, "mean_q": 6.064766883850098, "_runtime": 592.3221397399902, "_timestamp": 1582185425.6956215, "_step": 120}
{"step": 1201, "episode": 122, "duration": 0.07594950000009248, "episode_steps": 12, "sps": 157.99972350029148, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6666666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.099340125216405, "obs_min": -2.082437684989859, "obs_max": 1.354289580474013, "loss": 0.22666747868061066, "mae": 2.9415502548217773, "mean_q": 6.138990879058838, "_runtime": 592.4158821105957, "_timestamp": 1582185425.7893639, "_step": 121}
{"step": 1209, "episode": 123, "duration": 0.05106150000005982, "episode_steps": 8, "sps": 156.67381490928835, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.875, "action_min": 0, "action_max": 1, "obs_mean": -0.1570956590511805, "obs_min": -2.1878383791372435, "obs_max": 1.332231574679043, "loss": 0.15261149406433105, "mae": 2.9797298908233643, "mean_q": 6.291635036468506, "_runtime": 592.4783957004547, "_timestamp": 1582185425.8518775, "_step": 122}
{"step": 1220, "episode": 124, "duration": 0.07533560000001671, "episode_steps": 11, "sps": 146.01330579430655, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.11600151874890875, "obs_min": -2.2973124708278743, "obs_max": 1.5613258974691995, "loss": 0.1983691155910492, "mae": 2.940638542175293, "mean_q": 6.1219162940979, "_runtime": 592.5564959049225, "_timestamp": 1582185425.9299777, "_step": 123}
{"step": 1230, "episode": 125, "duration": 0.0646907000000283, "episode_steps": 10, "sps": 154.58172503923478, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7, "action_min": 0, "action_max": 1, "obs_mean": -0.12774800215307025, "obs_min": -2.1152790782126143, "obs_max": 1.3638799603378946, "loss": 0.24211056530475616, "mae": 2.9815032482147217, "mean_q": 6.234841346740723, "_runtime": 592.6502392292023, "_timestamp": 1582185426.023721, "_step": 124}
{"step": 1238, "episode": 126, "duration": 0.10308229999998275, "episode_steps": 8, "sps": 77.60789194654502, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.75, "action_min": 0, "action_max": 1, "obs_mean": -0.14150850338858256, "obs_min": -1.9118806066113851, "obs_max": 1.2036912676682303, "loss": 0.2581235468387604, "mae": 2.9513373374938965, "mean_q": 6.091818809509277, "_runtime": 592.7596123218536, "_timestamp": 1582185426.133094, "_step": 125}
{"step": 1247, "episode": 127, "duration": 0.06272720000004028, "episode_steps": 9, "sps": 143.47842722127274, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6666666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.12018653936194704, "obs_min": -1.64797148524302, "obs_max": 1.0163515475894767, "loss": 0.22629046440124512, "mae": 2.8750991821289062, "mean_q": 5.926468849182129, "_runtime": 592.8377358913422, "_timestamp": 1582185426.2112176, "_step": 126}
{"step": 1258, "episode": 128, "duration": 0.08976270000005115, "episode_steps": 11, "sps": 122.54533341793118, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.10173993704696584, "obs_min": -2.0376426601569912, "obs_max": 1.4120577017488611, "loss": 0.20056015253067017, "mae": 2.9448752403259277, "mean_q": 6.084070205688477, "_runtime": 592.9471015930176, "_timestamp": 1582185426.3205833, "_step": 127}
{"step": 1270, "episode": 129, "duration": 0.16933389999996962, "episode_steps": 12, "sps": 70.86590458261549, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6666666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.11451404897448865, "obs_min": -2.0295844487026926, "obs_max": 1.3468991288017973, "loss": 0.1773623675107956, "mae": 3.106679916381836, "mean_q": 6.435251712799072, "_runtime": 593.1345827579498, "_timestamp": 1582185426.5080645, "_step": 128}
{"step": 1282, "episode": 130, "duration": 0.13040699999999106, "episode_steps": 12, "sps": 92.01960017484355, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5833333333333334, "action_min": 0, "action_max": 1, "obs_mean": -0.09899775976308495, "obs_min": -1.7686290129111701, "obs_max": 1.1501464872267324, "loss": 0.21259339153766632, "mae": 3.048124313354492, "mean_q": 6.178112506866455, "_runtime": 593.275208234787, "_timestamp": 1582185426.64869, "_step": 129}
{"step": 1292, "episode": 131, "duration": 0.12373160000004191, "episode_steps": 10, "sps": 80.82009769530671, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6, "action_min": 0, "action_max": 1, "obs_mean": -0.12548766013411863, "obs_min": -1.7933821632167186, "obs_max": 1.1536533836273128, "loss": 0.17104336619377136, "mae": 3.13848614692688, "mean_q": 6.358958721160889, "_runtime": 593.4158132076263, "_timestamp": 1582185426.789295, "_step": 130}
{"step": 1305, "episode": 132, "duration": 0.07844979999993029, "episode_steps": 13, "sps": 165.71106618514708, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5384615384615384, "action_min": 0, "action_max": 1, "obs_mean": -0.0781843102565116, "obs_min": -1.46188107644099, "obs_max": 0.990643939170368, "loss": 0.23041439056396484, "mae": 3.1371357440948486, "mean_q": 6.280850410461426, "_runtime": 593.5095794200897, "_timestamp": 1582185426.8830612, "_step": 131}
{"step": 1317, "episode": 133, "duration": 0.0738439000000426, "episode_steps": 12, "sps": 162.50495978669974, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5833333333333334, "action_min": 0, "action_max": 1, "obs_mean": -0.09366270601286197, "obs_min": -1.7560443539400956, "obs_max": 1.201302239218358, "loss": 0.27439209818840027, "mae": 3.152196168899536, "mean_q": 6.243868350982666, "_runtime": 593.5876743793488, "_timestamp": 1582185426.9611561, "_step": 132}
{"step": 1327, "episode": 134, "duration": 0.06793590000006589, "episode_steps": 10, "sps": 147.19757889407958, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6, "action_min": 0, "action_max": 1, "obs_mean": -0.1156775617875511, "obs_min": -1.8080543934236024, "obs_max": 1.1948696191009347, "loss": 0.22304406762123108, "mae": 3.132338285446167, "mean_q": 6.2216386795043945, "_runtime": 593.6814186573029, "_timestamp": 1582185427.0549004, "_step": 133}
{"step": 1337, "episode": 135, "duration": 0.06313350000004903, "episode_steps": 10, "sps": 158.39451321393926, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6, "action_min": 0, "action_max": 1, "obs_mean": -0.12666778652304644, "obs_min": -1.5749807202055548, "obs_max": 0.9637099009871726, "loss": 0.2959218919277191, "mae": 3.1669507026672363, "mean_q": 6.213876247406006, "_runtime": 593.7595570087433, "_timestamp": 1582185427.1330388, "_step": 134}
{"step": 1350, "episode": 136, "duration": 0.11122560000001158, "episode_steps": 13, "sps": 116.87956729384824, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6153846153846154, "action_min": 0, "action_max": 1, "obs_mean": -0.1158147071313038, "obs_min": -1.7681850876230347, "obs_max": 1.1299485273918117, "loss": 0.21157918870449066, "mae": 3.214871406555176, "mean_q": 6.376652717590332, "_runtime": 593.8845355510712, "_timestamp": 1582185427.2580173, "_step": 135}
{"step": 1362, "episode": 137, "duration": 0.1880184999999983, "episode_steps": 12, "sps": 63.82350672939156, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5833333333333334, "action_min": 0, "action_max": 1, "obs_mean": -0.11684186249288825, "obs_min": -1.5428037164331072, "obs_max": 0.9814558232229138, "loss": 0.21937648952007294, "mae": 3.2677745819091797, "mean_q": 6.474447727203369, "_runtime": 594.0876398086548, "_timestamp": 1582185427.4611216, "_step": 136}
{"step": 1375, "episode": 138, "duration": 0.09834910000006403, "episode_steps": 13, "sps": 132.18219587155895, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5384615384615384, "action_min": 0, "action_max": 1, "obs_mean": -0.08963332303337221, "obs_min": -1.5076785539524438, "obs_max": 0.9998790846510175, "loss": 0.2775348424911499, "mae": 3.2066307067871094, "mean_q": 6.277397155761719, "_runtime": 594.1970100402832, "_timestamp": 1582185427.5704918, "_step": 137}
{"step": 1391, "episode": 139, "duration": 0.10199049999994259, "episode_steps": 16, "sps": 156.87735622444254, "episode_reward": 16.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5625, "action_min": 0, "action_max": 1, "obs_mean": -0.07613316094334895, "obs_min": -1.728168981832878, "obs_max": 1.1256075787092865, "loss": 0.17440825700759888, "mae": 3.1842050552368164, "mean_q": 6.305325508117676, "_runtime": 594.3063883781433, "_timestamp": 1582185427.6798701, "_step": 138}
{"step": 1400, "episode": 140, "duration": 0.08793529999991279, "episode_steps": 9, "sps": 102.3479762963102, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6666666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.12360851202570641, "obs_min": -1.512390320252178, "obs_max": 0.9809916157467868, "loss": 0.30181849002838135, "mae": 3.2901651859283447, "mean_q": 6.403886795043945, "_runtime": 594.4157419204712, "_timestamp": 1582185427.7892237, "_step": 139}
{"step": 1414, "episode": 141, "duration": 0.12421979999999166, "episode_steps": 14, "sps": 112.70344985260755, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": -0.10279702434448622, "obs_min": -1.485845807282709, "obs_max": 0.9560684246928569, "loss": 0.21818788349628448, "mae": 3.288975238800049, "mean_q": 6.448435306549072, "_runtime": 594.5563604831696, "_timestamp": 1582185427.9298422, "_step": 140}
{"step": 1427, "episode": 142, "duration": 0.09571030000006431, "episode_steps": 13, "sps": 135.82655158317615, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5384615384615384, "action_min": 0, "action_max": 1, "obs_mean": -0.11093652136439759, "obs_min": -1.1180603642913702, "obs_max": 0.5820387919493757, "loss": 0.23414219915866852, "mae": 3.2820074558258057, "mean_q": 6.380928039550781, "_runtime": 594.6657495498657, "_timestamp": 1582185428.0392313, "_step": 141}
{"step": 1447, "episode": 143, "duration": 0.13151479999999083, "episode_steps": 20, "sps": 152.07413918434574, "episode_reward": 20.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": -0.04347244106492455, "obs_min": -1.366610421076479, "obs_max": 1.018223905600571, "loss": 0.24951419234275818, "mae": 3.3762004375457764, "mean_q": 6.548541069030762, "_runtime": 594.8063600063324, "_timestamp": 1582185428.1798418, "_step": 142}
{"step": 1464, "episode": 144, "duration": 0.10302059999992252, "episode_steps": 17, "sps": 165.01554058132825, "episode_reward": 17.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47058823529411764, "action_min": 0, "action_max": 1, "obs_mean": -0.09626856849230851, "obs_min": -1.4373332555694156, "obs_max": 0.9530398655335791, "loss": 0.27362629771232605, "mae": 3.350001096725464, "mean_q": 6.460429668426514, "_runtime": 594.9313502311707, "_timestamp": 1582185428.304832, "_step": 143}
{"step": 1525, "episode": 145, "duration": 0.38738760000001093, "episode_steps": 61, "sps": 157.46502985639776, "episode_reward": 61.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47540983606557374, "action_min": 0, "action_max": 1, "obs_mean": -0.11853670498126849, "obs_min": -1.5083086899911557, "obs_max": 1.6538871659229006, "loss": 0.265109121799469, "mae": 3.509943723678589, "mean_q": 6.732850551605225, "_runtime": 595.3375525474548, "_timestamp": 1582185428.7110343, "_step": 144}
{"step": 1545, "episode": 146, "duration": 0.11858789999996588, "episode_steps": 20, "sps": 168.65127049223196, "episode_reward": 20.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.0035511948072219244, "obs_min": -2.348560687109383, "obs_max": 3.2508368517854267, "loss": 0.36722975969314575, "mae": 3.4723236560821533, "mean_q": 6.5704851150512695, "_runtime": 595.4625513553619, "_timestamp": 1582185428.836033, "_step": 145}
{"step": 1565, "episode": 147, "duration": 0.1912110999999186, "episode_steps": 20, "sps": 104.59643817753528, "episode_reward": 20.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.028541761549083722, "obs_min": -2.367677917624638, "obs_max": 3.401739627664985, "loss": 0.21907658874988556, "mae": 3.661558151245117, "mean_q": 7.033581733703613, "_runtime": 595.6656670570374, "_timestamp": 1582185429.0391488, "_step": 146}
{"step": 1574, "episode": 148, "duration": 0.11078250000002754, "episode_steps": 9, "sps": 81.24026809286451, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.16397324265929406, "obs_min": -1.7595678842050895, "obs_max": 2.838503659404123, "loss": 0.2882547676563263, "mae": 3.5470094680786133, "mean_q": 6.757116317749023, "_runtime": 595.8062705993652, "_timestamp": 1582185429.1797523, "_step": 147}
{"step": 1584, "episode": 149, "duration": 0.10959639999998672, "episode_steps": 10, "sps": 91.24387297394087, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.13395485607694577, "obs_min": -1.9484185026210565, "obs_max": 2.9803911172783533, "loss": 1.2378147840499878, "mae": 3.800032377243042, "mean_q": 7.198732852935791, "_runtime": 595.9156403541565, "_timestamp": 1582185429.289122, "_step": 148}
{"step": 1594, "episode": 150, "duration": 0.06583929999999327, "episode_steps": 10, "sps": 151.88496840034784, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.11054061662675738, "obs_min": -1.5760030485404581, "obs_max": 2.4833012739540097, "loss": 0.7837175130844116, "mae": 3.7308430671691895, "mean_q": 7.111921787261963, "_runtime": 595.9937787055969, "_timestamp": 1582185429.3672605, "_step": 149}
{"step": 1603, "episode": 151, "duration": 0.05634340000005977, "episode_steps": 9, "sps": 159.73476928957876, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1402849645090755, "obs_min": -1.7584334860051536, "obs_max": 2.7643545649433086, "loss": 0.6567790508270264, "mae": 3.7915408611297607, "mean_q": 7.239768981933594, "_runtime": 596.0718796253204, "_timestamp": 1582185429.4453614, "_step": 150}
{"step": 1674, "episode": 152, "duration": 0.41284730000006675, "episode_steps": 71, "sps": 171.97641839970498, "episode_reward": 71.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4788732394366197, "action_min": 0, "action_max": 1, "obs_mean": -0.10791466468722362, "obs_min": -1.5857372378629517, "obs_max": 1.868594831130097, "loss": 0.6595247983932495, "mae": 3.898362398147583, "mean_q": 7.392360687255859, "_runtime": 596.493723154068, "_timestamp": 1582185429.867205, "_step": 151}
{"step": 1686, "episode": 153, "duration": 0.07389960000000428, "episode_steps": 12, "sps": 162.38247568321486, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.25, "action_min": 0, "action_max": 1, "obs_mean": 0.12118940258165739, "obs_min": -1.5573027291924035, "obs_max": 2.4476661564074895, "loss": 0.5787844061851501, "mae": 3.8841516971588135, "mean_q": 7.3885650634765625, "_runtime": 596.5874862670898, "_timestamp": 1582185429.960968, "_step": 152}
{"step": 1696, "episode": 154, "duration": 0.06186930000001212, "episode_steps": 10, "sps": 161.63105126448886, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.12064848903572938, "obs_min": -1.3919955568986202, "obs_max": 2.0870575455238596, "loss": 1.1522891521453857, "mae": 4.07378625869751, "mean_q": 7.692739963531494, "_runtime": 596.6656057834625, "_timestamp": 1582185430.0390875, "_step": 153}
{"step": 1712, "episode": 155, "duration": 0.10383480000007239, "episode_steps": 16, "sps": 154.09092134803404, "episode_reward": 16.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": 0.09755312224229479, "obs_min": -0.5820037305351629, "obs_max": 1.058658067215381, "loss": 0.9578688740730286, "mae": 4.102408409118652, "mean_q": 7.797745704650879, "_runtime": 596.7749726772308, "_timestamp": 1582185430.1484544, "_step": 154}
{"step": 1724, "episode": 156, "duration": 0.07488239999997859, "episode_steps": 12, "sps": 160.2512739976741, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4166666666666667, "action_min": 0, "action_max": 1, "obs_mean": 0.10232248021720765, "obs_min": -1.1913725091399514, "obs_max": 1.7992811998761282, "loss": 1.4938331842422485, "mae": 4.182993412017822, "mean_q": 7.848026752471924, "_runtime": 596.8687012195587, "_timestamp": 1582185430.242183, "_step": 155}
{"step": 1746, "episode": 157, "duration": 0.2362805999999864, "episode_steps": 22, "sps": 93.10963320730211, "episode_reward": 22.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5454545454545454, "action_min": 0, "action_max": 1, "obs_mean": 0.11492648479918682, "obs_min": -0.6093103047446846, "obs_max": 0.970337702092479, "loss": 0.814689040184021, "mae": 4.205134868621826, "mean_q": 7.9734649658203125, "_runtime": 597.118691444397, "_timestamp": 1582185430.4921732, "_step": 156}
{"step": 1769, "episode": 158, "duration": 0.14039160000004358, "episode_steps": 23, "sps": 163.82746546084567, "episode_reward": 23.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4782608695652174, "action_min": 0, "action_max": 1, "obs_mean": 0.07337557202970238, "obs_min": -0.40183897187322154, "obs_max": 1.0275905350622236, "loss": 1.3203704357147217, "mae": 4.293702602386475, "mean_q": 8.10827350616455, "_runtime": 597.2749395370483, "_timestamp": 1582185430.6484213, "_step": 157}
{"step": 1779, "episode": 159, "duration": 0.06882050000001527, "episode_steps": 10, "sps": 145.30554122678245, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.12482358474449895, "obs_min": -0.7634066262802739, "obs_max": 1.4898910734385742, "loss": 0.35276705026626587, "mae": 4.170395851135254, "mean_q": 7.96382999420166, "_runtime": 597.3530576229095, "_timestamp": 1582185430.7265394, "_step": 158}
{"step": 1794, "episode": 160, "duration": 0.15499260000001414, "episode_steps": 15, "sps": 96.77881395627038, "episode_reward": 15.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4, "action_min": 0, "action_max": 1, "obs_mean": 0.10088722016074464, "obs_min": -0.9254905004192815, "obs_max": 1.4844194717886454, "loss": 0.41802510619163513, "mae": 4.375842571258545, "mean_q": 8.397333145141602, "_runtime": 597.52490401268, "_timestamp": 1582185430.8983858, "_step": 159}
{"step": 1803, "episode": 161, "duration": 0.07427930000005745, "episode_steps": 9, "sps": 121.16430822575118, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.1470677026466369, "obs_min": -0.9917419535606413, "obs_max": 1.6657593484102318, "loss": 1.516649603843689, "mae": 4.500556945800781, "mean_q": 8.519059181213379, "_runtime": 597.6186649799347, "_timestamp": 1582185430.9921467, "_step": 160}
{"step": 1812, "episode": 162, "duration": 0.057182300000022224, "episode_steps": 9, "sps": 157.39136061327548, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.15054496525456496, "obs_min": -0.9608695482712952, "obs_max": 1.6478201113592965, "loss": 1.778839111328125, "mae": 4.416292667388916, "mean_q": 8.278044700622559, "_runtime": 597.6811628341675, "_timestamp": 1582185431.0546446, "_step": 161}
{"step": 1824, "episode": 163, "duration": 0.07287690000009661, "episode_steps": 12, "sps": 164.6612301015012, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.25, "action_min": 0, "action_max": 1, "obs_mean": 0.11275873601122915, "obs_min": -1.4091634402788473, "obs_max": 2.18100563035312, "loss": 0.7460344433784485, "mae": 4.3713483810424805, "mean_q": 8.250598907470703, "_runtime": 597.7749035358429, "_timestamp": 1582185431.1483853, "_step": 162}
{"step": 1834, "episode": 164, "duration": 0.07046539999998913, "episode_steps": 10, "sps": 141.91362001778947, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.15612593202056146, "obs_min": -1.5466251791877286, "obs_max": 2.6131162420024823, "loss": 1.1680868864059448, "mae": 4.420764923095703, "mean_q": 8.33436107635498, "_runtime": 597.8530039787292, "_timestamp": 1582185431.2264857, "_step": 163}
{"step": 1843, "episode": 165, "duration": 0.05693599999995058, "episode_steps": 9, "sps": 158.07222144175586, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.12608426781955456, "obs_min": -1.786065092300571, "obs_max": 2.7826551579844545, "loss": 2.2513015270233154, "mae": 4.578253269195557, "mean_q": 8.544443130493164, "_runtime": 597.9311237335205, "_timestamp": 1582185431.3046055, "_step": 164}
{"step": 1852, "episode": 166, "duration": 0.1453946999999971, "episode_steps": 9, "sps": 61.900468173875524, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.15423684350071193, "obs_min": -1.8120851418033121, "obs_max": 2.879305965997507, "loss": 2.3526790142059326, "mae": 4.595086097717285, "mean_q": 8.529260635375977, "_runtime": 598.0874025821686, "_timestamp": 1582185431.4608843, "_step": 165}
{"step": 1863, "episode": 167, "duration": 0.07234719999996742, "episode_steps": 11, "sps": 152.04458500128484, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.18181818181818182, "action_min": 0, "action_max": 1, "obs_mean": 0.11546643644116988, "obs_min": -1.3622570205420925, "obs_max": 2.2754467022331637, "loss": 1.641203761100769, "mae": 4.61378812789917, "mean_q": 8.6279878616333, "_runtime": 598.1811060905457, "_timestamp": 1582185431.5545878, "_step": 166}
{"step": 1873, "episode": 168, "duration": 0.06197650000001431, "episode_steps": 10, "sps": 161.35147999641302, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.16318271963204015, "obs_min": -1.913590131541398, "obs_max": 3.092910894563708, "loss": 1.35990309715271, "mae": 4.7814154624938965, "mean_q": 9.041379928588867, "_runtime": 598.259245634079, "_timestamp": 1582185431.6327274, "_step": 167}
{"step": 1883, "episode": 169, "duration": 0.06633279999994102, "episode_steps": 10, "sps": 150.75498094470447, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.11835339889181391, "obs_min": -1.7646307099248948, "obs_max": 2.668669415373097, "loss": 1.6121928691864014, "mae": 4.744680404663086, "mean_q": 8.865673065185547, "_runtime": 598.3373444080353, "_timestamp": 1582185431.7108262, "_step": 168}
{"step": 1893, "episode": 170, "duration": 0.12108569999998053, "episode_steps": 10, "sps": 82.58613527445114, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.14293784752890765, "obs_min": -1.5466505092616438, "obs_max": 2.527430146468662, "loss": 1.3096119165420532, "mae": 4.743963718414307, "mean_q": 8.96485710144043, "_runtime": 598.4779648780823, "_timestamp": 1582185431.8514466, "_step": 169}
{"step": 1902, "episode": 171, "duration": 0.12452440000004117, "episode_steps": 9, "sps": 72.27499188911591, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.13138343337132508, "obs_min": -1.7974598025444068, "obs_max": 2.771906214731298, "loss": 2.127605676651001, "mae": 4.812323570251465, "mean_q": 9.067973136901855, "_runtime": 598.618579864502, "_timestamp": 1582185431.9920616, "_step": 170}
{"step": 1911, "episode": 172, "duration": 0.057130099999994854, "episode_steps": 9, "sps": 157.53516972665565, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.16847135102325195, "obs_min": -1.723985545034049, "obs_max": 2.8318832063728556, "loss": 1.928880214691162, "mae": 4.677370071411133, "mean_q": 8.8348970413208, "_runtime": 598.6810712814331, "_timestamp": 1582185432.054553, "_step": 171}
{"step": 1923, "episode": 173, "duration": 0.07453210000005583, "episode_steps": 12, "sps": 161.0044531147118, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.08333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.1204897088317352, "obs_min": -1.906999263076408, "obs_max": 2.9742183500274395, "loss": 1.6993328332901, "mae": 4.739356517791748, "mean_q": 8.847540855407715, "_runtime": 598.7748146057129, "_timestamp": 1582185432.1482964, "_step": 172}
{"step": 1932, "episode": 174, "duration": 0.1061638999999559, "episode_steps": 9, "sps": 84.77457968295944, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.1127098428498012, "obs_min": -1.424565662722141, "obs_max": 2.2721710242700097, "loss": 2.93916916847229, "mae": 4.938562393188477, "mean_q": 9.137154579162598, "_runtime": 598.8842074871063, "_timestamp": 1582185432.2576892, "_step": 173}
{"step": 1940, "episode": 175, "duration": 0.05178790000002209, "episode_steps": 8, "sps": 154.47623865799903, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.14907793724253793, "obs_min": -1.5428346937472996, "obs_max": 2.560153061580482, "loss": 2.1150550842285156, "mae": 4.719856262207031, "mean_q": 8.773356437683105, "_runtime": 598.962320804596, "_timestamp": 1582185432.3358026, "_step": 174}
{"step": 1950, "episode": 176, "duration": 0.061936099999911676, "episode_steps": 10, "sps": 161.45672717549635, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.11312319621105975, "obs_min": -1.9746020635520702, "obs_max": 2.987473817293793, "loss": 3.065263509750366, "mae": 5.071053504943848, "mean_q": 9.274080276489258, "_runtime": 599.0247976779938, "_timestamp": 1582185432.3982794, "_step": 175}
{"step": 1960, "episode": 177, "duration": 0.06391849999999977, "episode_steps": 10, "sps": 156.4492283141819, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.15611924545356576, "obs_min": -1.9369991615522313, "obs_max": 3.054179467434988, "loss": 1.2280628681182861, "mae": 4.787814140319824, "mean_q": 8.94944953918457, "_runtime": 599.1029372215271, "_timestamp": 1582185432.476419, "_step": 176}
{"step": 1968, "episode": 178, "duration": 0.054574099999967984, "episode_steps": 8, "sps": 146.58968265174676, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.14477216759362987, "obs_min": -1.5811847243375374, "obs_max": 2.54056748775442, "loss": 2.9154388904571533, "mae": 4.855756759643555, "mean_q": 8.797679901123047, "_runtime": 599.1810371875763, "_timestamp": 1582185432.554519, "_step": 177}
{"step": 1976, "episode": 179, "duration": 0.05884660000003805, "episode_steps": 8, "sps": 135.94668171134487, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.125, "action_min": 0, "action_max": 1, "obs_mean": 0.13733705909643057, "obs_min": -1.3739699437983162, "obs_max": 2.177936822032317, "loss": 1.996726155281067, "mae": 4.768514633178711, "mean_q": 8.76869010925293, "_runtime": 599.259156703949, "_timestamp": 1582185432.6326385, "_step": 178}
{"step": 1988, "episode": 180, "duration": 0.08920270000010078, "episode_steps": 12, "sps": 134.52507603454202, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.10911070578908937, "obs_min": -1.3496841230173202, "obs_max": 1.9936507006194588, "loss": 0.9486977458000183, "mae": 4.637935638427734, "mean_q": 8.610695838928223, "_runtime": 599.3529014587402, "_timestamp": 1582185432.7263832, "_step": 179}
{"step": 1998, "episode": 181, "duration": 0.06848389999993287, "episode_steps": 10, "sps": 146.0197214237186, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.13955867193980684, "obs_min": -1.540195929989103, "obs_max": 2.519058163131765, "loss": 1.6908385753631592, "mae": 4.657998085021973, "mean_q": 8.661626815795898, "_runtime": 599.4310402870178, "_timestamp": 1582185432.804522, "_step": 180}
{"step": 2008, "episode": 182, "duration": 0.06159279999997125, "episode_steps": 10, "sps": 162.35663908776135, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.13028310777790708, "obs_min": -1.7945338271410582, "obs_max": 2.7414680187455622, "loss": 2.3839688301086426, "mae": 4.8738179206848145, "mean_q": 9.071011543273926, "_runtime": 599.5091590881348, "_timestamp": 1582185432.8826408, "_step": 181}
{"step": 2020, "episode": 183, "duration": 0.07729640000002291, "episode_steps": 12, "sps": 155.24655740754346, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.08333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.12219357567185112, "obs_min": -1.9703808115355623, "obs_max": 3.04144618868075, "loss": 1.903168797492981, "mae": 4.9598307609558105, "mean_q": 9.290435791015625, "_runtime": 599.6028845310211, "_timestamp": 1582185432.9763663, "_step": 182}
{"step": 2030, "episode": 184, "duration": 0.11966039999992972, "episode_steps": 10, "sps": 83.56983596917505, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.10629545595772676, "obs_min": -1.8058858225080958, "obs_max": 2.6428774796290457, "loss": 1.836918592453003, "mae": 5.041970252990723, "mean_q": 9.4891939163208, "_runtime": 599.7435047626495, "_timestamp": 1582185433.1169865, "_step": 183}
{"step": 2039, "episode": 185, "duration": 0.0628650999999536, "episode_steps": 9, "sps": 143.1636949596301, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1650537324323831, "obs_min": -1.745681146171924, "obs_max": 2.8387050082457552, "loss": 2.864861011505127, "mae": 5.093636989593506, "mean_q": 9.42822265625, "_runtime": 599.8216171264648, "_timestamp": 1582185433.1950989, "_step": 184}
{"step": 2048, "episode": 186, "duration": 0.06452219999994213, "episode_steps": 9, "sps": 139.48687428525488, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1444257066779281, "obs_min": -1.7643332471115096, "obs_max": 2.84107892572971, "loss": 2.0307347774505615, "mae": 5.077932357788086, "mean_q": 9.53238582611084, "_runtime": 599.9153800010681, "_timestamp": 1582185433.2888618, "_step": 185}
{"step": 2058, "episode": 187, "duration": 0.06230410000000575, "episode_steps": 10, "sps": 160.50308085662223, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.11447092259382041, "obs_min": -1.748726200640834, "obs_max": 2.632050352355577, "loss": 2.469468593597412, "mae": 5.210999488830566, "mean_q": 9.644623756408691, "_runtime": 599.977876663208, "_timestamp": 1582185433.3513584, "_step": 186}
{"step": 2067, "episode": 188, "duration": 0.05850550000002386, "episode_steps": 9, "sps": 153.83169103753204, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.14171246199744422, "obs_min": -1.8014067085743903, "obs_max": 2.8090074259115982, "loss": 2.0522782802581787, "mae": 5.200824737548828, "mean_q": 9.685816764831543, "_runtime": 600.05597615242, "_timestamp": 1582185433.429458, "_step": 187}
{"step": 2075, "episode": 189, "duration": 0.0524232000000211, "episode_steps": 8, "sps": 152.60419051101002, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.16008209276750276, "obs_min": -1.5867908108665651, "obs_max": 2.5675769916068916, "loss": 3.9349799156188965, "mae": 5.118144512176514, "mean_q": 9.340475082397461, "_runtime": 600.1184916496277, "_timestamp": 1582185433.4919734, "_step": 188}
{"step": 2085, "episode": 190, "duration": 0.0941674000000603, "episode_steps": 10, "sps": 106.19386326896141, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.1155613396513407, "obs_min": -1.1515359436119608, "obs_max": 1.8500028594919613, "loss": 3.083406925201416, "mae": 5.142190933227539, "mean_q": 9.387855529785156, "_runtime": 600.2278587818146, "_timestamp": 1582185433.6013405, "_step": 189}
{"step": 2094, "episode": 191, "duration": 0.06096830000001319, "episode_steps": 9, "sps": 147.61769640941364, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.13489242720686537, "obs_min": -1.1758128030499706, "obs_max": 1.9261029526339806, "loss": 2.9650354385375977, "mae": 5.503652572631836, "mean_q": 10.04542064666748, "_runtime": 600.3059780597687, "_timestamp": 1582185433.6794598, "_step": 190}
{"step": 2104, "episode": 192, "duration": 0.06270919999997204, "episode_steps": 10, "sps": 159.46623461955275, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.12388075045577825, "obs_min": -1.3587812808495645, "obs_max": 2.132076983495632, "loss": 3.416726589202881, "mae": 5.116211891174316, "mean_q": 9.25822639465332, "_runtime": 600.3840985298157, "_timestamp": 1582185433.7575803, "_step": 191}
{"step": 2116, "episode": 193, "duration": 0.15826890000005278, "episode_steps": 12, "sps": 75.82032856736856, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.10336161710157, "obs_min": -1.1873755817952358, "obs_max": 1.7406782979510194, "loss": 2.3669400215148926, "mae": 5.097064018249512, "mean_q": 9.376008033752441, "_runtime": 600.5559537410736, "_timestamp": 1582185433.9294355, "_step": 192}
{"step": 2126, "episode": 194, "duration": 0.08976959999995415, "episode_steps": 10, "sps": 111.39628560230977, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.1162499914248051, "obs_min": -1.3942731580951322, "obs_max": 2.177931262340438, "loss": 3.0727875232696533, "mae": 5.142038345336914, "mean_q": 9.358118057250977, "_runtime": 600.6653118133545, "_timestamp": 1582185434.0387936, "_step": 193}
{"step": 2138, "episode": 195, "duration": 0.07445359999996981, "episode_steps": 12, "sps": 161.1742078288339, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.08333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.12208029793067927, "obs_min": -1.9050362694396543, "obs_max": 3.0035891003812343, "loss": 2.64997935295105, "mae": 5.277317047119141, "mean_q": 9.68287181854248, "_runtime": 600.7434303760529, "_timestamp": 1582185434.1169121, "_step": 194}
{"step": 2148, "episode": 196, "duration": 0.06686609999997017, "episode_steps": 10, "sps": 149.55261335720883, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.14811277572434467, "obs_min": -1.1353095987113377, "obs_max": 2.0678794365131665, "loss": 2.6664347648620605, "mae": 5.288407325744629, "mean_q": 9.82080078125, "_runtime": 600.8215637207031, "_timestamp": 1582185434.1950455, "_step": 195}
{"step": 2157, "episode": 197, "duration": 0.05729990000008911, "episode_steps": 9, "sps": 157.06833694275215, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.13989977051049646, "obs_min": -1.7829134845609216, "obs_max": 2.7639260496875058, "loss": 2.111971139907837, "mae": 5.295105934143066, "mean_q": 9.86169147491455, "_runtime": 600.8996679782867, "_timestamp": 1582185434.2731497, "_step": 196}
{"step": 2166, "episode": 198, "duration": 0.07818779999990966, "episode_steps": 9, "sps": 115.10747200983272, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.14729456683828207, "obs_min": -1.5934477583381386, "obs_max": 2.488922212524895, "loss": 2.1468570232391357, "mae": 5.229737758636475, "mean_q": 9.767461776733398, "_runtime": 600.9934213161469, "_timestamp": 1582185434.366903, "_step": 197}
{"step": 2175, "episode": 199, "duration": 0.06004229999996369, "episode_steps": 9, "sps": 149.8943245013173, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.17153698214973132, "obs_min": -1.541764082060231, "obs_max": 2.549470412050699, "loss": 1.4816837310791016, "mae": 5.153178691864014, "mean_q": 9.555938720703125, "_runtime": 601.0715305805206, "_timestamp": 1582185434.4450123, "_step": 198}
{"step": 2185, "episode": 200, "duration": 0.08221649999995861, "episode_steps": 10, "sps": 121.63008641823762, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.1484099241884113, "obs_min": -1.7896747363323218, "obs_max": 2.7559210488297015, "loss": 3.549042224884033, "mae": 5.520630836486816, "mean_q": 10.00309944152832, "_runtime": 601.1652941703796, "_timestamp": 1582185434.538776, "_step": 199}
{"step": 2193, "episode": 201, "duration": 0.05057340000007571, "episode_steps": 8, "sps": 158.18592382533157, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.14881578826995095, "obs_min": -1.5373806972401272, "obs_max": 2.5047617547629244, "loss": 1.106184959411621, "mae": 5.116420745849609, "mean_q": 9.63025188446045, "_runtime": 601.2277772426605, "_timestamp": 1582185434.601259, "_step": 200}
{"step": 2202, "episode": 202, "duration": 0.06166459999997187, "episode_steps": 9, "sps": 145.95083727136972, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.13927290958407157, "obs_min": -1.808836839703631, "obs_max": 2.787733135433291, "loss": 2.2922065258026123, "mae": 5.2269439697265625, "mean_q": 9.702287673950195, "_runtime": 601.3059096336365, "_timestamp": 1582185434.6793914, "_step": 201}
{"step": 2211, "episode": 203, "duration": 0.07932110000001558, "episode_steps": 9, "sps": 113.46287431715184, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.14789387012490782, "obs_min": -1.5718283389330476, "obs_max": 2.494641392552091, "loss": 3.2956669330596924, "mae": 5.487942695617676, "mean_q": 10.05225658416748, "_runtime": 601.3996348381042, "_timestamp": 1582185434.7731166, "_step": 202}
{"step": 2221, "episode": 204, "duration": 0.06931770000005599, "episode_steps": 10, "sps": 144.2632978300192, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.15888873965410594, "obs_min": -1.3235006431255036, "obs_max": 2.1841270228102747, "loss": 2.393939971923828, "mae": 5.3893866539001465, "mean_q": 9.932717323303223, "_runtime": 601.4777529239655, "_timestamp": 1582185434.8512347, "_step": 203}
{"step": 2230, "episode": 205, "duration": 0.07013419999998405, "episode_steps": 9, "sps": 128.32541042746686, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.1427209484981532, "obs_min": -1.2007361040255164, "obs_max": 1.969084144782956, "loss": 3.524348497390747, "mae": 5.54469633102417, "mean_q": 10.040385246276855, "_runtime": 601.5715153217316, "_timestamp": 1582185434.944997, "_step": 204}
{"step": 2239, "episode": 206, "duration": 0.06409739999992325, "episode_steps": 9, "sps": 140.4113115354254, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.16298454152292974, "obs_min": -1.324994317723401, "obs_max": 2.246250435220939, "loss": 2.0781443119049072, "mae": 5.215162754058838, "mean_q": 9.648819923400879, "_runtime": 601.6496212482452, "_timestamp": 1582185435.023103, "_step": 205}
{"step": 2248, "episode": 207, "duration": 0.07378209999990304, "episode_steps": 9, "sps": 121.98080564272131, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.1424399424977756, "obs_min": -1.3929510813762263, "obs_max": 2.2401444671944613, "loss": 3.2647485733032227, "mae": 5.4642767906188965, "mean_q": 9.880111694335938, "_runtime": 601.7277548313141, "_timestamp": 1582185435.1012366, "_step": 206}
{"step": 2258, "episode": 208, "duration": 0.067554800000039, "episode_steps": 10, "sps": 148.02797136538376, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.13044870274877715, "obs_min": -1.374524156267372, "obs_max": 2.1375553565200307, "loss": 2.6526970863342285, "mae": 5.47244930267334, "mean_q": 9.975502014160156, "_runtime": 601.8214988708496, "_timestamp": 1582185435.1949806, "_step": 207}
{"step": 2270, "episode": 209, "duration": 0.07289649999995618, "episode_steps": 12, "sps": 164.61695691846953, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.25, "action_min": 0, "action_max": 1, "obs_mean": 0.1357373775948024, "obs_min": -1.3268399133322224, "obs_max": 2.180949002414772, "loss": 1.9699832201004028, "mae": 5.359097957611084, "mean_q": 9.907881736755371, "_runtime": 601.899619102478, "_timestamp": 1582185435.2731009, "_step": 208}
{"step": 2282, "episode": 210, "duration": 0.07523200000002817, "episode_steps": 12, "sps": 159.5065929391151, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.16666666666666666, "action_min": 0, "action_max": 1, "obs_mean": 0.09993470366453726, "obs_min": -1.6166687026765425, "obs_max": 2.5799463674886813, "loss": 3.0487289428710938, "mae": 5.480288982391357, "mean_q": 10.069305419921875, "_runtime": 601.9933617115021, "_timestamp": 1582185435.3668435, "_step": 209}
{"step": 2292, "episode": 211, "duration": 0.08789779999995062, "episode_steps": 10, "sps": 113.76849022393755, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.13242517691125977, "obs_min": -1.5995676584503766, "obs_max": 2.3982084299583457, "loss": 2.6067728996276855, "mae": 5.248321056365967, "mean_q": 9.680047988891602, "_runtime": 602.1027219295502, "_timestamp": 1582185435.4762037, "_step": 210}
{"step": 2301, "episode": 212, "duration": 0.0784240000000409, "episode_steps": 9, "sps": 114.76078751396646, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.13354875210414932, "obs_min": -1.4156356948744664, "obs_max": 2.30880576605742, "loss": 2.443186044692993, "mae": 5.429953098297119, "mean_q": 9.992621421813965, "_runtime": 602.180830001831, "_timestamp": 1582185435.5543118, "_step": 211}
{"step": 2311, "episode": 213, "duration": 0.06427430000007917, "episode_steps": 10, "sps": 155.58318021336186, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.15965139386122076, "obs_min": -1.726322694234999, "obs_max": 2.7409883693661, "loss": 1.8687045574188232, "mae": 5.4102582931518555, "mean_q": 10.125356674194336, "_runtime": 602.2589678764343, "_timestamp": 1582185435.6324496, "_step": 212}
{"step": 2320, "episode": 214, "duration": 0.10166309999999612, "episode_steps": 9, "sps": 88.52769588966245, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.16303059248803442, "obs_min": -1.7484203288255662, "obs_max": 2.8434519127111417, "loss": 2.037741184234619, "mae": 5.444665908813477, "mean_q": 10.131576538085938, "_runtime": 602.3839421272278, "_timestamp": 1582185435.7574239, "_step": 213}
{"step": 2330, "episode": 215, "duration": 0.06646550000004936, "episode_steps": 10, "sps": 150.45399492958865, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.14452135650185244, "obs_min": -1.5359179499156834, "obs_max": 2.509595021304533, "loss": 1.357181191444397, "mae": 5.317358016967773, "mean_q": 10.035008430480957, "_runtime": 602.4620633125305, "_timestamp": 1582185435.835545, "_step": 214}
{"step": 2340, "episode": 216, "duration": 0.10466109999993023, "episode_steps": 10, "sps": 95.54648288625542, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.15268080976266712, "obs_min": -1.5701681399495133, "obs_max": 2.6292094083413047, "loss": 2.056042432785034, "mae": 5.407241344451904, "mean_q": 10.158535957336426, "_runtime": 602.5870704650879, "_timestamp": 1582185435.9605522, "_step": 215}
{"step": 2349, "episode": 217, "duration": 0.0641624000001002, "episode_steps": 9, "sps": 140.26906724165468, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.13445052914507857, "obs_min": -1.780505738635716, "obs_max": 2.768700254079677, "loss": 2.450712203979492, "mae": 5.634359359741211, "mean_q": 10.545686721801758, "_runtime": 602.6651861667633, "_timestamp": 1582185436.038668, "_step": 216}
{"step": 2361, "episode": 218, "duration": 0.15481130000000576, "episode_steps": 12, "sps": 77.51372154357954, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.16666666666666666, "action_min": 0, "action_max": 1, "obs_mean": 0.0999510999741706, "obs_min": -1.6091691717387726, "obs_max": 2.4486010599804215, "loss": 2.3362395763397217, "mae": 5.620908260345459, "mean_q": 10.510998725891113, "_runtime": 602.8370530605316, "_timestamp": 1582185436.2105348, "_step": 217}
{"step": 2371, "episode": 219, "duration": 0.1295886000000337, "episode_steps": 10, "sps": 77.16728168988168, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.1272312338711046, "obs_min": -1.7410885409313555, "obs_max": 2.6585688625441724, "loss": 2.134413003921509, "mae": 5.537650108337402, "mean_q": 10.38128662109375, "_runtime": 602.9776518344879, "_timestamp": 1582185436.3511336, "_step": 218}
{"step": 2381, "episode": 220, "duration": 0.06400320000000193, "episode_steps": 10, "sps": 156.24218789060077, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.14558092429196992, "obs_min": -1.7531458915113567, "obs_max": 2.7348911558790365, "loss": 1.6527210474014282, "mae": 5.393342971801758, "mean_q": 10.129573822021484, "_runtime": 603.0557703971863, "_timestamp": 1582185436.4292521, "_step": 219}
{"step": 2390, "episode": 221, "duration": 0.05566350000003695, "episode_steps": 9, "sps": 161.6858444042151, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.1407712777192946, "obs_min": -1.604916339493528, "obs_max": 2.50244653951797, "loss": 1.88486647605896, "mae": 5.507359981536865, "mean_q": 10.3792142868042, "_runtime": 603.1339061260223, "_timestamp": 1582185436.5073879, "_step": 220}
{"step": 2400, "episode": 222, "duration": 0.061832200000026205, "episode_steps": 10, "sps": 161.72803167274918, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.12877670492847668, "obs_min": -1.3848368514708636, "obs_max": 2.2112876570821625, "loss": 1.88629150390625, "mae": 5.428504943847656, "mean_q": 10.23830509185791, "_runtime": 603.1963834762573, "_timestamp": 1582185436.5698652, "_step": 221}
{"step": 2409, "episode": 223, "duration": 0.05897370000002411, "episode_steps": 9, "sps": 152.6104009074608, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.155445456028288, "obs_min": -1.717924183241855, "obs_max": 2.7705307509825596, "loss": 1.6209300756454468, "mae": 5.45590353012085, "mean_q": 10.366716384887695, "_runtime": 603.2745227813721, "_timestamp": 1582185436.6480045, "_step": 222}
{"step": 2418, "episode": 224, "duration": 0.05985590000000229, "episode_steps": 9, "sps": 150.3611172833364, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.12072048384207607, "obs_min": -1.586288268781889, "obs_max": 2.4435303353105824, "loss": 1.6607463359832764, "mae": 5.469263553619385, "mean_q": 10.417438507080078, "_runtime": 603.3526227474213, "_timestamp": 1582185436.7261045, "_step": 223}
{"step": 2432, "episode": 225, "duration": 0.08980939999992188, "episode_steps": 14, "sps": 155.88568679906757, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.21428571428571427, "action_min": 0, "action_max": 1, "obs_mean": 0.10352425270900363, "obs_min": -1.7096320487743617, "obs_max": 2.7116121417364063, "loss": 2.3758885860443115, "mae": 5.5265679359436035, "mean_q": 10.394989967346191, "_runtime": 603.4620101451874, "_timestamp": 1582185436.835492, "_step": 224}
{"step": 2440, "episode": 226, "duration": 0.052917399999955705, "episode_steps": 8, "sps": 151.17900728317522, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.125, "action_min": 0, "action_max": 1, "obs_mean": 0.1537279154836839, "obs_min": -1.372119576944215, "obs_max": 2.223475492864156, "loss": 0.9031804203987122, "mae": 5.481197357177734, "mean_q": 10.53205394744873, "_runtime": 603.5244858264923, "_timestamp": 1582185436.8979676, "_step": 225}
{"step": 2452, "episode": 227, "duration": 0.07274879999999939, "episode_steps": 12, "sps": 164.9511744523635, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.16666666666666666, "action_min": 0, "action_max": 1, "obs_mean": 0.10652234037077961, "obs_min": -1.7278424554606509, "obs_max": 2.639445782467186, "loss": 1.9604188203811646, "mae": 5.656009197235107, "mean_q": 10.654589653015137, "_runtime": 603.618250131607, "_timestamp": 1582185436.991732, "_step": 226}
{"step": 2462, "episode": 228, "duration": 0.10924169999998412, "episode_steps": 10, "sps": 91.54013531464133, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.1420589338026263, "obs_min": -1.7725569404062291, "obs_max": 2.712949443025747, "loss": 2.6294445991516113, "mae": 5.665139198303223, "mean_q": 10.529314994812012, "_runtime": 603.7432234287262, "_timestamp": 1582185437.1167052, "_step": 227}
{"step": 2472, "episode": 229, "duration": 0.06826839999996537, "episode_steps": 10, "sps": 146.48065576467403, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.14893979339949392, "obs_min": -1.738043990538592, "obs_max": 2.71566631735022, "loss": 2.1028010845184326, "mae": 5.469881534576416, "mean_q": 10.290495872497559, "_runtime": 603.8213605880737, "_timestamp": 1582185437.1948423, "_step": 228}
{"step": 2487, "episode": 230, "duration": 0.1480935000000727, "episode_steps": 15, "sps": 101.28736237574664, "episode_reward": 15.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.26666666666666666, "action_min": 0, "action_max": 1, "obs_mean": 0.0681686715584734, "obs_min": -1.4107303008012941, "obs_max": 2.2215641108931203, "loss": 2.371795654296875, "mae": 5.611589431762695, "mean_q": 10.469348907470703, "_runtime": 603.9775819778442, "_timestamp": 1582185437.3510637, "_step": 229}
{"step": 2502, "episode": 231, "duration": 0.09188910000000305, "episode_steps": 15, "sps": 163.240253740645, "episode_reward": 15.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.07478045657171287, "obs_min": -1.8061315637661388, "obs_max": 2.681369059011007, "loss": 3.220839262008667, "mae": 5.768362045288086, "mean_q": 10.650168418884277, "_runtime": 604.0869624614716, "_timestamp": 1582185437.4604442, "_step": 230}
{"step": 2510, "episode": 232, "duration": 0.05196180000007189, "episode_steps": 8, "sps": 153.95925468303508, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1673269533536837, "obs_min": -1.5374886671965209, "obs_max": 2.553083347569878, "loss": 1.9522145986557007, "mae": 5.50993537902832, "mean_q": 10.324882507324219, "_runtime": 604.1494617462158, "_timestamp": 1582185437.5229435, "_step": 231}
{"step": 2523, "episode": 233, "duration": 0.08754959999998846, "episode_steps": 13, "sps": 148.48725750890597, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.15384615384615385, "action_min": 0, "action_max": 1, "obs_mean": 0.08394495095852107, "obs_min": -1.8000682340043785, "obs_max": 2.7192276265632445, "loss": 3.2215254306793213, "mae": 5.765521049499512, "mean_q": 10.620461463928223, "_runtime": 604.2588293552399, "_timestamp": 1582185437.632311, "_step": 232}
{"step": 2532, "episode": 234, "duration": 0.10558200000002671, "episode_steps": 9, "sps": 85.24180257996366, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1662911858892379, "obs_min": -1.770948896906837, "obs_max": 2.8904453891097215, "loss": 2.9510536193847656, "mae": 5.700300216674805, "mean_q": 10.422834396362305, "_runtime": 604.3838012218475, "_timestamp": 1582185437.757283, "_step": 233}
{"step": 2542, "episode": 235, "duration": 0.06283179999991262, "episode_steps": 10, "sps": 159.1550775246596, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.14804037777578666, "obs_min": -1.740511891675761, "obs_max": 2.717437028593081, "loss": 3.3526928424835205, "mae": 5.6847734451293945, "mean_q": 10.25645637512207, "_runtime": 604.4619250297546, "_timestamp": 1582185437.8354068, "_step": 234}
{"step": 2551, "episode": 236, "duration": 0.0632801000000427, "episode_steps": 9, "sps": 142.22480685071497, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.14466529748516477, "obs_min": -1.6150440189051722, "obs_max": 2.4986339526380426, "loss": 1.6728037595748901, "mae": 5.582769870758057, "mean_q": 10.346442222595215, "_runtime": 604.5400607585907, "_timestamp": 1582185437.9135425, "_step": 235}
{"step": 2560, "episode": 237, "duration": 0.057793199999991884, "episode_steps": 9, "sps": 155.72766346215928, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.16195151092146162, "obs_min": -1.53944838435505, "obs_max": 2.5057532871236017, "loss": 1.8296563625335693, "mae": 5.7280049324035645, "mean_q": 10.69924545288086, "_runtime": 604.6025552749634, "_timestamp": 1582185437.976037, "_step": 236}
{"step": 2568, "episode": 238, "duration": 0.05075560000000223, "episode_steps": 8, "sps": 157.61807564090756, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.125, "action_min": 0, "action_max": 1, "obs_mean": 0.1294947609911332, "obs_min": -1.4154587356633639, "obs_max": 2.22242708478897, "loss": 1.8480886220932007, "mae": 5.4878339767456055, "mean_q": 10.263299942016602, "_runtime": 604.6650342941284, "_timestamp": 1582185438.038516, "_step": 237}
{"step": 2577, "episode": 239, "duration": 0.058280599999989136, "episode_steps": 9, "sps": 154.4253147702954, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.12896226840398956, "obs_min": -1.5961675326316065, "obs_max": 2.43039531489668, "loss": 1.406949520111084, "mae": 5.487480163574219, "mean_q": 10.349284172058105, "_runtime": 604.7431516647339, "_timestamp": 1582185438.1166334, "_step": 238}
{"step": 2589, "episode": 240, "duration": 0.09852269999998953, "episode_steps": 12, "sps": 121.7993416745712, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.25, "action_min": 0, "action_max": 1, "obs_mean": 0.11406688688552107, "obs_min": -1.5581471501957842, "obs_max": 2.350584502040833, "loss": 1.4428772926330566, "mae": 5.541182994842529, "mean_q": 10.545210838317871, "_runtime": 604.8525438308716, "_timestamp": 1582185438.2260256, "_step": 239}
{"step": 2599, "episode": 241, "duration": 0.06302020000009634, "episode_steps": 10, "sps": 158.67928061137084, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.14503560800288767, "obs_min": -1.7648021111044327, "obs_max": 2.7184667263958957, "loss": 2.043097972869873, "mae": 5.511847496032715, "mean_q": 10.367666244506836, "_runtime": 604.930657863617, "_timestamp": 1582185438.3041396, "_step": 240}
{"step": 2609, "episode": 242, "duration": 0.08785380000006171, "episode_steps": 10, "sps": 113.82546913159108, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.10955423502359958, "obs_min": -1.6104994586394643, "obs_max": 2.3836620971664817, "loss": 2.8481364250183105, "mae": 5.627263069152832, "mean_q": 10.388089179992676, "_runtime": 605.0400059223175, "_timestamp": 1582185438.4134877, "_step": 241}
{"step": 2619, "episode": 243, "duration": 0.09329160000004322, "episode_steps": 10, "sps": 107.19078673744868, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.16570298497510033, "obs_min": -1.718118836930781, "obs_max": 2.747023778393726, "loss": 2.138873815536499, "mae": 5.583807468414307, "mean_q": 10.401167869567871, "_runtime": 605.1493737697601, "_timestamp": 1582185438.5228555, "_step": 242}
{"step": 2633, "episode": 244, "duration": 0.10387930000001688, "episode_steps": 14, "sps": 134.7717976536011, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.21428571428571427, "action_min": 0, "action_max": 1, "obs_mean": 0.07555975174262612, "obs_min": -1.6067485992376696, "obs_max": 2.564979188904658, "loss": 2.3709118366241455, "mae": 5.682051658630371, "mean_q": 10.514524459838867, "_runtime": 605.2743852138519, "_timestamp": 1582185438.647867, "_step": 243}
{"step": 2642, "episode": 245, "duration": 0.07934030000001258, "episode_steps": 9, "sps": 113.43541680581714, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.14049547919491934, "obs_min": -1.8116814062767161, "obs_max": 2.80452926863536, "loss": 1.8933573961257935, "mae": 5.5416412353515625, "mean_q": 10.394462585449219, "_runtime": 605.3681108951569, "_timestamp": 1582185438.7415926, "_step": 244}
{"step": 2651, "episode": 246, "duration": 0.06467910000003485, "episode_steps": 9, "sps": 139.1485039215937, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.150882211167716, "obs_min": -1.8023256965695151, "obs_max": 2.8597329830437563, "loss": 2.2135910987854004, "mae": 5.504268646240234, "mean_q": 10.158422470092773, "_runtime": 605.4306237697601, "_timestamp": 1582185438.8041055, "_step": 245}
{"step": 2662, "episode": 247, "duration": 0.07334960000002866, "episode_steps": 11, "sps": 149.9667346515278, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.18181818181818182, "action_min": 0, "action_max": 1, "obs_mean": 0.11249292933551992, "obs_min": -1.349697940280792, "obs_max": 2.221876643727313, "loss": 1.8644089698791504, "mae": 5.331414699554443, "mean_q": 9.918645858764648, "_runtime": 605.5243470668793, "_timestamp": 1582185438.8978288, "_step": 246}
{"step": 2670, "episode": 248, "duration": 0.05171819999998206, "episode_steps": 8, "sps": 154.68442443864586, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.13571591010157846, "obs_min": -1.6081533523389862, "obs_max": 2.5233582840070117, "loss": 1.8809244632720947, "mae": 5.409795761108398, "mean_q": 10.120657920837402, "_runtime": 605.5868508815765, "_timestamp": 1582185438.9603326, "_step": 247}
{"step": 2680, "episode": 249, "duration": 0.0842113999999583, "episode_steps": 10, "sps": 118.74876798159099, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.10198775459599874, "obs_min": -1.7942033193484954, "obs_max": 2.6487911530435673, "loss": 2.633463144302368, "mae": 5.626443862915039, "mean_q": 10.40342903137207, "_runtime": 605.696230173111, "_timestamp": 1582185439.069712, "_step": 248}
{"step": 2692, "episode": 250, "duration": 0.07812550000005558, "episode_steps": 12, "sps": 153.59901696618215, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.16666666666666666, "action_min": 0, "action_max": 1, "obs_mean": 0.11667487648538448, "obs_min": -1.5437684558217009, "obs_max": 2.4591832587726357, "loss": 1.6476434469223022, "mae": 5.421382427215576, "mean_q": 10.148307800292969, "_runtime": 605.7899732589722, "_timestamp": 1582185439.163455, "_step": 249}
{"step": 2700, "episode": 251, "duration": 0.05693039999994198, "episode_steps": 8, "sps": 140.52246251577634, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1624736915208205, "obs_min": -1.5565327282068009, "obs_max": 2.5617540856364975, "loss": 1.4428125619888306, "mae": 5.507853984832764, "mean_q": 10.481378555297852, "_runtime": 605.8524496555328, "_timestamp": 1582185439.2259314, "_step": 250}
{"step": 2710, "episode": 252, "duration": 0.10590109999998276, "episode_steps": 10, "sps": 94.42772549106316, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.12265785496271397, "obs_min": -1.7632112321388738, "obs_max": 2.6838945294845935, "loss": 2.0298938751220703, "mae": 5.486893177032471, "mean_q": 10.344010353088379, "_runtime": 605.977441072464, "_timestamp": 1582185439.3509228, "_step": 251}
{"step": 2719, "episode": 253, "duration": 0.06673190000003615, "episode_steps": 9, "sps": 134.86803163097596, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.18178803419922085, "obs_min": -1.7154637415887943, "obs_max": 2.8687862483041684, "loss": 3.091167688369751, "mae": 5.535778999328613, "mean_q": 10.157930374145508, "_runtime": 606.0555608272552, "_timestamp": 1582185439.4290426, "_step": 252}
{"step": 2727, "episode": 254, "duration": 0.05118419999996604, "episode_steps": 8, "sps": 156.29823265783793, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.15431795616628075, "obs_min": -1.5740458865911533, "obs_max": 2.5654036670068443, "loss": 1.3359582424163818, "mae": 5.560976505279541, "mean_q": 10.561817169189453, "_runtime": 606.1336798667908, "_timestamp": 1582185439.5071616, "_step": 253}
{"step": 2736, "episode": 255, "duration": 0.057207500000004075, "episode_steps": 9, "sps": 157.32202945416876, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.13412796907950944, "obs_min": -1.5313520210385998, "obs_max": 2.4529943998672046, "loss": 1.7254045009613037, "mae": 5.575242042541504, "mean_q": 10.448745727539062, "_runtime": 606.1961786746979, "_timestamp": 1582185439.5696604, "_step": 254}
{"step": 2746, "episode": 256, "duration": 0.10056539999993674, "episode_steps": 10, "sps": 99.43777879873485, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.13664574264448748, "obs_min": -1.5347113155319405, "obs_max": 2.5121788699286114, "loss": 1.5467746257781982, "mae": 5.489142417907715, "mean_q": 10.326099395751953, "_runtime": 606.3211863040924, "_timestamp": 1582185439.694668, "_step": 255}
{"step": 2754, "episode": 257, "duration": 0.051840199999901415, "episode_steps": 8, "sps": 154.32039228273067, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1626157256066742, "obs_min": -1.5319708518619384, "obs_max": 2.5867133030078686, "loss": 1.6791085004806519, "mae": 5.482553482055664, "mean_q": 10.375505447387695, "_runtime": 606.3836653232574, "_timestamp": 1582185439.757147, "_step": 256}
{"step": 2763, "episode": 258, "duration": 0.13679079999997157, "episode_steps": 9, "sps": 65.79389842008285, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.15057408863844104, "obs_min": -1.7432629055504385, "obs_max": 2.8248915411118394, "loss": 1.2938565015792847, "mae": 5.480266094207764, "mean_q": 10.38247013092041, "_runtime": 606.5399217605591, "_timestamp": 1582185439.9134035, "_step": 257}
{"step": 2772, "episode": 259, "duration": 0.06282910000004449, "episode_steps": 9, "sps": 143.24572530871248, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.14250964401212762, "obs_min": -1.7698611232511106, "obs_max": 2.783374709098602, "loss": 1.5039808750152588, "mae": 5.336386203765869, "mean_q": 10.049158096313477, "_runtime": 606.6180217266083, "_timestamp": 1582185439.9915035, "_step": 258}
{"step": 2783, "episode": 260, "duration": 0.09261259999993854, "episode_steps": 11, "sps": 118.77433524171981, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.18181818181818182, "action_min": 0, "action_max": 1, "obs_mean": 0.12679349571613396, "obs_min": -1.5823657956681723, "obs_max": 2.484303470716851, "loss": 1.3173298835754395, "mae": 5.219931125640869, "mean_q": 9.961833953857422, "_runtime": 606.7273914813995, "_timestamp": 1582185440.1008732, "_step": 259}
{"step": 2791, "episode": 261, "duration": 0.054887600000029124, "episode_steps": 8, "sps": 145.75241038040932, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1502971356292269, "obs_min": -1.5834600800512313, "obs_max": 2.5551241766878943, "loss": 1.979644536972046, "mae": 5.428986072540283, "mean_q": 10.16128158569336, "_runtime": 606.7899045944214, "_timestamp": 1582185440.1633863, "_step": 260}
{"step": 2802, "episode": 262, "duration": 0.08982009999999718, "episode_steps": 11, "sps": 122.46702018813545, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.18181818181818182, "action_min": 0, "action_max": 1, "obs_mean": 0.10252483566513515, "obs_min": -1.4006897274116148, "obs_max": 2.274811882350011, "loss": 1.622866153717041, "mae": 5.416134357452393, "mean_q": 10.178498268127441, "_runtime": 606.8992719650269, "_timestamp": 1582185440.2727537, "_step": 261}
{"step": 2810, "episode": 263, "duration": 0.10094149999997626, "episode_steps": 8, "sps": 79.25382523542727, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.125, "action_min": 0, "action_max": 1, "obs_mean": 0.1310802093417558, "obs_min": -1.3768382076469465, "obs_max": 2.2156477098110727, "loss": 1.2849271297454834, "mae": 5.484386444091797, "mean_q": 10.391519546508789, "_runtime": 607.0242764949799, "_timestamp": 1582185440.3977582, "_step": 262}
{"step": 2822, "episode": 264, "duration": 0.08364649999998619, "episode_steps": 12, "sps": 143.46087403539875, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.25, "action_min": 0, "action_max": 1, "obs_mean": 0.10113878509913166, "obs_min": -1.3879505816120863, "obs_max": 2.1068076085390057, "loss": 1.3833662271499634, "mae": 5.504637241363525, "mean_q": 10.403531074523926, "_runtime": 607.1180062294006, "_timestamp": 1582185440.491488, "_step": 263}
{"step": 2831, "episode": 265, "duration": 0.10091660000000502, "episode_steps": 9, "sps": 89.18255272174798, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.14054015086564514, "obs_min": -1.419830252668553, "obs_max": 2.1797846481696816, "loss": 1.2530543804168701, "mae": 5.42253303527832, "mean_q": 10.265828132629395, "_runtime": 607.2273542881012, "_timestamp": 1582185440.600836, "_step": 264}
{"step": 2843, "episode": 266, "duration": 0.12723170000003847, "episode_steps": 12, "sps": 94.31611775993224, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.10873878289931765, "obs_min": -1.3639817287251967, "obs_max": 2.090053360437616, "loss": 1.3412045240402222, "mae": 5.41298246383667, "mean_q": 10.245808601379395, "_runtime": 607.3679723739624, "_timestamp": 1582185440.7414541, "_step": 265}
{"step": 2866, "episode": 267, "duration": 0.22069260000000668, "episode_steps": 23, "sps": 104.21735934960803, "episode_reward": 23.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5217391304347826, "action_min": 0, "action_max": 1, "obs_mean": 0.07670569902964468, "obs_min": -1.1853192383111741, "obs_max": 1.6986633419973696, "loss": 1.940742015838623, "mae": 5.464263439178467, "mean_q": 10.173360824584961, "_runtime": 607.6179633140564, "_timestamp": 1582185440.991445, "_step": 266}
{"step": 2888, "episode": 268, "duration": 0.18101469999999154, "episode_steps": 22, "sps": 121.53709063408125, "episode_reward": 22.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": 0.09123687147037475, "obs_min": -0.5920605783664954, "obs_max": 0.9669172972118201, "loss": 1.691409945487976, "mae": 5.401613235473633, "mean_q": 10.053793907165527, "_runtime": 607.8054392337799, "_timestamp": 1582185441.178921, "_step": 267}
{"step": 2913, "episode": 269, "duration": 0.19791090000001077, "episode_steps": 25, "sps": 126.31947002413025, "episode_reward": 25.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.48, "action_min": 0, "action_max": 1, "obs_mean": 0.09026698900741166, "obs_min": -0.9976334380032326, "obs_max": 1.4618229910268763, "loss": 1.213819146156311, "mae": 5.385775566101074, "mean_q": 10.123385429382324, "_runtime": 608.0241858959198, "_timestamp": 1582185441.3976676, "_step": 268}
{"step": 2922, "episode": 270, "duration": 0.07824679999998807, "episode_steps": 9, "sps": 115.02067816193598, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.13295869709725328, "obs_min": -1.1750390660762262, "obs_max": 1.866195101967915, "loss": 1.4519556760787964, "mae": 5.180332660675049, "mean_q": 9.642791748046875, "_runtime": 608.117936372757, "_timestamp": 1582185441.4914181, "_step": 269}
{"step": 2955, "episode": 271, "duration": 0.21605319999991934, "episode_steps": 33, "sps": 152.7401584425147, "episode_reward": 33.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5151515151515151, "action_min": 0, "action_max": 1, "obs_mean": 0.10652490037155593, "obs_min": -0.9813849247670298, "obs_max": 1.4798109851648267, "loss": 1.6460212469100952, "mae": 5.484690189361572, "mean_q": 10.207602500915527, "_runtime": 608.352296590805, "_timestamp": 1582185441.7257783, "_step": 270}
{"step": 2996, "episode": 272, "duration": 0.3247614000000567, "episode_steps": 41, "sps": 126.24653052977614, "episode_reward": 41.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4634146341463415, "action_min": 0, "action_max": 1, "obs_mean": 0.08772662683176058, "obs_min": -0.9820181324036087, "obs_max": 2.110923301223642, "loss": 1.2047500610351562, "mae": 5.279868125915527, "mean_q": 9.894033432006836, "_runtime": 608.680380821228, "_timestamp": 1582185442.0538626, "_step": 271}
{"step": 3061, "episode": 273, "duration": 0.48784390000002986, "episode_steps": 65, "sps": 133.23934151886704, "episode_reward": 65.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47692307692307695, "action_min": 0, "action_max": 1, "obs_mean": -0.06635004229419177, "obs_min": -0.8153015026829346, "obs_max": 1.1156926209260918, "loss": 1.2565007209777832, "mae": 5.346012115478516, "mean_q": 10.007990837097168, "_runtime": 609.192455291748, "_timestamp": 1582185442.565937, "_step": 272}
{"step": 3088, "episode": 274, "duration": 0.2299124999999549, "episode_steps": 27, "sps": 117.43598107978164, "episode_reward": 27.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.48148148148148145, "action_min": 0, "action_max": 1, "obs_mean": -0.10870843951923538, "obs_min": -1.2048995272099134, "obs_max": 0.3885816427739538, "loss": 1.3768588304519653, "mae": 5.458794116973877, "mean_q": 10.250263214111328, "_runtime": 609.443915605545, "_timestamp": 1582185442.8173974, "_step": 273}
{"step": 3147, "episode": 275, "duration": 0.4008569999999736, "episode_steps": 59, "sps": 147.18465687266004, "episode_reward": 59.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4745762711864407, "action_min": 0, "action_max": 1, "obs_mean": 0.08341911185342063, "obs_min": -0.7748232900910631, "obs_max": 1.7018521049567272, "loss": 1.0981365442276, "mae": 5.367992877960205, "mean_q": 10.083515167236328, "_runtime": 609.8428435325623, "_timestamp": 1582185443.2163253, "_step": 274}
{"step": 3201, "episode": 276, "duration": 0.4790169000000333, "episode_steps": 54, "sps": 112.7308869478222, "episode_reward": 54.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.48148148148148145, "action_min": 0, "action_max": 1, "obs_mean": -0.08493328048898358, "obs_min": -0.6706102312921898, "obs_max": 0.35566395783949034, "loss": 0.9480556845664978, "mae": 5.359170913696289, "mean_q": 10.11048412322998, "_runtime": 610.3503420352936, "_timestamp": 1582185443.7238238, "_step": 275}
{"step": 3255, "episode": 277, "duration": 0.43083039999999073, "episode_steps": 54, "sps": 125.33934467020238, "episode_reward": 54.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": 0.09469400920325192, "obs_min": -0.6452967337709821, "obs_max": 1.3754187304813184, "loss": 1.2206552028656006, "mae": 5.52768611907959, "mean_q": 10.410711288452148, "_runtime": 610.7868657112122, "_timestamp": 1582185444.1603475, "_step": 276}
{"step": 3323, "episode": 278, "duration": 0.44152600000006714, "episode_steps": 68, "sps": 154.0113153019067, "episode_reward": 68.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4852941176470588, "action_min": 0, "action_max": 1, "obs_mean": -0.08256069604039071, "obs_min": -0.7407388168040598, "obs_max": 0.6572908669314419, "loss": 1.1123839616775513, "mae": 5.521977424621582, "mean_q": 10.402016639709473, "_runtime": 611.2476732730865, "_timestamp": 1582185444.621155, "_step": 277}
{"step": 3370, "episode": 279, "duration": 0.3933622000000696, "episode_steps": 47, "sps": 119.48275660445178, "episode_reward": 47.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.48936170212765956, "action_min": 0, "action_max": 1, "obs_mean": -0.06393252899786969, "obs_min": -1.0494275791360341, "obs_max": 0.34730590987397103, "loss": 1.0654325485229492, "mae": 5.606730937957764, "mean_q": 10.579366683959961, "_runtime": 611.6557371616364, "_timestamp": 1582185445.029219, "_step": 278}
{"step": 3407, "episode": 280, "duration": 0.33059930000001714, "episode_steps": 37, "sps": 111.91796231872868, "episode_reward": 37.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4594594594594595, "action_min": 0, "action_max": 1, "obs_mean": -0.10561200847702999, "obs_min": -0.9665934130056015, "obs_max": 0.604689975159813, "loss": 1.016559362411499, "mae": 5.627885341644287, "mean_q": 10.62916374206543, "_runtime": 611.999959230423, "_timestamp": 1582185445.373441, "_step": 279}
{"step": 3438, "episode": 281, "duration": 0.2701454000000467, "episode_steps": 31, "sps": 114.75301818944405, "episode_reward": 31.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.45161290322580644, "action_min": 0, "action_max": 1, "obs_mean": -0.1218659625541127, "obs_min": -0.6106862771897344, "obs_max": 0.4365321950895588, "loss": 0.9674738645553589, "mae": 5.623010158538818, "mean_q": 10.625994682312012, "_runtime": 612.2875964641571, "_timestamp": 1582185445.6610782, "_step": 280}
{"step": 3476, "episode": 282, "duration": 0.2820621000000756, "episode_steps": 38, "sps": 134.72210552211664, "episode_reward": 38.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47368421052631576, "action_min": 0, "action_max": 1, "obs_mean": -0.0989940288317943, "obs_min": -0.6525397623892384, "obs_max": 0.37554407529380307, "loss": 1.547685146331787, "mae": 5.773953437805176, "mean_q": 10.79655647277832, "_runtime": 612.5831501483917, "_timestamp": 1582185445.956632, "_step": 281}
{"step": 3513, "episode": 283, "duration": 0.264495600000032, "episode_steps": 37, "sps": 139.88890552430937, "episode_reward": 37.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4594594594594595, "action_min": 0, "action_max": 1, "obs_mean": -0.10759292948190162, "obs_min": -0.8671754979451569, "obs_max": 0.5371067955542186, "loss": 1.0020519495010376, "mae": 5.646476745605469, "mean_q": 10.600960731506348, "_runtime": 612.8668587207794, "_timestamp": 1582185446.2403405, "_step": 282}
{"step": 3570, "episode": 284, "duration": 0.4344158999999763, "episode_steps": 57, "sps": 131.21066701288584, "episode_reward": 57.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47368421052631576, "action_min": 0, "action_max": 1, "obs_mean": -0.12374611760361381, "obs_min": -0.7506173175065513, "obs_max": 0.36083407426221065, "loss": 1.034286618232727, "mae": 5.810724258422852, "mean_q": 10.968868255615234, "_runtime": 613.3161535263062, "_timestamp": 1582185446.6896353, "_step": 283}
{"step": 3619, "episode": 285, "duration": 0.34042920000001686, "episode_steps": 49, "sps": 143.93594909014143, "episode_reward": 49.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46938775510204084, "action_min": 0, "action_max": 1, "obs_mean": -0.12143333752342263, "obs_min": -0.7858048421634717, "obs_max": 0.6755665898114884, "loss": 1.1261390447616577, "mae": 5.831433296203613, "mean_q": 11.005651473999023, "_runtime": 613.6699891090393, "_timestamp": 1582185447.0434709, "_step": 284}
{"step": 3678, "episode": 286, "duration": 0.4055054000000382, "episode_steps": 59, "sps": 145.4974459032961, "episode_reward": 59.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4915254237288136, "action_min": 0, "action_max": 1, "obs_mean": -0.061019781087438996, "obs_min": -0.9916841403585994, "obs_max": 0.1676061326574934, "loss": 1.3199909925460815, "mae": 5.795578956604004, "mean_q": 10.882938385009766, "_runtime": 614.08624792099, "_timestamp": 1582185447.4597297, "_step": 285}
{"step": 3721, "episode": 287, "duration": 0.30568369999991774, "episode_steps": 43, "sps": 140.66827900869941, "episode_reward": 43.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46511627906976744, "action_min": 0, "action_max": 1, "obs_mean": -0.11664334089925862, "obs_min": -0.5883069170817719, "obs_max": 0.3534487051428138, "loss": 1.3124078512191772, "mae": 5.928089141845703, "mean_q": 11.127195358276367, "_runtime": 614.3958251476288, "_timestamp": 1582185447.769307, "_step": 286}
{"step": 3781, "episode": 288, "duration": 0.4477511999999706, "episode_steps": 60, "sps": 134.00299094676674, "episode_reward": 60.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5166666666666667, "action_min": 0, "action_max": 1, "obs_mean": 0.08705535396005169, "obs_min": -0.4058576005377109, "obs_max": 0.816485940740713, "loss": 1.2018635272979736, "mae": 5.924432754516602, "mean_q": 11.171557426452637, "_runtime": 614.8654267787933, "_timestamp": 1582185448.2389085, "_step": 287}
{"step": 3893, "episode": 289, "duration": 0.8060166000000208, "episode_steps": 112, "sps": 138.95495452574687, "episode_reward": 112.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.48214285714285715, "action_min": 0, "action_max": 1, "obs_mean": -0.03287158733372689, "obs_min": -0.7344767631996576, "obs_max": 0.7962953578341451, "loss": 1.3303889036178589, "mae": 6.042617321014404, "mean_q": 11.34327220916748, "_runtime": 615.6791610717773, "_timestamp": 1582185449.0526428, "_step": 288}
{"step": 3942, "episode": 290, "duration": 0.3135244000000057, "episode_steps": 49, "sps": 156.28767649343754, "episode_reward": 49.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46938775510204084, "action_min": 0, "action_max": 1, "obs_mean": -0.10255368247814386, "obs_min": -0.6121943804532751, "obs_max": 0.4425023955069491, "loss": 1.5981022119522095, "mae": 6.168008804321289, "mean_q": 11.554863929748535, "_runtime": 616.0150780677795, "_timestamp": 1582185449.3885598, "_step": 289}
{"step": 3971, "episode": 291, "duration": 0.24366009999994276, "episode_steps": 29, "sps": 119.0182553483595, "episode_reward": 29.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5172413793103449, "action_min": 0, "action_max": 1, "obs_mean": 0.11958594595498227, "obs_min": -0.3499828445200065, "obs_max": 0.8198511562916384, "loss": 1.1825990676879883, "mae": 6.212669849395752, "mean_q": 11.735913276672363, "_runtime": 616.2721788883209, "_timestamp": 1582185449.6456606, "_step": 290}
{"step": 4032, "episode": 292, "duration": 0.4176763000000392, "episode_steps": 61, "sps": 146.04611274327578, "episode_reward": 61.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47540983606557374, "action_min": 0, "action_max": 1, "obs_mean": -0.12792470754419213, "obs_min": -0.8540107908783542, "obs_max": 0.4080880872143226, "loss": 1.344088077545166, "mae": 6.315541744232178, "mean_q": 11.936124801635742, "_runtime": 616.6935865879059, "_timestamp": 1582185450.0670683, "_step": 291}
{"step": 4079, "episode": 293, "duration": 0.3648815999999897, "episode_steps": 47, "sps": 128.80890677962748, "episode_reward": 47.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46808510638297873, "action_min": 0, "action_max": 1, "obs_mean": -0.10129953667838303, "obs_min": -0.9205876162083378, "obs_max": 0.6193954516650529, "loss": 1.6608892679214478, "mae": 6.283567428588867, "mean_q": 11.791765213012695, "_runtime": 617.0793437957764, "_timestamp": 1582185450.4528255, "_step": 292}
{"step": 4121, "episode": 294, "duration": 0.28719760000001315, "episode_steps": 42, "sps": 146.24077638531128, "episode_reward": 42.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4523809523809524, "action_min": 0, "action_max": 1, "obs_mean": -0.09997948123300086, "obs_min": -0.7462471164482244, "obs_max": 0.3739675812922999, "loss": 1.8971939086914062, "mae": 6.4058074951171875, "mean_q": 11.956446647644043, "_runtime": 617.3845319747925, "_timestamp": 1582185450.7580137, "_step": 293}
{"step": 4176, "episode": 295, "duration": 0.37810720000004494, "episode_steps": 55, "sps": 145.4613929594397, "episode_reward": 55.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4727272727272727, "action_min": 0, "action_max": 1, "obs_mean": -0.1423852299807514, "obs_min": -0.6848084739214138, "obs_max": 0.4783795196007173, "loss": 1.3878823518753052, "mae": 6.406604766845703, "mean_q": 12.072012901306152, "_runtime": 617.7727236747742, "_timestamp": 1582185451.1462054, "_step": 294}
{"step": 4218, "episode": 296, "duration": 0.27812040000003435, "episode_steps": 42, "sps": 151.01373362038458, "episode_reward": 42.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47619047619047616, "action_min": 0, "action_max": 1, "obs_mean": -0.09258995174663924, "obs_min": -1.0770172212980758, "obs_max": 0.2359517721182497, "loss": 1.4239336252212524, "mae": 6.498844623565674, "mean_q": 12.269927978515625, "_runtime": 618.0700693130493, "_timestamp": 1582185451.443551, "_step": 295}
{"step": 4314, "episode": 297, "duration": 0.7210119999999733, "episode_steps": 96, "sps": 133.14618896773362, "episode_reward": 96.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4895833333333333, "action_min": 0, "action_max": 1, "obs_mean": -0.024277181276295218, "obs_min": -0.9851586095733937, "obs_max": 0.38535247392185235, "loss": 1.7320181131362915, "mae": 6.656651973724365, "mean_q": 12.4959716796875, "_runtime": 618.807870388031, "_timestamp": 1582185452.1813521, "_step": 296}
{"step": 4381, "episode": 298, "duration": 0.4043462999999292, "episode_steps": 67, "sps": 165.69955011338482, "episode_reward": 67.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47761194029850745, "action_min": 0, "action_max": 1, "obs_mean": -0.11311555077797628, "obs_min": -0.9351062990666879, "obs_max": 0.4354669793574627, "loss": 1.4221177101135254, "mae": 6.653067588806152, "mean_q": 12.55617904663086, "_runtime": 619.2143483161926, "_timestamp": 1582185452.58783, "_step": 297}
{"step": 4432, "episode": 299, "duration": 0.3836914999999408, "episode_steps": 51, "sps": 132.91928541551707, "episode_reward": 51.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5294117647058824, "action_min": 0, "action_max": 1, "obs_mean": 0.10141187418260536, "obs_min": -0.47858235614466604, "obs_max": 0.9071095549235961, "loss": 1.4395114183425903, "mae": 6.664453983306885, "mean_q": 12.55970287322998, "_runtime": 619.6146476268768, "_timestamp": 1582185452.9881294, "_step": 298}
{"step": 4517, "episode": 300, "duration": 0.5221195999999964, "episode_steps": 85, "sps": 162.79794897567643, "episode_reward": 85.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5058823529411764, "action_min": 0, "action_max": 1, "obs_mean": 0.10557742773666029, "obs_min": -0.3564366407450581, "obs_max": 1.18614163292207, "loss": 1.7682065963745117, "mae": 6.846800327301025, "mean_q": 12.854452133178711, "_runtime": 620.1458621025085, "_timestamp": 1582185453.5193439, "_step": 299}
{"step": 4568, "episode": 301, "duration": 0.4501563000000033, "episode_steps": 51, "sps": 113.29398255672447, "episode_reward": 51.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.45098039215686275, "action_min": 0, "action_max": 1, "obs_mean": -0.11491724023212299, "obs_min": -0.857081414388303, "obs_max": 0.43856977422672966, "loss": 1.3155542612075806, "mae": 6.923384666442871, "mean_q": 13.089384078979492, "_runtime": 620.6145613193512, "_timestamp": 1582185453.988043, "_step": 300}
{"step": 4629, "episode": 302, "duration": 0.3624135000000024, "episode_steps": 61, "sps": 168.3160257551101, "episode_reward": 61.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47540983606557374, "action_min": 0, "action_max": 1, "obs_mean": -0.09556361601186843, "obs_min": -0.8324740052957347, "obs_max": 0.271281983484279, "loss": 1.3509514331817627, "mae": 6.987199306488037, "mean_q": 13.20019817352295, "_runtime": 620.9895522594452, "_timestamp": 1582185454.363034, "_step": 301}
{"step": 4678, "episode": 303, "duration": 0.34043609999991986, "episode_steps": 49, "sps": 143.9330317789786, "episode_reward": 49.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46938775510204084, "action_min": 0, "action_max": 1, "obs_mean": -0.16113814001879403, "obs_min": -0.9064524760904409, "obs_max": 0.16465929847975674, "loss": 1.5570967197418213, "mae": 7.025143146514893, "mean_q": 13.269377708435059, "_runtime": 621.355382680893, "_timestamp": 1582185454.7288644, "_step": 302}
{"step": 4748, "episode": 304, "duration": 0.5314463999999361, "episode_steps": 70, "sps": 131.7160112478105, "episode_reward": 70.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5142857142857142, "action_min": 0, "action_max": 1, "obs_mean": 0.123720292861674, "obs_min": -0.3522383759178971, "obs_max": 0.981333683641618, "loss": 1.8192473649978638, "mae": 7.164755821228027, "mean_q": 13.463262557983398, "_runtime": 621.9009492397308, "_timestamp": 1582185455.274431, "_step": 303}
{"step": 4884, "episode": 305, "duration": 0.9629584000000477, "episode_steps": 136, "sps": 141.23143845050134, "episode_reward": 136.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4852941176470588, "action_min": 0, "action_max": 1, "obs_mean": -0.04834034719037451, "obs_min": -0.7420287234127569, "obs_max": 0.4831798241332397, "loss": 2.0678889751434326, "mae": 7.266864776611328, "mean_q": 13.678881645202637, "_runtime": 622.8792631626129, "_timestamp": 1582185456.252745, "_step": 304}
{"step": 4972, "episode": 306, "duration": 0.5652994000000717, "episode_steps": 88, "sps": 155.6697212131993, "episode_reward": 88.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5227272727272727, "action_min": 0, "action_max": 1, "obs_mean": 0.06803772384096123, "obs_min": -0.5604726888761793, "obs_max": 0.7573168400036189, "loss": 1.6372425556182861, "mae": 7.471385478973389, "mean_q": 14.146835327148438, "_runtime": 623.4573562145233, "_timestamp": 1582185456.830838, "_step": 305}
