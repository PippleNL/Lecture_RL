{"step": 9, "episode": 1, "duration": 0.08240139999999929, "episode_steps": 9, "sps": 109.22144526670758, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.16191159973209868, "obs_min": -2.882146374456019, "obs_max": 1.7493737865778334, "loss": NaN, "mae": NaN, "mean_q": NaN, "_runtime": 2.421724319458008, "_timestamp": 1582186183.7253962, "_step": 0}
{"step": 20, "episode": 2, "duration": 0.8119518000000001, "episode_steps": 11, "sps": 13.54760220988487, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.08770055753954359, "obs_min": -2.7154319070278476, "obs_max": 1.8071698255497022, "loss": 0.6813500391112434, "mae": 0.9795496861139933, "mean_q": 0.845577339331309, "_runtime": 3.249776840209961, "_timestamp": 1582186184.5534487, "_step": 1}
{"step": 29, "episode": 3, "duration": 0.06903730000000063, "episode_steps": 9, "sps": 130.3643103076151, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.11077951752015847, "obs_min": -2.225823684949646, "obs_max": 1.422672819270184, "loss": 0.771551251411438, "mae": 0.9912669658660889, "mean_q": 1.0261715650558472, "_runtime": 3.343517780303955, "_timestamp": 1582186184.6471896, "_step": 2}
{"step": 39, "episode": 4, "duration": 0.05933209999999978, "episode_steps": 10, "sps": 168.5428292610583, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.1524645016251861, "obs_min": -2.770248548892709, "obs_max": 1.7379318776413772, "loss": 0.695906937122345, "mae": 0.9029070138931274, "mean_q": 1.1047022342681885, "_runtime": 3.4060139656066895, "_timestamp": 1582186184.7096858, "_step": 3}
{"step": 47, "episode": 5, "duration": 0.09616910000000001, "episode_steps": 8, "sps": 83.18680324553313, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13801240874262907, "obs_min": -2.563367859456072, "obs_max": 1.6044162335499457, "loss": 0.7231571674346924, "mae": 0.8854678869247437, "mean_q": 1.231076717376709, "_runtime": 3.51538348197937, "_timestamp": 1582186184.8190553, "_step": 4}
{"step": 56, "episode": 6, "duration": 0.05863310000000066, "episode_steps": 9, "sps": 153.49691556475605, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.12352575750529961, "obs_min": -2.761808527178321, "obs_max": 1.7677038732598396, "loss": 0.54632169008255, "mae": 0.7856051325798035, "mean_q": 1.3974006175994873, "_runtime": 3.5935168266296387, "_timestamp": 1582186184.8971887, "_step": 5}
{"step": 65, "episode": 7, "duration": 0.12301940000000045, "episode_steps": 9, "sps": 73.15919277772423, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.1394178181279121, "obs_min": -2.7984229196413786, "obs_max": 1.803674166928711, "loss": 0.552150309085846, "mae": 0.7344174385070801, "mean_q": 1.4433956146240234, "_runtime": 3.7341148853302, "_timestamp": 1582186185.0377867, "_step": 6}
{"step": 74, "episode": 8, "duration": 0.07021429999999995, "episode_steps": 9, "sps": 128.17901766449293, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13844782204888295, "obs_min": -2.8166755398401757, "obs_max": 1.7573622882211342, "loss": 0.5143999457359314, "mae": 0.6863148212432861, "mean_q": 1.5837085247039795, "_runtime": 3.827875852584839, "_timestamp": 1582186185.1315477, "_step": 7}
{"step": 83, "episode": 9, "duration": 0.05942589999999903, "episode_steps": 9, "sps": 151.44911562130562, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.11795240898187087, "obs_min": -2.7407886987423464, "obs_max": 1.8047122684066061, "loss": 0.5344337821006775, "mae": 0.6407734751701355, "mean_q": 1.6332106590270996, "_runtime": 3.8903722763061523, "_timestamp": 1582186185.194044, "_step": 8}
{"step": 94, "episode": 10, "duration": 0.07881429999999945, "episode_steps": 11, "sps": 139.56858082860694, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.12426704542242013, "obs_min": -2.71926295818212, "obs_max": 1.7429313110145965, "loss": 0.5324039459228516, "mae": 0.6191503405570984, "mean_q": 1.6900267601013184, "_runtime": 3.9841012954711914, "_timestamp": 1582186185.2877731, "_step": 9}
{"step": 103, "episode": 11, "duration": 0.054591600000000184, "episode_steps": 9, "sps": 164.8605279933171, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14259677376966162, "obs_min": -2.801669680145508, "obs_max": 1.7339559246845002, "loss": 0.5185721516609192, "mae": 0.5727230310440063, "mean_q": 1.7522214651107788, "_runtime": 4.0622313022613525, "_timestamp": 1582186185.3659031, "_step": 10}
{"step": 112, "episode": 12, "duration": 0.16101260000000117, "episode_steps": 9, "sps": 55.89624662914539, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13610207125490298, "obs_min": -2.794754030147289, "obs_max": 1.8015528903675007, "loss": 0.5876611471176147, "mae": 0.6039944291114807, "mean_q": 1.8272260427474976, "_runtime": 4.234085559844971, "_timestamp": 1582186185.5377574, "_step": 11}
{"step": 121, "episode": 13, "duration": 0.06380249999999954, "episode_steps": 9, "sps": 141.06030327965306, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14362367320127434, "obs_min": -2.8807037608770236, "obs_max": 1.8038797001425235, "loss": 0.5584128499031067, "mae": 0.5516172051429749, "mean_q": 1.953104019165039, "_runtime": 4.31221342086792, "_timestamp": 1582186185.6158853, "_step": 12}
{"step": 130, "episode": 14, "duration": 0.06080840000000087, "episode_steps": 9, "sps": 148.0058676103938, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14193205454341953, "obs_min": -2.812409525259429, "obs_max": 1.7775502400095635, "loss": 0.515375554561615, "mae": 0.4932449758052826, "mean_q": 1.9305672645568848, "_runtime": 4.390321731567383, "_timestamp": 1582186185.6939936, "_step": 13}
{"step": 140, "episode": 15, "duration": 0.08969190000000005, "episode_steps": 10, "sps": 111.4927880890024, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15679793720641083, "obs_min": -3.068967598537639, "obs_max": 1.9483266209670798, "loss": 0.610721230506897, "mae": 0.5522680878639221, "mean_q": 2.045454978942871, "_runtime": 4.499705076217651, "_timestamp": 1582186185.803377, "_step": 14}
{"step": 150, "episode": 16, "duration": 0.07041290000000089, "episode_steps": 10, "sps": 142.0194310985611, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13219675622833363, "obs_min": -3.015821011057961, "obs_max": 1.9616649456589925, "loss": 0.671048104763031, "mae": 0.5518163442611694, "mean_q": 2.1082427501678467, "_runtime": 4.577805757522583, "_timestamp": 1582186185.8814776, "_step": 15}
{"step": 159, "episode": 17, "duration": 0.06044699999999992, "episode_steps": 9, "sps": 148.89076380961853, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.16735631394366582, "obs_min": -2.8726168451026037, "obs_max": 1.7795084560897525, "loss": 0.6198040246963501, "mae": 0.5644912719726562, "mean_q": 2.1346449851989746, "_runtime": 4.640308618545532, "_timestamp": 1582186185.9439805, "_step": 16}
{"step": 168, "episode": 18, "duration": 0.05452550000000045, "episode_steps": 9, "sps": 165.06038459069472, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15166943492302165, "obs_min": -2.8346734579118316, "obs_max": 1.7512034595622028, "loss": 0.6112913489341736, "mae": 0.5952374935150146, "mean_q": 2.1730263233184814, "_runtime": 4.718439102172852, "_timestamp": 1582186186.022111, "_step": 17}
{"step": 179, "episode": 19, "duration": 0.16636519999999955, "episode_steps": 11, "sps": 66.11959712728401, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.0924033883352705, "obs_min": -2.7739351334419147, "obs_max": 1.7845541344950633, "loss": 0.6064653992652893, "mae": 0.611505925655365, "mean_q": 2.2313547134399414, "_runtime": 4.90591835975647, "_timestamp": 1582186186.2095902, "_step": 18}
{"step": 189, "episode": 20, "duration": 0.0640584000000004, "episode_steps": 10, "sps": 156.10755185892774, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14098117467779642, "obs_min": -3.0912610418716966, "obs_max": 1.96056247627468, "loss": 0.5728060007095337, "mae": 0.6477874517440796, "mean_q": 2.261617422103882, "_runtime": 4.984046220779419, "_timestamp": 1582186186.287718, "_step": 19}
{"step": 199, "episode": 21, "duration": 0.05914590000000075, "episode_steps": 10, "sps": 169.07342689856563, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.10475124698969955, "obs_min": -2.978864163382826, "obs_max": 1.9739705658030546, "loss": 0.4634457230567932, "mae": 0.6123322248458862, "mean_q": 2.357069492340088, "_runtime": 5.046521902084351, "_timestamp": 1582186186.3501937, "_step": 20}
{"step": 208, "episode": 22, "duration": 0.10886679999999949, "episode_steps": 9, "sps": 82.6698313902865, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13255269758351684, "obs_min": -2.742953427428682, "obs_max": 1.7479996465987795, "loss": 0.5197940468788147, "mae": 0.6453275084495544, "mean_q": 2.5459442138671875, "_runtime": 5.1715333461761475, "_timestamp": 1582186186.4752052, "_step": 21}
{"step": 219, "episode": 23, "duration": 0.07211359999999978, "episode_steps": 11, "sps": 152.5371081183027, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.11443622167351436, "obs_min": -2.7411028390995877, "obs_max": 1.795740163570261, "loss": 0.5862478613853455, "mae": 0.6919615268707275, "mean_q": 2.565464735031128, "_runtime": 5.265276670455933, "_timestamp": 1582186186.5689485, "_step": 22}
{"step": 229, "episode": 24, "duration": 0.05926000000000009, "episode_steps": 10, "sps": 168.7478906513666, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13562496090897774, "obs_min": -3.098992904331541, "obs_max": 1.9701235040697056, "loss": 0.6433624029159546, "mae": 0.7900501489639282, "mean_q": 2.690190076828003, "_runtime": 5.327772378921509, "_timestamp": 1582186186.6314442, "_step": 23}
{"step": 238, "episode": 25, "duration": 0.053965599999999725, "episode_steps": 9, "sps": 166.7729071853189, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.17306553878196274, "obs_min": -2.8608802092796, "obs_max": 1.7477307180279875, "loss": 0.5789306163787842, "mae": 0.7783651351928711, "mean_q": 2.646033763885498, "_runtime": 5.405892610549927, "_timestamp": 1582186186.7095644, "_step": 24}
{"step": 248, "episode": 26, "duration": 0.06225749999999941, "episode_steps": 10, "sps": 160.62321808617588, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13048503604159384, "obs_min": -2.9842028148967925, "obs_max": 1.968733576258563, "loss": 0.5973044633865356, "mae": 0.8108164668083191, "mean_q": 2.7138452529907227, "_runtime": 5.484011888504028, "_timestamp": 1582186186.7876837, "_step": 25}
{"step": 257, "episode": 27, "duration": 0.056549000000000404, "episode_steps": 9, "sps": 159.1540080284344, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.17483154436146597, "obs_min": -2.8888443082728044, "obs_max": 1.752269336221238, "loss": 0.7096689939498901, "mae": 0.8679356575012207, "mean_q": 2.741119861602783, "_runtime": 5.546487808227539, "_timestamp": 1582186186.8501596, "_step": 26}
{"step": 267, "episode": 28, "duration": 0.06250389999999939, "episode_steps": 10, "sps": 159.99001662296428, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15603142098161824, "obs_min": -3.0258148363774806, "obs_max": 1.9064722486462786, "loss": 0.6712883710861206, "mae": 0.8964252471923828, "mean_q": 2.7711715698242188, "_runtime": 5.624607086181641, "_timestamp": 1582186186.928279, "_step": 27}
{"step": 276, "episode": 29, "duration": 0.05518230000000024, "episode_steps": 9, "sps": 163.09577527576707, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.11950334147444666, "obs_min": -2.7907918389545165, "obs_max": 1.806666138315911, "loss": 0.6755818128585815, "mae": 0.9241640567779541, "mean_q": 2.7981648445129395, "_runtime": 5.702739715576172, "_timestamp": 1582186187.0064116, "_step": 28}
{"step": 285, "episode": 30, "duration": 0.06540580000000062, "episode_steps": 9, "sps": 137.60247562142675, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13095688978542727, "obs_min": -2.759517722305575, "obs_max": 1.8038621756320117, "loss": 0.5375446081161499, "mae": 0.8975366950035095, "mean_q": 2.8014965057373047, "_runtime": 5.780866384506226, "_timestamp": 1582186187.0845382, "_step": 29}
{"step": 293, "episode": 31, "duration": 0.04916399999999932, "episode_steps": 8, "sps": 162.7206899357276, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14668954101450227, "obs_min": -2.506182524670037, "obs_max": 1.534585954494033, "loss": 0.5980502367019653, "mae": 0.9231762886047363, "mean_q": 2.9416604042053223, "_runtime": 5.843362331390381, "_timestamp": 1582186187.1470342, "_step": 30}
{"step": 306, "episode": 32, "duration": 0.12620650000000033, "episode_steps": 13, "sps": 103.00578813294058, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8461538461538461, "action_min": 0, "action_max": 1, "obs_mean": -0.11897542499604813, "obs_min": -2.7559854331288105, "obs_max": 1.715881759570612, "loss": 0.5762288570404053, "mae": 0.9446223974227905, "mean_q": 3.0803308486938477, "_runtime": 5.98395848274231, "_timestamp": 1582186187.2876303, "_step": 31}
{"step": 316, "episode": 33, "duration": 0.06090030000000013, "episode_steps": 10, "sps": 164.20280359866828, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.1296388962028291, "obs_min": -2.550963210065308, "obs_max": 1.5904241754254935, "loss": 0.6635127663612366, "mae": 0.9842625856399536, "mean_q": 3.061837673187256, "_runtime": 6.046453952789307, "_timestamp": 1582186187.3501258, "_step": 32}
{"step": 326, "episode": 34, "duration": 0.05873749999999944, "episode_steps": 10, "sps": 170.24898914662856, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.1383471705400548, "obs_min": -3.0674294835655203, "obs_max": 2.004989035306454, "loss": 0.7524856328964233, "mae": 1.0848400592803955, "mean_q": 3.0806095600128174, "_runtime": 6.124594211578369, "_timestamp": 1582186187.428266, "_step": 33}
{"step": 337, "episode": 35, "duration": 0.0688828000000008, "episode_steps": 11, "sps": 159.69153402590882, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.13401511653548623, "obs_min": -2.739577030418574, "obs_max": 1.7366784819164722, "loss": 0.626237154006958, "mae": 1.0639065504074097, "mean_q": 3.0367112159729004, "_runtime": 6.2183380126953125, "_timestamp": 1582186187.5220098, "_step": 34}
{"step": 346, "episode": 36, "duration": 0.07400810000000035, "episode_steps": 9, "sps": 121.60831044169431, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15946351534986491, "obs_min": -2.8251281452622097, "obs_max": 1.739565815792131, "loss": 0.6889154314994812, "mae": 1.1233000755310059, "mean_q": 3.1868128776550293, "_runtime": 6.296437501907349, "_timestamp": 1582186187.6001093, "_step": 35}
{"step": 355, "episode": 37, "duration": 0.05334030000000034, "episode_steps": 9, "sps": 168.72795991023565, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.13520501312938663, "obs_min": -2.2908091780829194, "obs_max": 1.3902546232932922, "loss": 0.5380063056945801, "mae": 1.1004595756530762, "mean_q": 3.2086145877838135, "_runtime": 6.374571800231934, "_timestamp": 1582186187.6782436, "_step": 36}
{"step": 365, "episode": 38, "duration": 0.0639479999999999, "episode_steps": 10, "sps": 156.37705635829138, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13065476393712583, "obs_min": -3.00440676590345, "obs_max": 1.9731467512936793, "loss": 0.6069319844245911, "mae": 1.126718521118164, "mean_q": 3.3242669105529785, "_runtime": 6.452677011489868, "_timestamp": 1582186187.7563488, "_step": 37}
{"step": 373, "episode": 39, "duration": 0.09309780000000067, "episode_steps": 8, "sps": 85.93113908169626, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13774906731880038, "obs_min": -2.489830655978082, "obs_max": 1.562211466992707, "loss": 0.612106204032898, "mae": 1.1673504114151, "mean_q": 3.293754816055298, "_runtime": 6.546429634094238, "_timestamp": 1582186187.8501015, "_step": 38}
{"step": 385, "episode": 40, "duration": 0.08101300000000045, "episode_steps": 12, "sps": 148.12437510029173, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9166666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.12529961613377988, "obs_min": -3.0689556484294047, "obs_max": 1.9424094523992097, "loss": 0.5101202130317688, "mae": 1.1859155893325806, "mean_q": 3.3312876224517822, "_runtime": 6.64018177986145, "_timestamp": 1582186187.9438536, "_step": 39}
{"step": 396, "episode": 41, "duration": 0.11908899999999889, "episode_steps": 11, "sps": 92.36789292042172, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.121266349121658, "obs_min": -3.3018210745325627, "obs_max": 2.1506985772005174, "loss": 0.691453754901886, "mae": 1.2959376573562622, "mean_q": 3.4433538913726807, "_runtime": 6.78079628944397, "_timestamp": 1582186188.0844681, "_step": 40}
{"step": 407, "episode": 42, "duration": 0.06420160000000052, "episode_steps": 11, "sps": 171.33529382445158, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.14884374187757554, "obs_min": -2.835225100792633, "obs_max": 1.7142999400484658, "loss": 0.5681100487709045, "mae": 1.326305866241455, "mean_q": 3.4734132289886475, "_runtime": 6.8589184284210205, "_timestamp": 1582186188.1625903, "_step": 41}
{"step": 417, "episode": 43, "duration": 0.05922360000000104, "episode_steps": 10, "sps": 168.85160645418082, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.09468622196172545, "obs_min": -2.6084715847194486, "obs_max": 1.7942007797697535, "loss": 0.5703909993171692, "mae": 1.3687726259231567, "mean_q": 3.577864408493042, "_runtime": 6.921396493911743, "_timestamp": 1582186188.2250683, "_step": 42}
{"step": 426, "episode": 44, "duration": 0.0682192999999991, "episode_steps": 9, "sps": 131.92747506937363, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.13511178666956827, "obs_min": -2.829871783717932, "obs_max": 1.8011456946953626, "loss": 0.6225254535675049, "mae": 1.4133193492889404, "mean_q": 3.6212010383605957, "_runtime": 7.015138864517212, "_timestamp": 1582186188.3188107, "_step": 43}
{"step": 439, "episode": 45, "duration": 0.07855840000000036, "episode_steps": 13, "sps": 165.4819853764835, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8461538461538461, "action_min": 0, "action_max": 1, "obs_mean": -0.07814663628622985, "obs_min": -2.742027949314543, "obs_max": 1.8000039779042616, "loss": 0.5632908940315247, "mae": 1.471319317817688, "mean_q": 3.643625497817993, "_runtime": 7.108882188796997, "_timestamp": 1582186188.412554, "_step": 44}
{"step": 449, "episode": 46, "duration": 0.059626300000001464, "episode_steps": 10, "sps": 167.7112280990059, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.1015938319739605, "obs_min": -2.65192655663699, "obs_max": 1.7931034341401861, "loss": 0.48243069648742676, "mae": 1.4741008281707764, "mean_q": 3.7020256519317627, "_runtime": 7.1713948249816895, "_timestamp": 1582186188.4750667, "_step": 45}
{"step": 459, "episode": 47, "duration": 0.05906330000000004, "episode_steps": 10, "sps": 169.30987601437766, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.12973218566036437, "obs_min": -3.1117180882877666, "obs_max": 1.995496047159169, "loss": 0.5512486100196838, "mae": 1.522695779800415, "mean_q": 3.8360278606414795, "_runtime": 7.233890771865845, "_timestamp": 1582186188.5375626, "_step": 46}
{"step": 469, "episode": 48, "duration": 0.06532990000000005, "episode_steps": 10, "sps": 153.06926843604523, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.1699168165997487, "obs_min": -3.106829746627677, "obs_max": 1.9229117240351636, "loss": 0.5456032752990723, "mae": 1.558815598487854, "mean_q": 3.873908281326294, "_runtime": 7.327613830566406, "_timestamp": 1582186188.6312857, "_step": 47}
{"step": 479, "episode": 49, "duration": 0.07579740000000079, "episode_steps": 10, "sps": 131.9306466976426, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15149996994365456, "obs_min": -3.103053968885648, "obs_max": 1.9485372985540357, "loss": 0.5454302430152893, "mae": 1.5531432628631592, "mean_q": 3.831244707107544, "_runtime": 7.421358346939087, "_timestamp": 1582186188.7250302, "_step": 48}
{"step": 489, "episode": 50, "duration": 0.06599270000000068, "episode_steps": 10, "sps": 151.5319118629772, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.1518658230671754, "obs_min": -2.256436909206176, "obs_max": 1.351215573574009, "loss": 0.5896236896514893, "mae": 1.614630103111267, "mean_q": 3.8536391258239746, "_runtime": 7.499493360519409, "_timestamp": 1582186188.8031652, "_step": 49}
{"step": 498, "episode": 51, "duration": 0.055242299999999744, "episode_steps": 9, "sps": 162.91863300405743, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.13263401735506358, "obs_min": -2.2161122650398144, "obs_max": 1.4055460770452723, "loss": 0.511573076248169, "mae": 1.5865159034729004, "mean_q": 3.9427032470703125, "_runtime": 7.5619728565216064, "_timestamp": 1582186188.8656447, "_step": 50}
{"step": 506, "episode": 52, "duration": 0.13304810000000167, "episode_steps": 8, "sps": 60.1286301720949, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.150039692050456, "obs_min": -2.5365888009309785, "obs_max": 1.5335975128885075, "loss": 0.506562352180481, "mae": 1.614386796951294, "mean_q": 3.983403205871582, "_runtime": 7.718244791030884, "_timestamp": 1582186189.0219166, "_step": 51}
{"step": 514, "episode": 53, "duration": 0.051374099999998535, "episode_steps": 8, "sps": 155.7204895073632, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.1421130197716918, "obs_min": -2.5260954204785677, "obs_max": 1.5258771194713574, "loss": 0.5159868001937866, "mae": 1.675701379776001, "mean_q": 4.0726823806762695, "_runtime": 7.780707359313965, "_timestamp": 1582186189.0843792, "_step": 52}
{"step": 524, "episode": 54, "duration": 0.09507209999999944, "episode_steps": 10, "sps": 105.18332928377578, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15998578572403815, "obs_min": -3.1348481123597502, "obs_max": 1.9516280530872048, "loss": 0.5947908759117126, "mae": 1.7293434143066406, "mean_q": 4.124402046203613, "_runtime": 7.890075922012329, "_timestamp": 1582186189.1937478, "_step": 53}
{"step": 534, "episode": 55, "duration": 0.06348909999999997, "episode_steps": 10, "sps": 157.50735165563862, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14854270946185272, "obs_min": -3.0832806835388755, "obs_max": 1.974747173059204, "loss": 0.4744938015937805, "mae": 1.7293994426727295, "mean_q": 4.131312370300293, "_runtime": 7.968204736709595, "_timestamp": 1582186189.2718766, "_step": 54}
{"step": 543, "episode": 56, "duration": 0.06482929999999953, "episode_steps": 9, "sps": 138.8261172031792, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.15407263026608653, "obs_min": -2.1565080642003767, "obs_max": 1.3402552135987535, "loss": 0.46280771493911743, "mae": 1.7595031261444092, "mean_q": 4.242135047912598, "_runtime": 8.061971426010132, "_timestamp": 1582186189.3656433, "_step": 55}
{"step": 553, "episode": 57, "duration": 0.1564338000000003, "episode_steps": 10, "sps": 63.92480397458849, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.14114639352155553, "obs_min": -2.513482798257149, "obs_max": 1.5527805113096917, "loss": 0.5007305145263672, "mae": 1.825848937034607, "mean_q": 4.319009780883789, "_runtime": 8.233801364898682, "_timestamp": 1582186189.5374732, "_step": 56}
{"step": 564, "episode": 58, "duration": 0.0669795999999998, "episode_steps": 11, "sps": 164.22910856439918, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9090909090909091, "action_min": 0, "action_max": 1, "obs_mean": -0.11175949561116294, "obs_min": -2.7743114724187885, "obs_max": 1.7895336354771576, "loss": 0.5162988305091858, "mae": 1.8445191383361816, "mean_q": 4.327882766723633, "_runtime": 8.311922550201416, "_timestamp": 1582186189.6155944, "_step": 57}
{"step": 574, "episode": 59, "duration": 0.05978439999999985, "episode_steps": 10, "sps": 167.26771532373036, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.1343474859615263, "obs_min": -2.965707003300599, "obs_max": 1.9147392623322883, "loss": 0.4665047228336334, "mae": 1.8837264776229858, "mean_q": 4.29456090927124, "_runtime": 8.390045642852783, "_timestamp": 1582186189.6937175, "_step": 58}
{"step": 583, "episode": 60, "duration": 0.05832679999999968, "episode_steps": 9, "sps": 154.30299622129192, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14573218628714205, "obs_min": -2.8067436234104823, "obs_max": 1.7196711377046066, "loss": 0.4862845242023468, "mae": 1.9195806980133057, "mean_q": 4.356607437133789, "_runtime": 8.452538251876831, "_timestamp": 1582186189.75621, "_step": 59}
{"step": 595, "episode": 61, "duration": 0.15014709999999987, "episode_steps": 12, "sps": 79.92162352786042, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8333333333333334, "action_min": 0, "action_max": 1, "obs_mean": -0.12833134454429132, "obs_min": -2.5785224056202853, "obs_max": 1.556168757255145, "loss": 0.42161861062049866, "mae": 1.9185699224472046, "mean_q": 4.422708034515381, "_runtime": 8.624405145645142, "_timestamp": 1582186189.928077, "_step": 60}
{"step": 604, "episode": 62, "duration": 0.09785940000000082, "episode_steps": 9, "sps": 91.96868159829229, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15887504769907046, "obs_min": -2.817729903084119, "obs_max": 1.7666580559750695, "loss": 0.4520655870437622, "mae": 1.9394081830978394, "mean_q": 4.5880208015441895, "_runtime": 8.733768463134766, "_timestamp": 1582186190.0374403, "_step": 61}
{"step": 613, "episode": 63, "duration": 0.05472909999999942, "episode_steps": 9, "sps": 164.44633659241785, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.14258045576021613, "obs_min": -2.3580724421366095, "obs_max": 1.4158877626243107, "loss": 0.35091716051101685, "mae": 1.9236814975738525, "mean_q": 4.65831184387207, "_runtime": 8.811890840530396, "_timestamp": 1582186190.1155627, "_step": 62}
{"step": 622, "episode": 64, "duration": 0.0542315999999996, "episode_steps": 9, "sps": 165.9549045206128, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14829241923126182, "obs_min": -2.830570590521011, "obs_max": 1.803511043864801, "loss": 0.5640783905982971, "mae": 2.018674612045288, "mean_q": 4.568723201751709, "_runtime": 8.874384641647339, "_timestamp": 1582186190.1780565, "_step": 63}
{"step": 630, "episode": 65, "duration": 0.10537030000000058, "episode_steps": 8, "sps": 75.9227220573535, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.15550972663334547, "obs_min": -2.522561074362013, "obs_max": 1.5522931793681622, "loss": 0.42906180024147034, "mae": 2.020933151245117, "mean_q": 4.563896656036377, "_runtime": 8.983750343322754, "_timestamp": 1582186190.2874222, "_step": 64}
{"step": 640, "episode": 66, "duration": 0.08747289999999985, "episode_steps": 10, "sps": 114.32112117009973, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.13840274361843033, "obs_min": -2.583758981225653, "obs_max": 1.586237969849976, "loss": 0.4374488294124603, "mae": 2.053577423095703, "mean_q": 4.584776878356934, "_runtime": 9.093125104904175, "_timestamp": 1582186190.396797, "_step": 65}
{"step": 648, "episode": 67, "duration": 0.08587770000000106, "episode_steps": 8, "sps": 93.15573193040686, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.14736492393786205, "obs_min": -2.523693354672406, "obs_max": 1.5624440903660795, "loss": 0.4036639332771301, "mae": 2.0781445503234863, "mean_q": 4.694933891296387, "_runtime": 9.202496767044067, "_timestamp": 1582186190.5061686, "_step": 66}
{"step": 658, "episode": 68, "duration": 0.06670489999999951, "episode_steps": 10, "sps": 149.914024307061, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.13038227707615319, "obs_min": -2.708686679481316, "obs_max": 1.7801248366931595, "loss": 0.46492281556129456, "mae": 2.133634090423584, "mean_q": 4.7469892501831055, "_runtime": 9.296244382858276, "_timestamp": 1582186190.5999162, "_step": 67}
{"step": 667, "episode": 69, "duration": 0.06842700000000157, "episode_steps": 9, "sps": 131.5270288044163, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.14080971440072737, "obs_min": -2.2514316752084413, "obs_max": 1.3856996670824258, "loss": 0.46288490295410156, "mae": 2.1755409240722656, "mean_q": 4.673485279083252, "_runtime": 9.37438154220581, "_timestamp": 1582186190.6780534, "_step": 68}
{"step": 679, "episode": 70, "duration": 0.10695800000000055, "episode_steps": 12, "sps": 112.19357130836345, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.75, "action_min": 0, "action_max": 1, "obs_mean": -0.09350828839348578, "obs_min": -2.2250789838038445, "obs_max": 1.3875908396373937, "loss": 0.45508989691734314, "mae": 2.199899435043335, "mean_q": 4.676144599914551, "_runtime": 9.499370813369751, "_timestamp": 1582186190.8030427, "_step": 69}
{"step": 690, "episode": 71, "duration": 0.09012460000000111, "episode_steps": 11, "sps": 122.05324628347715, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.12289702928460372, "obs_min": -2.346261974401072, "obs_max": 1.5166774267294445, "loss": 0.4278298318386078, "mae": 2.2098796367645264, "mean_q": 4.792001724243164, "_runtime": 9.60870885848999, "_timestamp": 1582186190.9123807, "_step": 70}
{"step": 700, "episode": 72, "duration": 0.06059259999999966, "episode_steps": 10, "sps": 165.0366546409967, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.9, "action_min": 0, "action_max": 1, "obs_mean": -0.11226693216214176, "obs_min": -2.6289201779114166, "obs_max": 1.786748594545673, "loss": 0.33418527245521545, "mae": 2.1819210052490234, "mean_q": 4.9019575119018555, "_runtime": 9.686826229095459, "_timestamp": 1582186190.990498, "_step": 71}
{"step": 709, "episode": 73, "duration": 0.08153080000000124, "episode_steps": 9, "sps": 110.38773077168216, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.15732021006165142, "obs_min": -2.444327633747246, "obs_max": 1.5206016044320023, "loss": 0.42399829626083374, "mae": 2.24666690826416, "mean_q": 4.980251789093018, "_runtime": 9.780568599700928, "_timestamp": 1582186191.0842404, "_step": 72}
{"step": 720, "episode": 74, "duration": 0.08752400000000016, "episode_steps": 11, "sps": 125.67981353685823, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8181818181818182, "action_min": 0, "action_max": 1, "obs_mean": -0.10606476002542563, "obs_min": -2.3224107115589225, "obs_max": 1.595936780635547, "loss": 0.38003310561180115, "mae": 2.2347564697265625, "mean_q": 4.947281360626221, "_runtime": 9.8743155002594, "_timestamp": 1582186191.1779873, "_step": 73}
{"step": 730, "episode": 75, "duration": 0.1123908999999994, "episode_steps": 10, "sps": 88.97517503641356, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.1310717601399709, "obs_min": -2.4251281247532614, "obs_max": 1.5847156737205057, "loss": 0.37410545349121094, "mae": 2.2469258308410645, "mean_q": 5.0021138191223145, "_runtime": 10.014961004257202, "_timestamp": 1582186191.3186328, "_step": 74}
{"step": 743, "episode": 76, "duration": 0.10531040000000047, "episode_steps": 13, "sps": 123.44459806438815, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7692307692307693, "action_min": 0, "action_max": 1, "obs_mean": -0.06348795655757059, "obs_min": -2.4104825770277616, "obs_max": 1.6068658815433299, "loss": 0.3593566119670868, "mae": 2.2651429176330566, "mean_q": 5.050439834594727, "_runtime": 10.139923572540283, "_timestamp": 1582186191.4435954, "_step": 75}
{"step": 751, "episode": 77, "duration": 0.11676019999999987, "episode_steps": 8, "sps": 68.51649791624209, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.875, "action_min": 0, "action_max": 1, "obs_mean": -0.1430036251697413, "obs_min": -2.223066586839376, "obs_max": 1.3950288437260763, "loss": 0.35788801312446594, "mae": 2.3019044399261475, "mean_q": 5.177393436431885, "_runtime": 10.264916181564331, "_timestamp": 1582186191.568588, "_step": 76}
{"step": 762, "episode": 78, "duration": 0.07034149999999961, "episode_steps": 11, "sps": 156.3799464043283, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.10911614193282367, "obs_min": -2.353265701500261, "obs_max": 1.603150627535026, "loss": 0.3848712742328644, "mae": 2.2778427600860596, "mean_q": 5.058907985687256, "_runtime": 10.358673334121704, "_timestamp": 1582186191.6623452, "_step": 77}
{"step": 773, "episode": 79, "duration": 0.06567339999999966, "episode_steps": 11, "sps": 167.49551568823995, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8181818181818182, "action_min": 0, "action_max": 1, "obs_mean": -0.11561401391664711, "obs_min": -2.465574642867091, "obs_max": 1.6004251596882333, "loss": 0.3716183006763458, "mae": 2.268369197845459, "mean_q": 5.088756084442139, "_runtime": 10.436773777008057, "_timestamp": 1582186191.7404456, "_step": 78}
{"step": 783, "episode": 80, "duration": 0.09844799999999942, "episode_steps": 10, "sps": 101.57646676418067, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.12919736212055322, "obs_min": -2.198832221072091, "obs_max": 1.4136528200274474, "loss": 0.381740003824234, "mae": 2.2914490699768066, "mean_q": 5.129332065582275, "_runtime": 10.546144247055054, "_timestamp": 1582186191.849816, "_step": 79}
{"step": 792, "episode": 81, "duration": 0.0679734000000014, "episode_steps": 9, "sps": 132.40473479331348, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.12192413087712985, "obs_min": -2.4102383555193287, "obs_max": 1.576783758950689, "loss": 0.31880858540534973, "mae": 2.274906873703003, "mean_q": 5.2910003662109375, "_runtime": 10.624263763427734, "_timestamp": 1582186191.9279356, "_step": 80}
{"step": 802, "episode": 82, "duration": 0.06378999999999913, "episode_steps": 10, "sps": 156.76438313215453, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.12327174318069445, "obs_min": -2.0064826503219457, "obs_max": 1.222039548631157, "loss": 0.35693636536598206, "mae": 2.2873148918151855, "mean_q": 5.30022668838501, "_runtime": 10.702380657196045, "_timestamp": 1582186192.0060525, "_step": 81}
{"step": 811, "episode": 83, "duration": 0.08219320000000074, "episode_steps": 9, "sps": 109.49810933264453, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.13160113969485923, "obs_min": -2.2163112427928353, "obs_max": 1.3490743601155466, "loss": 0.35007914900779724, "mae": 2.29659366607666, "mean_q": 5.259105205535889, "_runtime": 10.811748504638672, "_timestamp": 1582186192.1154203, "_step": 82}
{"step": 820, "episode": 84, "duration": 0.10162290000000063, "episode_steps": 9, "sps": 88.56271568711328, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.1298499545017626, "obs_min": -2.456750435171601, "obs_max": 1.608525257568004, "loss": 0.33382686972618103, "mae": 2.29901385307312, "mean_q": 5.255648136138916, "_runtime": 10.921119928359985, "_timestamp": 1582186192.2247918, "_step": 83}
{"step": 832, "episode": 85, "duration": 0.0751179999999998, "episode_steps": 12, "sps": 159.74866210495532, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.75, "action_min": 0, "action_max": 1, "obs_mean": -0.10671073823086259, "obs_min": -2.4093042877728266, "obs_max": 1.5530211162720682, "loss": 0.35206475853919983, "mae": 2.3094322681427, "mean_q": 5.272008895874023, "_runtime": 11.01486325263977, "_timestamp": 1582186192.318535, "_step": 84}
{"step": 842, "episode": 86, "duration": 0.09298420000000007, "episode_steps": 10, "sps": 107.5451528324166, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.14111509524800123, "obs_min": -2.451915934374731, "obs_max": 1.574433815785225, "loss": 0.41164737939834595, "mae": 2.369877338409424, "mean_q": 5.26446008682251, "_runtime": 11.124228239059448, "_timestamp": 1582186192.4279, "_step": 85}
{"step": 851, "episode": 87, "duration": 0.058690099999999745, "episode_steps": 9, "sps": 153.3478389029843, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.1310184541040458, "obs_min": -2.173485217582556, "obs_max": 1.416664429010753, "loss": 0.33323943614959717, "mae": 2.362985849380493, "mean_q": 5.337735176086426, "_runtime": 11.202348232269287, "_timestamp": 1582186192.50602, "_step": 86}
{"step": 862, "episode": 88, "duration": 0.09540410000000143, "episode_steps": 11, "sps": 115.29902802919197, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8181818181818182, "action_min": 0, "action_max": 1, "obs_mean": -0.1287233240658322, "obs_min": -2.3294943193559, "obs_max": 1.3417683198070387, "loss": 0.27278244495391846, "mae": 2.3677620887756348, "mean_q": 5.462258815765381, "_runtime": 11.311723232269287, "_timestamp": 1582186192.615395, "_step": 87}
{"step": 871, "episode": 89, "duration": 0.07623889999999989, "episode_steps": 9, "sps": 118.04997186475688, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.13628825767765584, "obs_min": -2.4606868655131233, "obs_max": 1.540531612038262, "loss": 0.2995457053184509, "mae": 2.404863119125366, "mean_q": 5.551255226135254, "_runtime": 11.405462741851807, "_timestamp": 1582186192.7091346, "_step": 88}
{"step": 880, "episode": 90, "duration": 0.05412289999999942, "episode_steps": 9, "sps": 166.28820702512425, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.15254852065680996, "obs_min": -2.5308728084151646, "obs_max": 1.6069937720090974, "loss": 0.3472861051559448, "mae": 2.4301838874816895, "mean_q": 5.475558280944824, "_runtime": 11.467952966690063, "_timestamp": 1582186192.7716248, "_step": 89}
{"step": 894, "episode": 91, "duration": 0.10860629999999993, "episode_steps": 14, "sps": 128.90596586017577, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7142857142857143, "action_min": 0, "action_max": 1, "obs_mean": -0.09694033324310107, "obs_min": -2.1273049481359787, "obs_max": 1.232710762107146, "loss": 0.342900812625885, "mae": 2.440946102142334, "mean_q": 5.393225193023682, "_runtime": 11.592963457107544, "_timestamp": 1582186192.8966353, "_step": 90}
{"step": 903, "episode": 92, "duration": 0.07628549999999912, "episode_steps": 9, "sps": 117.97785948837071, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.1357160459242112, "obs_min": -2.159715854492891, "obs_max": 1.3469428187241563, "loss": 0.2646733224391937, "mae": 2.4478557109832764, "mean_q": 5.637908458709717, "_runtime": 11.671069383621216, "_timestamp": 1582186192.9747412, "_step": 91}
{"step": 913, "episode": 93, "duration": 0.1472514000000018, "episode_steps": 10, "sps": 67.91106909679553, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.13421873700115833, "obs_min": -2.2421521270260376, "obs_max": 1.3700830869478406, "loss": 0.32183775305747986, "mae": 2.458115816116333, "mean_q": 5.403864860534668, "_runtime": 11.827316045761108, "_timestamp": 1582186193.130988, "_step": 92}
{"step": 922, "episode": 94, "duration": 0.05663410000000013, "episode_steps": 9, "sps": 158.91485871586164, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.1360051403751285, "obs_min": -2.125056018317453, "obs_max": 1.3466628277342185, "loss": 0.3447696268558502, "mae": 2.5187559127807617, "mean_q": 5.481603145599365, "_runtime": 11.905437707901001, "_timestamp": 1582186193.2091095, "_step": 93}
{"step": 933, "episode": 95, "duration": 0.06434910000000116, "episode_steps": 11, "sps": 170.94256174522724, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.09068714358574229, "obs_min": -2.2638819088174973, "obs_max": 1.5959854985760904, "loss": 0.261985182762146, "mae": 2.4627747535705566, "mean_q": 5.438866138458252, "_runtime": 11.98355746269226, "_timestamp": 1582186193.2872293, "_step": 94}
{"step": 943, "episode": 96, "duration": 0.060211500000001195, "episode_steps": 10, "sps": 166.08123032975098, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.11358137420041617, "obs_min": -2.201083912308955, "obs_max": 1.4174103186447642, "loss": 0.3522578179836273, "mae": 2.555279493331909, "mean_q": 5.614405632019043, "_runtime": 12.046037912368774, "_timestamp": 1582186193.3497097, "_step": 95}
{"step": 951, "episode": 97, "duration": 0.11377169999999737, "episode_steps": 8, "sps": 70.31625615157535, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.875, "action_min": 0, "action_max": 1, "obs_mean": -0.14170569235846975, "obs_min": -2.1677567175700423, "obs_max": 1.3559742269846529, "loss": 0.3131355047225952, "mae": 2.509676218032837, "mean_q": 5.534689426422119, "_runtime": 12.186684846878052, "_timestamp": 1582186193.4903567, "_step": 96}
{"step": 962, "episode": 98, "duration": 0.09276889999999938, "episode_steps": 11, "sps": 118.57422045534736, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.1077780707680248, "obs_min": -2.0442286420184015, "obs_max": 1.3949343578703726, "loss": 0.36777201294898987, "mae": 2.58807373046875, "mean_q": 5.6071014404296875, "_runtime": 12.280399560928345, "_timestamp": 1582186193.5840714, "_step": 97}
{"step": 972, "episode": 99, "duration": 0.07272190000000123, "episode_steps": 10, "sps": 137.51015856296152, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.12722746433007934, "obs_min": -2.3674277669110757, "obs_max": 1.552629710303523, "loss": 0.29987913370132446, "mae": 2.529371976852417, "mean_q": 5.5758562088012695, "_runtime": 12.374140739440918, "_timestamp": 1582186193.6778126, "_step": 98}
{"step": 981, "episode": 100, "duration": 0.057710999999997625, "episode_steps": 9, "sps": 155.94947237095823, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.18243252596944678, "obs_min": -2.8873725952760045, "obs_max": 1.7216271156377165, "loss": 0.31108343601226807, "mae": 2.564527750015259, "mean_q": 5.650642395019531, "_runtime": 12.436637878417969, "_timestamp": 1582186193.7403097, "_step": 99}
{"step": 990, "episode": 101, "duration": 0.09563529999999787, "episode_steps": 9, "sps": 94.1075105112882, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.16183581855422494, "obs_min": -2.525631642692673, "obs_max": 1.5740265250670191, "loss": 0.2501988112926483, "mae": 2.5537166595458984, "mean_q": 5.751636028289795, "_runtime": 12.546023607254028, "_timestamp": 1582186193.8496954, "_step": 100}
{"step": 1002, "episode": 102, "duration": 0.12515309999999857, "episode_steps": 12, "sps": 95.88256303679363, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.75, "action_min": 0, "action_max": 1, "obs_mean": -0.11083857455893202, "obs_min": -2.2774895941373314, "obs_max": 1.3629696312518242, "loss": 0.23625129461288452, "mae": 2.5963504314422607, "mean_q": 5.861365795135498, "_runtime": 12.68662142753601, "_timestamp": 1582186193.9902933, "_step": 101}
{"step": 1012, "episode": 103, "duration": 0.08545369999999863, "episode_steps": 10, "sps": 117.02243437089511, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.10851058554971109, "obs_min": -2.0063700290007427, "obs_max": 1.1879888128668927, "loss": 0.2746853530406952, "mae": 2.571732759475708, "mean_q": 5.670995712280273, "_runtime": 12.780361890792847, "_timestamp": 1582186194.0840337, "_step": 102}
{"step": 1022, "episode": 104, "duration": 0.14393039999999857, "episode_steps": 10, "sps": 69.47802549009869, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.12270954788142921, "obs_min": -2.3506276338150354, "obs_max": 1.5629886870188134, "loss": 0.21609430015087128, "mae": 2.6041088104248047, "mean_q": 5.732496738433838, "_runtime": 12.936633586883545, "_timestamp": 1582186194.2403054, "_step": 103}
{"step": 1031, "episode": 105, "duration": 0.114481099999999, "episode_steps": 9, "sps": 78.61559681030387, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.14873126857119182, "obs_min": -2.2033799670120935, "obs_max": 1.3539097446381916, "loss": 0.23883305490016937, "mae": 2.641812562942505, "mean_q": 5.814220428466797, "_runtime": 13.092847108840942, "_timestamp": 1582186194.396519, "_step": 104}
{"step": 1040, "episode": 106, "duration": 0.10921009999999853, "episode_steps": 9, "sps": 82.40996025093028, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.14513635322973445, "obs_min": -2.1682687720458236, "obs_max": 1.3629591962412044, "loss": 0.28373345732688904, "mae": 2.6771209239959717, "mean_q": 5.778230667114258, "_runtime": 13.21785044670105, "_timestamp": 1582186194.5215223, "_step": 105}
{"step": 1049, "episode": 107, "duration": 0.09392080000000291, "episode_steps": 9, "sps": 95.82541886355015, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.1268092681719678, "obs_min": -2.455678550874657, "obs_max": 1.5801209277244361, "loss": 0.2600744366645813, "mae": 2.6802566051483154, "mean_q": 5.7423224449157715, "_runtime": 13.342827081680298, "_timestamp": 1582186194.646499, "_step": 106}
{"step": 1059, "episode": 108, "duration": 0.09033099999999905, "episode_steps": 10, "sps": 110.7039665231217, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7, "action_min": 0, "action_max": 1, "obs_mean": -0.10201406324146703, "obs_min": -1.8674139654758348, "obs_max": 1.2187844455399202, "loss": 0.22077956795692444, "mae": 2.6918368339538574, "mean_q": 5.713679313659668, "_runtime": 13.452190399169922, "_timestamp": 1582186194.7558622, "_step": 107}
{"step": 1070, "episode": 109, "duration": 0.08712759999999875, "episode_steps": 11, "sps": 126.251612577417, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.1036422964659978, "obs_min": -2.2771318145262827, "obs_max": 1.5940390781742293, "loss": 0.21881665289402008, "mae": 2.739548444747925, "mean_q": 5.839459419250488, "_runtime": 13.545953273773193, "_timestamp": 1582186194.849625, "_step": 108}
{"step": 1080, "episode": 110, "duration": 0.09401420000000016, "episode_steps": 10, "sps": 106.3669105305367, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.1332225123128034, "obs_min": -1.9452306400598987, "obs_max": 1.179506465472505, "loss": 0.23242127895355225, "mae": 2.7656619548797607, "mean_q": 5.812831401824951, "_runtime": 13.670930862426758, "_timestamp": 1582186194.9746027, "_step": 109}
{"step": 1091, "episode": 111, "duration": 0.08056919999999934, "episode_steps": 11, "sps": 136.52859901798814, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6363636363636364, "action_min": 0, "action_max": 1, "obs_mean": -0.12306986457694964, "obs_min": -1.8394488590376834, "obs_max": 1.1629528503562572, "loss": 0.28110215067863464, "mae": 2.746255397796631, "mean_q": 5.646036624908447, "_runtime": 13.764689683914185, "_timestamp": 1582186195.0683615, "_step": 110}
{"step": 1102, "episode": 112, "duration": 0.09568129999999897, "episode_steps": 11, "sps": 114.96499315958414, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6363636363636364, "action_min": 0, "action_max": 1, "obs_mean": -0.10815093391749904, "obs_min": -1.8855855971302045, "obs_max": 1.1947807696923147, "loss": 0.2452796995639801, "mae": 2.794144630432129, "mean_q": 5.797682762145996, "_runtime": 13.874036312103271, "_timestamp": 1582186195.1777081, "_step": 111}
{"step": 1112, "episode": 113, "duration": 0.12140709999999899, "episode_steps": 10, "sps": 82.36750568953615, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7, "action_min": 0, "action_max": 1, "obs_mean": -0.10182882432054499, "obs_min": -2.100089278441839, "obs_max": 1.393553401400704, "loss": 0.177515909075737, "mae": 2.931748628616333, "mean_q": 6.2164692878723145, "_runtime": 14.014670133590698, "_timestamp": 1582186195.318342, "_step": 112}
{"step": 1123, "episode": 114, "duration": 0.06467129999999699, "episode_steps": 11, "sps": 170.0909058577841, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6363636363636364, "action_min": 0, "action_max": 1, "obs_mean": -0.11988826515010803, "obs_min": -2.0174426968878514, "obs_max": 1.331030662189229, "loss": 0.250489205121994, "mae": 2.9512293338775635, "mean_q": 6.086975574493408, "_runtime": 14.092773199081421, "_timestamp": 1582186195.396445, "_step": 113}
{"step": 1134, "episode": 115, "duration": 0.10770029999999764, "episode_steps": 11, "sps": 102.13527724621233, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6363636363636364, "action_min": 0, "action_max": 1, "obs_mean": -0.12419629587228248, "obs_min": -2.0593640196599923, "obs_max": 1.3308321701476549, "loss": 0.2371322065591812, "mae": 2.9230756759643555, "mean_q": 6.005436420440674, "_runtime": 14.217794179916382, "_timestamp": 1582186195.521466, "_step": 114}
{"step": 1145, "episode": 116, "duration": 0.08553950000000299, "episode_steps": 11, "sps": 128.59556111503593, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.10414149379715032, "obs_min": -1.834639290797811, "obs_max": 1.145632722424872, "loss": 0.1905239224433899, "mae": 2.9926748275756836, "mean_q": 6.167484760284424, "_runtime": 14.311506509780884, "_timestamp": 1582186195.6151783, "_step": 115}
{"step": 1154, "episode": 117, "duration": 0.05618439999999936, "episode_steps": 9, "sps": 160.18681342152098, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6666666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.13923272243078164, "obs_min": -1.9129854283695717, "obs_max": 1.1843348103420444, "loss": 0.2412242591381073, "mae": 2.9661388397216797, "mean_q": 6.038948059082031, "_runtime": 14.389627456665039, "_timestamp": 1582186195.6932993, "_step": 116}
{"step": 1163, "episode": 118, "duration": 0.10451860000000224, "episode_steps": 9, "sps": 86.10907532247664, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6666666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.13515650936524576, "obs_min": -1.848467810376242, "obs_max": 1.1486711349924144, "loss": 0.27026140689849854, "mae": 2.953450918197632, "mean_q": 5.97755241394043, "_runtime": 14.49899411201477, "_timestamp": 1582186195.802666, "_step": 117}
{"step": 1171, "episode": 119, "duration": 0.07474310000000273, "episode_steps": 8, "sps": 107.03329136735977, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.75, "action_min": 0, "action_max": 1, "obs_mean": -0.14188866665977523, "obs_min": -1.9020315509881098, "obs_max": 1.1854849917356054, "loss": 0.1844167411327362, "mae": 2.887462615966797, "mean_q": 5.884422302246094, "_runtime": 14.59274411201477, "_timestamp": 1582186195.896416, "_step": 118}
{"step": 1179, "episode": 120, "duration": 0.04937249999999693, "episode_steps": 8, "sps": 162.03352068460168, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.75, "action_min": 0, "action_max": 1, "obs_mean": -0.12966313515979677, "obs_min": -1.8960710386467066, "obs_max": 1.219351342537824, "loss": 0.306862473487854, "mae": 2.936635732650757, "mean_q": 5.905036926269531, "_runtime": 14.655235052108765, "_timestamp": 1582186195.958907, "_step": 119}
{"step": 1188, "episode": 121, "duration": 0.10192410000000152, "episode_steps": 9, "sps": 88.30100045033379, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7777777777777778, "action_min": 0, "action_max": 1, "obs_mean": -0.1571945241467988, "obs_min": -2.1734754322017587, "obs_max": 1.3336054634314465, "loss": 0.2435893416404724, "mae": 2.984678030014038, "mean_q": 6.129757404327393, "_runtime": 14.780241966247559, "_timestamp": 1582186196.0839138, "_step": 120}
{"step": 1200, "episode": 122, "duration": 0.1342478000000007, "episode_steps": 12, "sps": 89.38693967424373, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6666666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.09261365554100999, "obs_min": -1.7700441060461798, "obs_max": 1.158510218873331, "loss": 0.2650977671146393, "mae": 2.9136667251586914, "mean_q": 5.915040493011475, "_runtime": 14.920838832855225, "_timestamp": 1582186196.2245107, "_step": 121}
{"step": 1208, "episode": 123, "duration": 0.09875390000000195, "episode_steps": 8, "sps": 81.00945886693935, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 1.0, "action_min": 1, "action_max": 1, "obs_mean": -0.16291818356639748, "obs_min": -2.5277365373455476, "obs_max": 1.5285425797058305, "loss": 0.29920461773872375, "mae": 2.9558331966400146, "mean_q": 5.97695779800415, "_runtime": 15.045845985412598, "_timestamp": 1582186196.3495178, "_step": 122}
{"step": 1219, "episode": 124, "duration": 0.06557829999999853, "episode_steps": 11, "sps": 167.73841346909336, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.110917006281649, "obs_min": -2.038724564288567, "obs_max": 1.3674344877005167, "loss": 0.23149266839027405, "mae": 3.003653049468994, "mean_q": 6.119116306304932, "_runtime": 15.123974084854126, "_timestamp": 1582186196.427646, "_step": 123}
{"step": 1229, "episode": 125, "duration": 0.08587189999999723, "episode_steps": 10, "sps": 116.45252987298899, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7, "action_min": 0, "action_max": 1, "obs_mean": -0.12216605605438588, "obs_min": -1.8615254799033831, "obs_max": 1.1702495660083663, "loss": 0.22069048881530762, "mae": 2.976605176925659, "mean_q": 6.061400890350342, "_runtime": 15.233337163925171, "_timestamp": 1582186196.537009, "_step": 124}
{"step": 1237, "episode": 126, "duration": 0.09446450000000084, "episode_steps": 8, "sps": 84.68789862858459, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.75, "action_min": 0, "action_max": 1, "obs_mean": -0.14150850338858256, "obs_min": -1.9118806066113851, "obs_max": 1.2036912676682303, "loss": 0.1523415446281433, "mae": 2.9802515506744385, "mean_q": 6.110692024230957, "_runtime": 15.342685222625732, "_timestamp": 1582186196.646357, "_step": 125}
{"step": 1246, "episode": 127, "duration": 0.055137099999999606, "episode_steps": 9, "sps": 163.22947706716647, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6666666666666666, "action_min": 0, "action_max": 1, "obs_mean": -0.12636080718884624, "obs_min": -1.899287486380411, "obs_max": 1.209797545989966, "loss": 0.2683173716068268, "mae": 3.0405073165893555, "mean_q": 6.153696060180664, "_runtime": 15.405188083648682, "_timestamp": 1582186196.70886, "_step": 126}
{"step": 1257, "episode": 128, "duration": 0.07613219999999998, "episode_steps": 11, "sps": 144.485513357029, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6363636363636364, "action_min": 0, "action_max": 1, "obs_mean": -0.09755830722169531, "obs_min": -2.0376426601569912, "obs_max": 1.4120577017488611, "loss": 0.2307129055261612, "mae": 3.045105218887329, "mean_q": 6.1585893630981445, "_runtime": 15.498924255371094, "_timestamp": 1582186196.802596, "_step": 127}
{"step": 1268, "episode": 129, "duration": 0.07765440000000012, "episode_steps": 11, "sps": 141.65327399348888, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.7272727272727273, "action_min": 0, "action_max": 1, "obs_mean": -0.1280937929181124, "obs_min": -2.344580759476041, "obs_max": 1.5427132128432557, "loss": 0.17385977506637573, "mae": 3.003131628036499, "mean_q": 6.1054229736328125, "_runtime": 15.577043771743774, "_timestamp": 1582186196.8807156, "_step": 128}
{"step": 1278, "episode": 130, "duration": 0.0607135999999997, "episode_steps": 10, "sps": 164.70774258156408, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.11520842289640813, "obs_min": -2.3527360879179056, "obs_max": 1.5401293736276043, "loss": 0.1866939812898636, "mae": 3.129082441329956, "mean_q": 6.405113220214844, "_runtime": 15.65516471862793, "_timestamp": 1582186196.9588366, "_step": 129}
{"step": 1287, "episode": 131, "duration": 0.09874260000000135, "episode_steps": 9, "sps": 91.14607069289119, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8888888888888888, "action_min": 0, "action_max": 1, "obs_mean": -0.14515459189471658, "obs_min": -2.211003387794791, "obs_max": 1.3528163461342968, "loss": 0.23342108726501465, "mae": 2.9817183017730713, "mean_q": 5.9757585525512695, "_runtime": 15.764530181884766, "_timestamp": 1582186197.068202, "_step": 130}
{"step": 1298, "episode": 132, "duration": 0.0960856000000021, "episode_steps": 11, "sps": 114.48125421498912, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6363636363636364, "action_min": 0, "action_max": 1, "obs_mean": -0.09001552593463726, "obs_min": -1.7851176003604827, "obs_max": 1.1868224215271104, "loss": 0.24960209429264069, "mae": 3.0670201778411865, "mean_q": 6.130517959594727, "_runtime": 15.889541387557983, "_timestamp": 1582186197.1932132, "_step": 131}
{"step": 1308, "episode": 133, "duration": 0.1119312999999984, "episode_steps": 10, "sps": 89.34051511954335, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.8, "action_min": 0, "action_max": 1, "obs_mean": -0.11362124908771262, "obs_min": -2.1381717899940167, "obs_max": 1.3994190345558846, "loss": 0.1990176886320114, "mae": 3.125154495239258, "mean_q": 6.253483772277832, "_runtime": 16.014516353607178, "_timestamp": 1582186197.3181882, "_step": 132}
{"step": 1319, "episode": 134, "duration": 0.08972340000000045, "episode_steps": 11, "sps": 122.59900984581441, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.6363636363636364, "action_min": 0, "action_max": 1, "obs_mean": -0.10891487259258295, "obs_min": -1.5453607886790812, "obs_max": 1.001051075471534, "loss": 0.19362477958202362, "mae": 3.0688445568084717, "mean_q": 6.100400924682617, "_runtime": 16.123899936676025, "_timestamp": 1582186197.4275718, "_step": 133}
{"step": 1330, "episode": 135, "duration": 0.06559910000000002, "episode_steps": 11, "sps": 167.68522738879034, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5454545454545454, "action_min": 0, "action_max": 1, "obs_mean": -0.11971268020523777, "obs_min": -1.5749807202055548, "obs_max": 0.9637099009871726, "loss": 0.15479305386543274, "mae": 3.1474030017852783, "mean_q": 6.2741007804870605, "_runtime": 16.202019453048706, "_timestamp": 1582186197.5056913, "_step": 134}
{"step": 1346, "episode": 136, "duration": 0.14263090000000034, "episode_steps": 16, "sps": 112.17765575341642, "episode_reward": 16.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": -0.0873153416102051, "obs_min": -1.5223441009927847, "obs_max": 0.9366644465640601, "loss": 0.2330477237701416, "mae": 3.2192564010620117, "mean_q": 6.341159820556641, "_runtime": 16.358271598815918, "_timestamp": 1582186197.6619434, "_step": 135}
{"step": 1359, "episode": 137, "duration": 0.1700324000000002, "episode_steps": 13, "sps": 76.45601661800919, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46153846153846156, "action_min": 0, "action_max": 1, "obs_mean": -0.10919683450942098, "obs_min": -1.5428037164331072, "obs_max": 0.9814558232229138, "loss": 0.21035657823085785, "mae": 3.171572685241699, "mean_q": 6.214500427246094, "_runtime": 16.545730113983154, "_timestamp": 1582186197.849402, "_step": 136}
{"step": 1389, "episode": 138, "duration": 0.1755849000000005, "episode_steps": 30, "sps": 170.857516791022, "episode_reward": 30.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": -0.1365396844034169, "obs_min": -1.3418227871376898, "obs_max": 0.9435516844044214, "loss": 0.22404876351356506, "mae": 3.225017547607422, "mean_q": 6.247286796569824, "_runtime": 16.733216047286987, "_timestamp": 1582186198.036888, "_step": 137}
{"step": 1411, "episode": 139, "duration": 0.16947270000000003, "episode_steps": 22, "sps": 129.81441848746138, "episode_reward": 22.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.22727272727272727, "action_min": 0, "action_max": 1, "obs_mean": 0.01990244480032283, "obs_min": -2.373109671395743, "obs_max": 3.303742138820379, "loss": 0.2145182490348816, "mae": 3.3675537109375, "mean_q": 6.475561141967773, "_runtime": 16.920706272125244, "_timestamp": 1582186198.224378, "_step": 138}
{"step": 1421, "episode": 140, "duration": 0.07444680000000048, "episode_steps": 10, "sps": 134.32410795359823, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.12492211277332724, "obs_min": -1.9498147924874971, "obs_max": 3.024766637977419, "loss": 0.6624146699905396, "mae": 3.501528263092041, "mean_q": 6.630293846130371, "_runtime": 17.014445781707764, "_timestamp": 1582186198.3181176, "_step": 139}
{"step": 1430, "episode": 141, "duration": 0.09771549999999962, "episode_steps": 9, "sps": 92.10411858916993, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.1350185292870933, "obs_min": -1.585021681206524, "obs_max": 2.4523586134258073, "loss": 0.9829038977622986, "mae": 3.466439723968506, "mean_q": 6.550849437713623, "_runtime": 17.123830556869507, "_timestamp": 1582186198.4275024, "_step": 140}
{"step": 1453, "episode": 142, "duration": 0.17708430000000064, "episode_steps": 23, "sps": 129.88164394020203, "episode_reward": 23.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.43478260869565216, "action_min": 0, "action_max": 1, "obs_mean": -0.1316281653373878, "obs_min": -0.9523916617688573, "obs_max": 0.5748623446880856, "loss": 0.6522396802902222, "mae": 3.4901185035705566, "mean_q": 6.5839619636535645, "_runtime": 17.311319828033447, "_timestamp": 1582186198.6149917, "_step": 141}
{"step": 1477, "episode": 143, "duration": 0.23546169999999833, "episode_steps": 24, "sps": 101.9274047541497, "episode_reward": 24.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4583333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.08397774238497924, "obs_min": -1.3190024294958322, "obs_max": 2.0545344856718892, "loss": 0.6960558891296387, "mae": 3.5517494678497314, "mean_q": 6.717748641967773, "_runtime": 17.561300039291382, "_timestamp": 1582186198.8649719, "_step": 142}
{"step": 1559, "episode": 144, "duration": 0.5306139999999999, "episode_steps": 82, "sps": 154.53795037447185, "episode_reward": 82.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": -0.1478532844551814, "obs_min": -1.8186558130219352, "obs_max": 1.5157133322192686, "loss": 0.41900917887687683, "mae": 3.6387031078338623, "mean_q": 6.943282127380371, "_runtime": 18.1081326007843, "_timestamp": 1582186199.4118044, "_step": 143}
{"step": 1568, "episode": 145, "duration": 0.053389000000002795, "episode_steps": 9, "sps": 168.57405083443274, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.17091593700710886, "obs_min": -1.7430876730636091, "obs_max": 2.8927208684742296, "loss": 0.5023232698440552, "mae": 3.867753267288208, "mean_q": 7.32875919342041, "_runtime": 18.170613527297974, "_timestamp": 1582186199.4742854, "_step": 144}
{"step": 1578, "episode": 146, "duration": 0.0829373000000011, "episode_steps": 10, "sps": 120.57301117832226, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.09759487297582188, "obs_min": -1.7757147243049607, "obs_max": 2.612755590825135, "loss": 0.7688134908676147, "mae": 3.7692253589630127, "mean_q": 7.1234002113342285, "_runtime": 18.280003786087036, "_timestamp": 1582186199.5836756, "_step": 145}
{"step": 1588, "episode": 147, "duration": 0.0676887999999991, "episode_steps": 10, "sps": 147.73492808263896, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.11925410958787985, "obs_min": -1.600543145561553, "obs_max": 2.4959562053912214, "loss": 0.659443736076355, "mae": 3.8030993938446045, "mean_q": 7.2513933181762695, "_runtime": 18.35810399055481, "_timestamp": 1582186199.6617758, "_step": 146}
{"step": 1598, "episode": 148, "duration": 0.06258369999999758, "episode_steps": 10, "sps": 159.786014569295, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.15060085620225344, "obs_min": -1.566394447340178, "obs_max": 2.583212614392307, "loss": 0.23971839249134064, "mae": 3.858771562576294, "mean_q": 7.4572882652282715, "_runtime": 18.420616626739502, "_timestamp": 1582186199.7242885, "_step": 147}
{"step": 1609, "episode": 149, "duration": 0.08819230000000289, "episode_steps": 11, "sps": 124.72744219166117, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.09090909090909091, "action_min": 0, "action_max": 1, "obs_mean": 0.13249873957702418, "obs_min": -1.7551420200361691, "obs_max": 2.738725310376813, "loss": 0.5528225302696228, "mae": 3.9090726375579834, "mean_q": 7.4683637619018555, "_runtime": 18.52996587753296, "_timestamp": 1582186199.8336377, "_step": 148}
{"step": 1619, "episode": 150, "duration": 0.1015289000000017, "episode_steps": 10, "sps": 98.49412334812878, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.13072284858118532, "obs_min": -1.9651174725633198, "obs_max": 3.0737062911776287, "loss": 1.451451301574707, "mae": 4.1568779945373535, "mean_q": 7.846803188323975, "_runtime": 18.65497398376465, "_timestamp": 1582186199.9586458, "_step": 149}
{"step": 1628, "episode": 151, "duration": 0.084912199999998, "episode_steps": 9, "sps": 105.99183627323532, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1402849645090755, "obs_min": -1.7584334860051536, "obs_max": 2.7643545649433086, "loss": 1.1473592519760132, "mae": 4.0318756103515625, "mean_q": 7.661172866821289, "_runtime": 18.76432228088379, "_timestamp": 1582186200.067994, "_step": 150}
{"step": 1637, "episode": 152, "duration": 0.05452449999999942, "episode_steps": 9, "sps": 165.06341186072493, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1299042270330625, "obs_min": -1.8090029311719296, "obs_max": 2.842688212716558, "loss": 0.700580358505249, "mae": 4.091135501861572, "mean_q": 7.83587646484375, "_runtime": 18.826839923858643, "_timestamp": 1582186200.1305118, "_step": 151}
{"step": 1646, "episode": 153, "duration": 0.11767550000000071, "episode_steps": 9, "sps": 76.48151059481324, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1462781221511436, "obs_min": -1.7541208343519306, "obs_max": 2.8034803451908106, "loss": 1.1400253772735596, "mae": 4.14234733581543, "mean_q": 7.87473726272583, "_runtime": 18.951812028884888, "_timestamp": 1582186200.2554839, "_step": 152}
{"step": 1655, "episode": 154, "duration": 0.07569429999999855, "episode_steps": 9, "sps": 118.89930945923501, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.13172000815358528, "obs_min": -1.7842268963806291, "obs_max": 2.752297355840007, "loss": 0.5626664757728577, "mae": 4.08854866027832, "mean_q": 7.765384197235107, "_runtime": 19.045552253723145, "_timestamp": 1582186200.349224, "_step": 153}
{"step": 1666, "episode": 155, "duration": 0.060317900000001146, "episode_steps": 11, "sps": 182.36709169251236, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.09090909090909091, "action_min": 0, "action_max": 1, "obs_mean": 0.12320734751176575, "obs_min": -1.7496245997873268, "obs_max": 2.789970313409817, "loss": 1.8042649030685425, "mae": 4.295520305633545, "mean_q": 8.038715362548828, "_runtime": 19.123672246932983, "_timestamp": 1582186200.427344, "_step": 154}
{"step": 1677, "episode": 156, "duration": 0.07154510000000158, "episode_steps": 11, "sps": 153.74917359818852, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.09090909090909091, "action_min": 0, "action_max": 1, "obs_mean": 0.12139406674100726, "obs_min": -1.7797273197863974, "obs_max": 2.791888542009006, "loss": 2.1676011085510254, "mae": 4.308887958526611, "mean_q": 8.049898147583008, "_runtime": 19.217434883117676, "_timestamp": 1582186200.5211067, "_step": 155}
{"step": 1685, "episode": 157, "duration": 0.11318610000000007, "episode_steps": 8, "sps": 70.68005700346593, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.14644453449374878, "obs_min": -1.5904166627248475, "obs_max": 2.6088070251944844, "loss": 0.4396117329597473, "mae": 4.227572441101074, "mean_q": 8.056966781616211, "_runtime": 19.34240961074829, "_timestamp": 1582186200.6460814, "_step": 156}
{"step": 1695, "episode": 158, "duration": 0.07154979999999966, "episode_steps": 10, "sps": 139.76279458503095, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.13404595132635738, "obs_min": -1.5555176667209065, "obs_max": 2.407908103385751, "loss": 1.9887813329696655, "mae": 4.3809590339660645, "mean_q": 8.096914291381836, "_runtime": 19.42052698135376, "_timestamp": 1582186200.7241988, "_step": 157}
{"step": 1706, "episode": 159, "duration": 0.08867389999999986, "episode_steps": 11, "sps": 124.05003050503042, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2727272727272727, "action_min": 0, "action_max": 1, "obs_mean": 0.12386884663869671, "obs_min": -1.1506929408915048, "obs_max": 2.008796797286223, "loss": 1.2686724662780762, "mae": 4.365466594696045, "mean_q": 8.166864395141602, "_runtime": 19.52989435195923, "_timestamp": 1582186200.8335662, "_step": 158}
{"step": 1718, "episode": 160, "duration": 0.07069900000000118, "episode_steps": 12, "sps": 169.73365959914284, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4166666666666667, "action_min": 0, "action_max": 1, "obs_mean": 0.11862860849959568, "obs_min": -1.314755449022925, "obs_max": 2.046868301641016, "loss": 2.713632583618164, "mae": 4.540822505950928, "mean_q": 8.332803726196289, "_runtime": 19.60802173614502, "_timestamp": 1582186200.9116936, "_step": 159}
{"step": 1726, "episode": 161, "duration": 0.0824543999999996, "episode_steps": 8, "sps": 97.02332440718797, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.25, "action_min": 0, "action_max": 1, "obs_mean": 0.14814554638258232, "obs_min": -1.1849978445217617, "obs_max": 1.9124791317161356, "loss": 2.007227897644043, "mae": 4.388871192932129, "mean_q": 8.076199531555176, "_runtime": 19.70176339149475, "_timestamp": 1582186201.0054352, "_step": 160}
{"step": 1735, "episode": 162, "duration": 0.07624410000000026, "episode_steps": 9, "sps": 118.04192062074272, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.15671815737727746, "obs_min": -1.1542373767077905, "obs_max": 1.8973124991888777, "loss": 2.289968729019165, "mae": 4.614108085632324, "mean_q": 8.493626594543457, "_runtime": 19.795534133911133, "_timestamp": 1582186201.099206, "_step": 161}
{"step": 1760, "episode": 163, "duration": 0.21701119999999818, "episode_steps": 25, "sps": 115.20142739176691, "episode_reward": 25.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.44, "action_min": 0, "action_max": 1, "obs_mean": 0.12672196363374366, "obs_min": -1.0166305978994197, "obs_max": 1.8796692042377794, "loss": 1.578224778175354, "mae": 4.481582164764404, "mean_q": 8.226407051086426, "_runtime": 20.029881477355957, "_timestamp": 1582186201.3335533, "_step": 162}
{"step": 1774, "episode": 164, "duration": 0.14202929999999725, "episode_steps": 14, "sps": 98.57121030660765, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.35714285714285715, "action_min": 0, "action_max": 1, "obs_mean": 0.13484115435690242, "obs_min": -0.7777195571492541, "obs_max": 1.6741518298950149, "loss": 2.0987746715545654, "mae": 4.545154094696045, "mean_q": 8.264596939086914, "_runtime": 20.18611478805542, "_timestamp": 1582186201.4897866, "_step": 163}
{"step": 1790, "episode": 165, "duration": 0.14115229999999812, "episode_steps": 16, "sps": 113.35274026707474, "episode_reward": 16.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4375, "action_min": 0, "action_max": 1, "obs_mean": 0.0900419761091661, "obs_min": -0.8095015442099647, "obs_max": 1.2982820266868487, "loss": 1.1168497800827026, "mae": 4.370272636413574, "mean_q": 8.081713676452637, "_runtime": 20.342338800430298, "_timestamp": 1582186201.6460106, "_step": 164}
{"step": 1799, "episode": 166, "duration": 0.075970599999998, "episode_steps": 9, "sps": 118.46688060908085, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.12751875729402481, "obs_min": -1.223432512673906, "obs_max": 1.8637233138514926, "loss": 1.6331863403320312, "mae": 4.582608699798584, "mean_q": 8.53757381439209, "_runtime": 20.420459747314453, "_timestamp": 1582186201.7241316, "_step": 165}
{"step": 1809, "episode": 167, "duration": 0.07172419999999846, "episode_steps": 10, "sps": 139.42295626859854, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.1190527961320704, "obs_min": -1.1605931305096697, "obs_max": 1.797988940883021, "loss": 1.0554667711257935, "mae": 4.473445415496826, "mean_q": 8.41629409790039, "_runtime": 20.514219760894775, "_timestamp": 1582186201.8178916, "_step": 166}
{"step": 1819, "episode": 168, "duration": 0.06584140000000005, "episode_steps": 10, "sps": 151.8801240556852, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.1390561357718392, "obs_min": -1.325506472763018, "obs_max": 2.082238170042924, "loss": 1.5331705808639526, "mae": 4.641780376434326, "mean_q": 8.685934066772461, "_runtime": 20.592323541641235, "_timestamp": 1582186201.8959954, "_step": 167}
{"step": 1833, "episode": 169, "duration": 0.10480309999999804, "episode_steps": 14, "sps": 133.58383482931575, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.42857142857142855, "action_min": 0, "action_max": 1, "obs_mean": 0.07598552401153125, "obs_min": -1.177282459732615, "obs_max": 1.7194471087488157, "loss": 1.9448574781417847, "mae": 4.75626802444458, "mean_q": 8.85448932647705, "_runtime": 20.717331647872925, "_timestamp": 1582186202.0210035, "_step": 168}
{"step": 1845, "episode": 170, "duration": 0.13913089999999784, "episode_steps": 12, "sps": 86.24971160252817, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": 0.10866571925720929, "obs_min": -0.9574840783174822, "obs_max": 1.5176186890134842, "loss": 1.4073200225830078, "mae": 4.613771915435791, "mean_q": 8.650897026062012, "_runtime": 20.87355327606201, "_timestamp": 1582186202.177225, "_step": 169}
{"step": 1857, "episode": 171, "duration": 0.09632980000000302, "episode_steps": 12, "sps": 124.57204312683743, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4166666666666667, "action_min": 0, "action_max": 1, "obs_mean": 0.09868515473614024, "obs_min": -1.015214472717099, "obs_max": 1.519985799802007, "loss": 1.6213315725326538, "mae": 4.721879482269287, "mean_q": 8.76619815826416, "_runtime": 20.982938289642334, "_timestamp": 1582186202.2866101, "_step": 170}
{"step": 1876, "episode": 172, "duration": 0.11925469999999905, "episode_steps": 19, "sps": 159.3228610696279, "episode_reward": 19.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47368421052631576, "action_min": 0, "action_max": 1, "obs_mean": 0.12268497928947018, "obs_min": -0.7443261978708866, "obs_max": 1.225235132927447, "loss": 2.948927164077759, "mae": 4.769536972045898, "mean_q": 8.641990661621094, "_runtime": 21.12353754043579, "_timestamp": 1582186202.4272094, "_step": 171}
{"step": 1895, "episode": 173, "duration": 0.10956390000000127, "episode_steps": 19, "sps": 173.41478351902205, "episode_reward": 19.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47368421052631576, "action_min": 0, "action_max": 1, "obs_mean": 0.07237819295343721, "obs_min": -0.7348931389580352, "obs_max": 1.1279639243832604, "loss": 1.2268623113632202, "mae": 4.686326503753662, "mean_q": 8.705742835998535, "_runtime": 21.248544692993164, "_timestamp": 1582186202.5522165, "_step": 172}
{"step": 1904, "episode": 174, "duration": 0.07272009999999796, "episode_steps": 9, "sps": 123.76220604757492, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.10354445144718635, "obs_min": -1.031557473040824, "obs_max": 1.5982750658228497, "loss": 1.7940627336502075, "mae": 4.941007614135742, "mean_q": 9.168734550476074, "_runtime": 21.32664656639099, "_timestamp": 1582186202.6303184, "_step": 173}
{"step": 1913, "episode": 175, "duration": 0.07757259999999988, "episode_steps": 9, "sps": 116.02034739070257, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.136183800546238, "obs_min": -1.1501929370369588, "obs_max": 1.8865260404938118, "loss": 0.7320507764816284, "mae": 4.778748989105225, "mean_q": 9.071995735168457, "_runtime": 21.42042112350464, "_timestamp": 1582186202.724093, "_step": 174}
{"step": 1925, "episode": 176, "duration": 0.13910339999999977, "episode_steps": 12, "sps": 86.2667627103293, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.08915656859847576, "obs_min": -1.195513099126131, "obs_max": 1.810198499681461, "loss": 2.267930269241333, "mae": 4.993859767913818, "mean_q": 9.299098014831543, "_runtime": 21.576632261276245, "_timestamp": 1582186202.880304, "_step": 175}
{"step": 1935, "episode": 177, "duration": 0.07189350000000161, "episode_steps": 10, "sps": 139.0946330335813, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.14194044430815725, "obs_min": -1.545051612315067, "obs_max": 2.3801030838182857, "loss": 2.408177614212036, "mae": 5.1486406326293945, "mean_q": 9.518293380737305, "_runtime": 21.654747009277344, "_timestamp": 1582186202.9584188, "_step": 176}
{"step": 1943, "episode": 178, "duration": 0.11318449999999913, "episode_steps": 8, "sps": 70.68105615168209, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.14477216759362987, "obs_min": -1.5811847243375374, "obs_max": 2.54056748775442, "loss": 2.490978479385376, "mae": 5.097438335418701, "mean_q": 9.434624671936035, "_runtime": 21.795364141464233, "_timestamp": 1582186203.099036, "_step": 177}
{"step": 1951, "episode": 179, "duration": 0.07395690000000243, "episode_steps": 8, "sps": 108.17111047109515, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.1431702302715612, "obs_min": -1.5702739596799322, "obs_max": 2.517022674412324, "loss": 1.340216875076294, "mae": 4.997608184814453, "mean_q": 9.432140350341797, "_runtime": 21.87348484992981, "_timestamp": 1582186203.1771567, "_step": 178}
{"step": 1962, "episode": 180, "duration": 0.10683669999999879, "episode_steps": 11, "sps": 102.9608739318991, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.18181818181818182, "action_min": 0, "action_max": 1, "obs_mean": 0.11926464991908442, "obs_min": -1.5459503549852827, "obs_max": 2.329284687913508, "loss": 2.8225533962249756, "mae": 5.18732213973999, "mean_q": 9.574150085449219, "_runtime": 21.998475551605225, "_timestamp": 1582186203.3021474, "_step": 179}
{"step": 1973, "episode": 181, "duration": 0.06689380000000256, "episode_steps": 11, "sps": 164.439753758937, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.18181818181818182, "action_min": 0, "action_max": 1, "obs_mean": 0.13252021213829168, "obs_min": -1.5391947396247585, "obs_max": 2.479132711016101, "loss": 1.6333900690078735, "mae": 5.033635139465332, "mean_q": 9.40071964263916, "_runtime": 22.076595783233643, "_timestamp": 1582186203.3802676, "_step": 180}
{"step": 1983, "episode": 182, "duration": 0.06622089999999758, "episode_steps": 10, "sps": 151.0097265364917, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.11557988969905097, "obs_min": -1.4050391744029274, "obs_max": 2.1610858455767326, "loss": 2.034170627593994, "mae": 4.978301525115967, "mean_q": 9.308600425720215, "_runtime": 22.154712438583374, "_timestamp": 1582186203.4583843, "_step": 181}
{"step": 1994, "episode": 183, "duration": 0.06857650000000248, "episode_steps": 11, "sps": 160.4048033947431, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.18181818181818182, "action_min": 0, "action_max": 1, "obs_mean": 0.1273099503175087, "obs_min": -1.5774364412074502, "obs_max": 2.3375146554170216, "loss": 2.842031717300415, "mae": 5.295520782470703, "mean_q": 9.775211334228516, "_runtime": 22.232831716537476, "_timestamp": 1582186203.5365036, "_step": 182}
{"step": 2004, "episode": 184, "duration": 0.06154889999999824, "episode_steps": 10, "sps": 162.47244061226579, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.11095648823360664, "obs_min": -2.001832918218554, "obs_max": 2.9819560554991256, "loss": 1.7866995334625244, "mae": 4.986465930938721, "mean_q": 9.2488431930542, "_runtime": 22.310953855514526, "_timestamp": 1582186203.6146257, "_step": 183}
{"step": 2014, "episode": 185, "duration": 0.06327869999999791, "episode_steps": 10, "sps": 158.03105942442448, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.15770756165832228, "obs_min": -1.552687636614686, "obs_max": 2.594517549335012, "loss": 3.1346468925476074, "mae": 5.232682228088379, "mean_q": 9.487053871154785, "_runtime": 22.389090299606323, "_timestamp": 1582186203.6927621, "_step": 184}
{"step": 2023, "episode": 186, "duration": 0.12112030000000118, "episode_steps": 9, "sps": 74.30628887147664, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.13393590085900584, "obs_min": -1.3753387604243092, "obs_max": 2.2652567505960075, "loss": 4.147699356079102, "mae": 5.308406352996826, "mean_q": 9.494035720825195, "_runtime": 22.529724836349487, "_timestamp": 1582186203.8333967, "_step": 185}
{"step": 2036, "episode": 187, "duration": 0.08089179999999985, "episode_steps": 13, "sps": 160.70850197424244, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.38461538461538464, "action_min": 0, "action_max": 1, "obs_mean": 0.08014552010719743, "obs_min": -1.1619358208330697, "obs_max": 1.6987008642916337, "loss": 2.567079782485962, "mae": 5.154383659362793, "mean_q": 9.39383316040039, "_runtime": 22.623449563980103, "_timestamp": 1582186203.9271214, "_step": 186}
{"step": 2046, "episode": 188, "duration": 0.0645421000000006, "episode_steps": 10, "sps": 154.93762985709958, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.1208199922270781, "obs_min": -1.2129726473687825, "obs_max": 1.811572762093566, "loss": 1.9147861003875732, "mae": 5.033725738525391, "mean_q": 9.198102951049805, "_runtime": 22.701565504074097, "_timestamp": 1582186204.0052373, "_step": 187}
{"step": 2055, "episode": 189, "duration": 0.0824185999999969, "episode_steps": 9, "sps": 109.19865176065036, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.1519788847917224, "obs_min": -1.194198384898516, "obs_max": 1.8958406462259245, "loss": 3.4656448364257812, "mae": 5.466602325439453, "mean_q": 9.804725646972656, "_runtime": 22.79532551765442, "_timestamp": 1582186204.0989974, "_step": 188}
{"step": 2065, "episode": 190, "duration": 0.1101624000000001, "episode_steps": 10, "sps": 90.77507389091006, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.11039264518213972, "obs_min": -1.1490320138986012, "obs_max": 1.7812420237415134, "loss": 2.316573143005371, "mae": 5.197016716003418, "mean_q": 9.478313446044922, "_runtime": 22.935908555984497, "_timestamp": 1582186204.2395804, "_step": 189}
{"step": 2074, "episode": 191, "duration": 0.05444519999999997, "episode_steps": 9, "sps": 165.3038284366667, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.12435247541615195, "obs_min": -1.1728964632239636, "obs_max": 1.8440779244024155, "loss": 2.1889607906341553, "mae": 5.2462158203125, "mean_q": 9.604401588439941, "_runtime": 22.99842643737793, "_timestamp": 1582186204.3020983, "_step": 190}
{"step": 2086, "episode": 192, "duration": 0.07132579999999678, "episode_steps": 12, "sps": 168.24206668555476, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.11691587136841446, "obs_min": -0.9726580571052159, "obs_max": 1.6426194089949901, "loss": 2.0539228916168213, "mae": 5.189359664916992, "mean_q": 9.497496604919434, "_runtime": 23.09216618537903, "_timestamp": 1582186204.395838, "_step": 191}
{"step": 2100, "episode": 193, "duration": 0.09755300000000133, "episode_steps": 14, "sps": 143.5117320840959, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.35714285714285715, "action_min": 0, "action_max": 1, "obs_mean": 0.0939357014410339, "obs_min": -0.991397827939072, "obs_max": 1.4289081152642318, "loss": 2.0021843910217285, "mae": 5.209592342376709, "mean_q": 9.634625434875488, "_runtime": 23.20153498649597, "_timestamp": 1582186204.5052068, "_step": 192}
{"step": 2112, "episode": 194, "duration": 0.09008049999999912, "episode_steps": 12, "sps": 133.21418064953144, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4166666666666667, "action_min": 0, "action_max": 1, "obs_mean": 0.09236680982972573, "obs_min": -1.0015280722967108, "obs_max": 1.5104097697597498, "loss": 1.52875816822052, "mae": 5.298074722290039, "mean_q": 9.909407615661621, "_runtime": 23.295260906219482, "_timestamp": 1582186204.5989327, "_step": 193}
{"step": 2125, "episode": 195, "duration": 0.10506399999999871, "episode_steps": 13, "sps": 123.73410492652249, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.38461538461538464, "action_min": 0, "action_max": 1, "obs_mean": 0.10251035550155402, "obs_min": -1.1209526524982143, "obs_max": 1.6882740067885376, "loss": 2.2178573608398438, "mae": 5.288888931274414, "mean_q": 9.840486526489258, "_runtime": 23.435892343521118, "_timestamp": 1582186204.7395642, "_step": 194}
{"step": 2135, "episode": 196, "duration": 0.06379909999999711, "episode_steps": 10, "sps": 156.74202300660124, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.1292855559566644, "obs_min": -0.9374205203491642, "obs_max": 1.6873217383778434, "loss": 2.7223687171936035, "mae": 5.327027797698975, "mean_q": 9.8482666015625, "_runtime": 23.514012098312378, "_timestamp": 1582186204.817684, "_step": 195}
{"step": 2145, "episode": 197, "duration": 0.08275740000000198, "episode_steps": 10, "sps": 120.8351156512863, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.11879099101911991, "obs_min": -1.1944578570785647, "obs_max": 1.7691899867490941, "loss": 3.2390105724334717, "mae": 5.4527268409729, "mean_q": 9.90552806854248, "_runtime": 23.607737064361572, "_timestamp": 1582186204.911409, "_step": 196}
{"step": 2154, "episode": 198, "duration": 0.05820310000000006, "episode_steps": 9, "sps": 154.63093890187963, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.13093056556021182, "obs_min": -1.203862448295616, "obs_max": 1.9081239792794784, "loss": 1.832875370979309, "mae": 5.430407524108887, "mean_q": 10.084481239318848, "_runtime": 23.67023205757141, "_timestamp": 1582186204.973904, "_step": 197}
{"step": 2163, "episode": 199, "duration": 0.09885870000000097, "episode_steps": 9, "sps": 91.0390284314877, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.1610492784375319, "obs_min": -1.3454992349662824, "obs_max": 2.2113332443959015, "loss": 3.924463987350464, "mae": 5.435000896453857, "mean_q": 9.665276527404785, "_runtime": 23.79525637626648, "_timestamp": 1582186205.0989282, "_step": 198}
{"step": 2173, "episode": 200, "duration": 0.05932420000000249, "episode_steps": 10, "sps": 168.56527353086227, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.12416817979614561, "obs_min": -1.3975791395123358, "obs_max": 2.0971739636909366, "loss": 2.526242733001709, "mae": 5.260274887084961, "mean_q": 9.51097297668457, "_runtime": 23.857719898223877, "_timestamp": 1582186205.1613917, "_step": 199}
{"step": 2182, "episode": 201, "duration": 0.08901919999999919, "episode_steps": 9, "sps": 101.10178478350831, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.1293457007321122, "obs_min": -0.9513393756019637, "obs_max": 1.583509083072069, "loss": 2.050274133682251, "mae": 5.166362762451172, "mean_q": 9.439542770385742, "_runtime": 23.967106580734253, "_timestamp": 1582186205.2707784, "_step": 200}
{"step": 2193, "episode": 202, "duration": 0.06542730000000319, "episode_steps": 11, "sps": 168.12553781066106, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.36363636363636365, "action_min": 0, "action_max": 1, "obs_mean": 0.1125777088605636, "obs_min": -1.026563488166403, "obs_max": 1.5294451737749064, "loss": 2.1984286308288574, "mae": 5.22730827331543, "mean_q": 9.506755828857422, "_runtime": 24.045206785202026, "_timestamp": 1582186205.3488786, "_step": 201}
{"step": 2203, "episode": 203, "duration": 0.08192929999999876, "episode_steps": 10, "sps": 122.05645599315692, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.1324532593597868, "obs_min": -1.1795030952659764, "obs_max": 1.8378166089831134, "loss": 3.2218570709228516, "mae": 5.255763053894043, "mean_q": 9.415183067321777, "_runtime": 24.138949871063232, "_timestamp": 1582186205.4426217, "_step": 202}
{"step": 2212, "episode": 204, "duration": 0.05860090000000184, "episode_steps": 9, "sps": 153.58125899089805, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.1547674874269251, "obs_min": -1.516715164891393, "obs_max": 2.4230986283942397, "loss": 2.317277669906616, "mae": 5.339961528778076, "mean_q": 9.68986988067627, "_runtime": 24.217071533203125, "_timestamp": 1582186205.5207434, "_step": 203}
{"step": 2221, "episode": 205, "duration": 0.15004880000000043, "episode_steps": 9, "sps": 59.98048634844114, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.1590326792911374, "obs_min": -1.5902350473785063, "obs_max": 2.5491744013514057, "loss": 2.5897376537323, "mae": 5.360858917236328, "mean_q": 9.73546314239502, "_runtime": 24.388935565948486, "_timestamp": 1582186205.6926074, "_step": 204}
{"step": 2230, "episode": 206, "duration": 0.08687830000000218, "episode_steps": 9, "sps": 103.59318725158957, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.173486932922821, "obs_min": -1.7140194337431047, "obs_max": 2.822329756717492, "loss": 2.231808662414551, "mae": 5.277068614959717, "mean_q": 9.728914260864258, "_runtime": 24.482680320739746, "_timestamp": 1582186205.7863522, "_step": 205}
{"step": 2239, "episode": 207, "duration": 0.09133819999999915, "episode_steps": 9, "sps": 98.53489558585656, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.0, "action_min": 0, "action_max": 0, "obs_mean": 0.15300986628862076, "obs_min": -1.7821163356958294, "obs_max": 2.817573708020938, "loss": 2.213345766067505, "mae": 5.264791011810303, "mean_q": 9.743282318115234, "_runtime": 24.592077493667603, "_timestamp": 1582186205.8957493, "_step": 206}
{"step": 2249, "episode": 208, "duration": 0.08325329999999909, "episode_steps": 10, "sps": 120.1153587905838, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.1452543884485103, "obs_min": -1.7641934030445234, "obs_max": 2.719466245889929, "loss": 2.240922451019287, "mae": 5.265370845794678, "mean_q": 9.737154006958008, "_runtime": 24.701414585113525, "_timestamp": 1582186206.0050864, "_step": 207}
{"step": 2259, "episode": 209, "duration": 0.0708707000000004, "episode_steps": 10, "sps": 141.10203511465167, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.14869797280005917, "obs_min": -1.521189073792357, "obs_max": 2.4709677953544684, "loss": 1.9005781412124634, "mae": 5.271474361419678, "mean_q": 9.886621475219727, "_runtime": 24.779533863067627, "_timestamp": 1582186206.0832057, "_step": 208}
{"step": 2270, "episode": 210, "duration": 0.10970900000000228, "episode_steps": 11, "sps": 100.26524715383215, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.18181818181818182, "action_min": 0, "action_max": 1, "obs_mean": 0.11169694910204737, "obs_min": -1.4230102719763198, "obs_max": 2.3187113352240165, "loss": 1.9153841733932495, "mae": 5.3734283447265625, "mean_q": 10.030233383178711, "_runtime": 24.90455436706543, "_timestamp": 1582186206.2082262, "_step": 209}
{"step": 2281, "episode": 211, "duration": 0.09064529999999849, "episode_steps": 11, "sps": 121.35212746827672, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.09090909090909091, "action_min": 0, "action_max": 1, "obs_mean": 0.11567517900763592, "obs_min": -1.7969691551598976, "obs_max": 2.773921596399044, "loss": 2.254610300064087, "mae": 5.417726516723633, "mean_q": 10.138197898864746, "_runtime": 25.01388931274414, "_timestamp": 1582186206.3175611, "_step": 210}
{"step": 2290, "episode": 212, "duration": 0.07716929999999778, "episode_steps": 9, "sps": 116.62668962916936, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.13898115808000075, "obs_min": -1.6085225626421686, "obs_max": 2.536818728544704, "loss": 2.453066110610962, "mae": 5.499149799346924, "mean_q": 10.286219596862793, "_runtime": 25.107632637023926, "_timestamp": 1582186206.4113045, "_step": 211}
{"step": 2300, "episode": 213, "duration": 0.10381389999999868, "episode_steps": 10, "sps": 96.32621450499525, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.1547276414042023, "obs_min": -1.533130448541213, "obs_max": 2.509340133609289, "loss": 2.252331495285034, "mae": 5.4294562339782715, "mean_q": 10.14622688293457, "_runtime": 25.232656002044678, "_timestamp": 1582186206.5363278, "_step": 212}
{"step": 2309, "episode": 214, "duration": 0.05878279999999947, "episode_steps": 9, "sps": 153.10601060174204, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.15793729739022866, "obs_min": -1.5522876253932665, "obs_max": 2.497539478247823, "loss": 1.5876879692077637, "mae": 5.413756370544434, "mean_q": 10.196773529052734, "_runtime": 25.295122146606445, "_timestamp": 1582186206.598794, "_step": 213}
{"step": 2319, "episode": 215, "duration": 0.09172639999999888, "episode_steps": 10, "sps": 109.0198677807057, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.14972313374725973, "obs_min": -1.5358972172739058, "obs_max": 2.5154958710904527, "loss": 2.14432430267334, "mae": 5.3641533851623535, "mean_q": 9.995013236999512, "_runtime": 25.404489994049072, "_timestamp": 1582186206.7081618, "_step": 214}
{"step": 2328, "episode": 216, "duration": 0.09975080000000247, "episode_steps": 9, "sps": 90.22484030203043, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1111111111111111, "action_min": 0, "action_max": 1, "obs_mean": 0.1550408314101927, "obs_min": -1.3741338624575248, "obs_max": 2.3044136800721877, "loss": 2.073674201965332, "mae": 5.312142372131348, "mean_q": 9.895092010498047, "_runtime": 25.529500722885132, "_timestamp": 1582186206.8331726, "_step": 215}
{"step": 2338, "episode": 217, "duration": 0.06088100000000196, "episode_steps": 10, "sps": 164.25485783741524, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.126378787152228, "obs_min": -1.5873346326265938, "obs_max": 2.5198748809363196, "loss": 1.8022611141204834, "mae": 5.370513439178467, "mean_q": 10.057920455932617, "_runtime": 25.59199547767639, "_timestamp": 1582186206.8956673, "_step": 216}
{"step": 2350, "episode": 218, "duration": 0.0944800999999984, "episode_steps": 12, "sps": 127.01087318917108, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.25, "action_min": 0, "action_max": 1, "obs_mean": 0.08669726419980801, "obs_min": -1.6051398877661516, "obs_max": 2.320597937274715, "loss": 2.728330373764038, "mae": 5.463800430297852, "mean_q": 10.073063850402832, "_runtime": 25.701362133026123, "_timestamp": 1582186207.005034, "_step": 217}
{"step": 2360, "episode": 219, "duration": 0.06484260000000219, "episode_steps": 10, "sps": 154.2196025452351, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.1, "action_min": 0, "action_max": 1, "obs_mean": 0.11708231909111666, "obs_min": -1.547781971906983, "obs_max": 2.4162338536620744, "loss": 2.346710681915283, "mae": 5.420657157897949, "mean_q": 10.028318405151367, "_runtime": 25.779465436935425, "_timestamp": 1582186207.0831373, "_step": 218}
{"step": 2370, "episode": 220, "duration": 0.06033130000000142, "episode_steps": 10, "sps": 165.75144245192405, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.11583396834423576, "obs_min": -1.1672100646553434, "obs_max": 1.8156056088071877, "loss": 2.3476009368896484, "mae": 5.397048473358154, "mean_q": 9.930645942687988, "_runtime": 25.857601165771484, "_timestamp": 1582186207.161273, "_step": 219}
{"step": 2380, "episode": 221, "duration": 0.08144679999999838, "episode_steps": 10, "sps": 122.7795321608731, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.1255840078696023, "obs_min": -1.2125082491733625, "obs_max": 1.84195341062751, "loss": 2.700611114501953, "mae": 5.455325126647949, "mean_q": 10.002542495727539, "_runtime": 25.951356410980225, "_timestamp": 1582186207.2550282, "_step": 220}
{"step": 2390, "episode": 222, "duration": 0.08510079999999931, "episode_steps": 10, "sps": 117.50770850567892, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.11937182687789002, "obs_min": -1.188315307599392, "obs_max": 1.8711177650754964, "loss": 2.522956609725952, "mae": 5.476307392120361, "mean_q": 10.09294605255127, "_runtime": 26.060710906982422, "_timestamp": 1582186207.3643827, "_step": 221}
{"step": 2401, "episode": 223, "duration": 0.09789440000000127, "episode_steps": 11, "sps": 112.36597803347135, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2727272727272727, "action_min": 0, "action_max": 1, "obs_mean": 0.14556717153156642, "obs_min": -1.135301488932785, "obs_max": 1.9407992798344986, "loss": 1.6903454065322876, "mae": 5.464000225067139, "mean_q": 10.239001274108887, "_runtime": 26.170058965682983, "_timestamp": 1582186207.4737308, "_step": 222}
{"step": 2411, "episode": 224, "duration": 0.05998419999999882, "episode_steps": 10, "sps": 166.71056711601048, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.11439270302344015, "obs_min": -1.200402087567686, "obs_max": 1.9712219204238117, "loss": 3.6256210803985596, "mae": 5.497756004333496, "mean_q": 9.926281929016113, "_runtime": 26.248193979263306, "_timestamp": 1582186207.5518658, "_step": 223}
{"step": 2423, "episode": 225, "duration": 0.10541410000000084, "episode_steps": 12, "sps": 113.83676377258739, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.1187722042730928, "obs_min": -1.3174392099387258, "obs_max": 2.0476502112172454, "loss": 2.792851448059082, "mae": 5.56982421875, "mean_q": 10.140499114990234, "_runtime": 26.3575656414032, "_timestamp": 1582186207.6612375, "_step": 224}
{"step": 2431, "episode": 226, "duration": 0.10721729999999852, "episode_steps": 8, "sps": 74.61482428675326, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.125, "action_min": 0, "action_max": 1, "obs_mean": 0.1537279154836839, "obs_min": -1.372119576944215, "obs_max": 2.223475492864156, "loss": 3.208207607269287, "mae": 5.45977783203125, "mean_q": 9.952245712280273, "_runtime": 26.48254680633545, "_timestamp": 1582186207.7862186, "_step": 225}
{"step": 2442, "episode": 227, "duration": 0.09297049999999984, "episode_steps": 11, "sps": 118.31710058566985, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2727272727272727, "action_min": 0, "action_max": 1, "obs_mean": 0.10638045360972676, "obs_min": -1.3369810941517124, "obs_max": 2.0240446215282772, "loss": 3.1453397274017334, "mae": 5.628570079803467, "mean_q": 10.204944610595703, "_runtime": 26.59190535545349, "_timestamp": 1582186207.8955772, "_step": 226}
{"step": 2454, "episode": 228, "duration": 0.09955730000000074, "episode_steps": 12, "sps": 120.5336022571917, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.25, "action_min": 0, "action_max": 1, "obs_mean": 0.09777266820437992, "obs_min": -1.3816803005924156, "obs_max": 2.0998638739884705, "loss": 2.2687923908233643, "mae": 5.467161178588867, "mean_q": 10.023299217224121, "_runtime": 26.71691656112671, "_timestamp": 1582186208.0205884, "_step": 227}
{"step": 2464, "episode": 229, "duration": 0.05944069999999968, "episode_steps": 10, "sps": 168.23489629159909, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2, "action_min": 0, "action_max": 1, "obs_mean": 0.13934675531504045, "obs_min": -1.5420473191963375, "obs_max": 2.3864429308122244, "loss": 1.5825517177581787, "mae": 5.2988433837890625, "mean_q": 9.923663139343262, "_runtime": 26.77939486503601, "_timestamp": 1582186208.0830667, "_step": 228}
{"step": 2475, "episode": 230, "duration": 0.089458699999998, "episode_steps": 11, "sps": 122.96176895036754, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2727272727272727, "action_min": 0, "action_max": 1, "obs_mean": 0.10218156364106723, "obs_min": -1.4058602513137384, "obs_max": 2.088443495184316, "loss": 2.36391282081604, "mae": 5.659118175506592, "mean_q": 10.549243927001953, "_runtime": 26.88875961303711, "_timestamp": 1582186208.1924314, "_step": 229}
{"step": 2491, "episode": 231, "duration": 0.11483470000000295, "episode_steps": 16, "sps": 139.33070753003742, "episode_reward": 16.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.375, "action_min": 0, "action_max": 1, "obs_mean": 0.06214866868262632, "obs_min": -1.4152434402446883, "obs_max": 2.023637937205727, "loss": 1.647240161895752, "mae": 5.368277072906494, "mean_q": 10.099435806274414, "_runtime": 27.013771057128906, "_timestamp": 1582186208.317443, "_step": 230}
{"step": 2500, "episode": 232, "duration": 0.13445500000000266, "episode_steps": 9, "sps": 66.93689338440238, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.16470010425366388, "obs_min": -1.1481328405048195, "obs_max": 1.9743521144947715, "loss": 1.5213531255722046, "mae": 5.4831390380859375, "mean_q": 10.341154098510742, "_runtime": 27.169991970062256, "_timestamp": 1582186208.4736638, "_step": 231}
{"step": 2512, "episode": 233, "duration": 0.138281199999998, "episode_steps": 12, "sps": 86.77969239491829, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.09205339974994663, "obs_min": -1.4047435320825012, "obs_max": 1.971009606241254, "loss": 1.880966305732727, "mae": 5.488865375518799, "mean_q": 10.319150924682617, "_runtime": 27.326234817504883, "_timestamp": 1582186208.6299067, "_step": 232}
{"step": 2525, "episode": 234, "duration": 0.10284640000000067, "episode_steps": 13, "sps": 126.40209088504717, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3076923076923077, "action_min": 0, "action_max": 1, "obs_mean": 0.11613085790124635, "obs_min": -1.1875582066477153, "obs_max": 2.0161940044703344, "loss": 2.38322377204895, "mae": 5.506589412689209, "mean_q": 10.20975112915039, "_runtime": 27.435599088668823, "_timestamp": 1582186208.739271, "_step": 233}
{"step": 2536, "episode": 235, "duration": 0.08976960000000034, "episode_steps": 11, "sps": 122.53591416247771, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2727272727272727, "action_min": 0, "action_max": 1, "obs_mean": 0.13497588732045324, "obs_min": -1.3485131583072383, "obs_max": 2.06507619753702, "loss": 2.9154982566833496, "mae": 5.605231761932373, "mean_q": 10.169782638549805, "_runtime": 27.54498028755188, "_timestamp": 1582186208.8486521, "_step": 234}
{"step": 2545, "episode": 236, "duration": 0.054617600000000266, "episode_steps": 9, "sps": 164.78204827747751, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.12832265288578565, "obs_min": -1.225491026834972, "obs_max": 1.9181218751070022, "loss": 2.056002378463745, "mae": 5.514679431915283, "mean_q": 10.095641136169434, "_runtime": 27.607459783554077, "_timestamp": 1582186208.9111316, "_step": 235}
{"step": 2554, "episode": 237, "duration": 0.07896539999999774, "episode_steps": 9, "sps": 113.97396834563311, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.13959751288097216, "obs_min": -1.1499776721598927, "obs_max": 1.9215364183968993, "loss": 2.207812786102295, "mae": 5.529660224914551, "mean_q": 10.134385108947754, "_runtime": 27.701205492019653, "_timestamp": 1582186209.0048773, "_step": 236}
{"step": 2562, "episode": 238, "duration": 0.07125130000000013, "episode_steps": 8, "sps": 112.2786531614158, "episode_reward": 8.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.125, "action_min": 0, "action_max": 1, "obs_mean": 0.12335691855394745, "obs_min": -1.2224656868582577, "obs_max": 1.9858519902422245, "loss": 2.218085289001465, "mae": 5.452917098999023, "mean_q": 10.027807235717773, "_runtime": 27.779348611831665, "_timestamp": 1582186209.0830204, "_step": 237}
{"step": 2572, "episode": 239, "duration": 0.11816589999999749, "episode_steps": 10, "sps": 84.62678319210713, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.11292048975845445, "obs_min": -1.2039002845995113, "obs_max": 1.778091664200545, "loss": 2.06472110748291, "mae": 5.565081596374512, "mean_q": 10.281822204589844, "_runtime": 27.919940948486328, "_timestamp": 1582186209.2236128, "_step": 238}
{"step": 2584, "episode": 240, "duration": 0.07241249999999866, "episode_steps": 12, "sps": 165.71724495080576, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.10484990700088427, "obs_min": -1.1664497239225438, "obs_max": 1.7191559642158887, "loss": 1.871727466583252, "mae": 5.490720272064209, "mean_q": 10.285414695739746, "_runtime": 28.013681888580322, "_timestamp": 1582186209.3173537, "_step": 239}
{"step": 2596, "episode": 241, "duration": 0.07105419999999896, "episode_steps": 12, "sps": 168.88516090533952, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.12282514449417181, "obs_min": -1.1788155902933657, "obs_max": 1.8052776660994758, "loss": 2.0362937450408936, "mae": 5.378964900970459, "mean_q": 10.003556251525879, "_runtime": 28.091801404953003, "_timestamp": 1582186209.3954732, "_step": 240}
{"step": 2612, "episode": 242, "duration": 0.15329429999999888, "episode_steps": 16, "sps": 104.37439617781037, "episode_reward": 16.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": 0.07827956010934282, "obs_min": -1.218773493505608, "obs_max": 1.7516599660530954, "loss": 2.4772703647613525, "mae": 5.411990165710449, "mean_q": 9.9217529296875, "_runtime": 28.263696908950806, "_timestamp": 1582186209.5673687, "_step": 241}
{"step": 2623, "episode": 243, "duration": 0.11951760000000178, "episode_steps": 11, "sps": 92.03665401580885, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2727272727272727, "action_min": 0, "action_max": 1, "obs_mean": 0.138234068968405, "obs_min": -1.1302613144668403, "obs_max": 1.7782733527213261, "loss": 2.4564151763916016, "mae": 5.459965229034424, "mean_q": 10.027347564697266, "_runtime": 28.4042911529541, "_timestamp": 1582186209.707963, "_step": 242}
{"step": 2635, "episode": 244, "duration": 0.12749060000000156, "episode_steps": 12, "sps": 94.12458644009718, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4166666666666667, "action_min": 0, "action_max": 1, "obs_mean": 0.0847167034961948, "obs_min": -1.0182011662520056, "obs_max": 1.5806083670895916, "loss": 2.0327112674713135, "mae": 5.379188537597656, "mean_q": 9.964340209960938, "_runtime": 28.544894695281982, "_timestamp": 1582186209.8485665, "_step": 243}
{"step": 2644, "episode": 245, "duration": 0.10322150000000363, "episode_steps": 9, "sps": 87.19113750526473, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.11900163604437476, "obs_min": -1.22592842963112, "obs_max": 1.8796568287593254, "loss": 2.0962648391723633, "mae": 5.252505302429199, "mean_q": 9.603082656860352, "_runtime": 28.669920444488525, "_timestamp": 1582186209.9735923, "_step": 244}
{"step": 2654, "episode": 246, "duration": 0.1055513000000019, "episode_steps": 10, "sps": 94.74066164983113, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.12025092861778193, "obs_min": -1.0201332688563771, "obs_max": 1.5934575249003873, "loss": 1.8493585586547852, "mae": 5.508209705352783, "mean_q": 10.238801002502441, "_runtime": 28.779253482818604, "_timestamp": 1582186210.0829253, "_step": 245}
{"step": 2668, "episode": 247, "duration": 0.13085350000000062, "episode_steps": 14, "sps": 106.98987799332791, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.35714285714285715, "action_min": 0, "action_max": 1, "obs_mean": 0.0854756337412079, "obs_min": -0.9597296098859609, "obs_max": 1.6233124765913123, "loss": 2.484588146209717, "mae": 5.360476493835449, "mean_q": 9.857131004333496, "_runtime": 28.935494899749756, "_timestamp": 1582186210.2391667, "_step": 246}
{"step": 2677, "episode": 248, "duration": 0.07525740000000525, "episode_steps": 9, "sps": 119.58956860055453, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.12142904416201267, "obs_min": -1.0262174074370267, "obs_max": 1.709780460413871, "loss": 2.2880046367645264, "mae": 5.450181484222412, "mean_q": 9.988758087158203, "_runtime": 29.029236793518066, "_timestamp": 1582186210.3329086, "_step": 247}
{"step": 2689, "episode": 249, "duration": 0.15496430000000316, "episode_steps": 12, "sps": 77.43719037223254, "episode_reward": 12.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.07745004354434191, "obs_min": -1.2068391737439548, "obs_max": 1.702502330351113, "loss": 1.4778939485549927, "mae": 5.316568851470947, "mean_q": 9.911032676696777, "_runtime": 29.201131343841553, "_timestamp": 1582186210.5048032, "_step": 248}
{"step": 2703, "episode": 250, "duration": 0.14424089999999978, "episode_steps": 14, "sps": 97.0598491828602, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.35714285714285715, "action_min": 0, "action_max": 1, "obs_mean": 0.0935885167235396, "obs_min": -1.342114026301626, "obs_max": 1.9776755794444587, "loss": 2.2189576625823975, "mae": 5.503138065338135, "mean_q": 10.224138259887695, "_runtime": 29.357354164123535, "_timestamp": 1582186210.661026, "_step": 249}
{"step": 2712, "episode": 251, "duration": 0.07587220000000627, "episode_steps": 9, "sps": 118.62052240477087, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.159925911447117, "obs_min": -1.1672038256503607, "obs_max": 1.9832665961554783, "loss": 2.4258341789245605, "mae": 5.328516483306885, "mean_q": 9.847146987915039, "_runtime": 29.451101303100586, "_timestamp": 1582186210.7547731, "_step": 250}
{"step": 2723, "episode": 252, "duration": 0.07706089999999932, "episode_steps": 11, "sps": 142.7442451359911, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2727272727272727, "action_min": 0, "action_max": 1, "obs_mean": 0.10872130960226518, "obs_min": -1.371395880663959, "obs_max": 2.04069999860307, "loss": 1.89532470703125, "mae": 5.458682537078857, "mean_q": 10.130309104919434, "_runtime": 29.544827699661255, "_timestamp": 1582186210.8484995, "_step": 251}
{"step": 2732, "episode": 253, "duration": 0.05941590000000474, "episode_steps": 9, "sps": 151.4746052824123, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.15422744447286413, "obs_min": -1.1297494705650257, "obs_max": 1.9380802937235635, "loss": 1.1653465032577515, "mae": 5.336065769195557, "mean_q": 10.159307479858398, "_runtime": 29.622948169708252, "_timestamp": 1582186210.92662, "_step": 252}
{"step": 2741, "episode": 254, "duration": 0.054625300000004984, "episode_steps": 9, "sps": 164.75882054650828, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.2222222222222222, "action_min": 0, "action_max": 1, "obs_mean": 0.1513539966273693, "obs_min": -1.1846303976427408, "obs_max": 1.986075921796603, "loss": 1.343940258026123, "mae": 5.356677532196045, "mean_q": 10.140726089477539, "_runtime": 29.685441255569458, "_timestamp": 1582186210.989113, "_step": 253}
{"step": 2751, "episode": 255, "duration": 0.06031530000000629, "episode_steps": 10, "sps": 165.79541177775718, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3, "action_min": 0, "action_max": 1, "obs_mean": 0.12314474997262877, "obs_min": -1.1416026286927718, "obs_max": 1.8707514159278968, "loss": 1.7070868015289307, "mae": 5.506841659545898, "mean_q": 10.368101119995117, "_runtime": 29.76356291770935, "_timestamp": 1582186211.0672348, "_step": 254}
{"step": 2762, "episode": 256, "duration": 0.06965430000000339, "episode_steps": 11, "sps": 157.92277002280497, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.36363636363636365, "action_min": 0, "action_max": 1, "obs_mean": 0.10993866060572371, "obs_min": -1.1400564858423636, "obs_max": 1.7751555486148463, "loss": 2.2237327098846436, "mae": 5.563603401184082, "mean_q": 10.313446998596191, "_runtime": 29.84168004989624, "_timestamp": 1582186211.145352, "_step": 255}
{"step": 2771, "episode": 257, "duration": 0.06680800000000175, "episode_steps": 9, "sps": 134.71440546042035, "episode_reward": 9.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.3333333333333333, "action_min": 0, "action_max": 1, "obs_mean": 0.14364450603016088, "obs_min": -0.9460086221337489, "obs_max": 1.6639934011181747, "loss": 1.5483691692352295, "mae": 5.343222618103027, "mean_q": 9.965519905090332, "_runtime": 29.91981863975525, "_timestamp": 1582186211.2234905, "_step": 256}
{"step": 2782, "episode": 258, "duration": 0.09518380000000093, "episode_steps": 11, "sps": 115.56588411053029, "episode_reward": 11.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.45454545454545453, "action_min": 0, "action_max": 1, "obs_mean": 0.11577012074692003, "obs_min": -0.9610414168730504, "obs_max": 1.5670486906898056, "loss": 1.710220456123352, "mae": 5.307516098022461, "mean_q": 9.937575340270996, "_runtime": 30.044793367385864, "_timestamp": 1582186211.3484652, "_step": 257}
{"step": 2795, "episode": 259, "duration": 0.0820661000000058, "episode_steps": 13, "sps": 158.40889234408704, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46153846153846156, "action_min": 0, "action_max": 1, "obs_mean": 0.09467836979101014, "obs_min": -0.9881066006161741, "obs_max": 1.544813969833316, "loss": 1.6998364925384521, "mae": 5.3701276779174805, "mean_q": 10.040149688720703, "_runtime": 30.138537883758545, "_timestamp": 1582186211.4422097, "_step": 258}
{"step": 2813, "episode": 260, "duration": 0.10238130000000467, "episode_steps": 18, "sps": 175.81335654068837, "episode_reward": 18.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": 0.08556481229229829, "obs_min": -0.9924420027087592, "obs_max": 1.464434590111469, "loss": 2.2545289993286133, "mae": 5.352685451507568, "mean_q": 9.835050582885742, "_runtime": 30.247902154922485, "_timestamp": 1582186211.551574, "_step": 259}
{"step": 2823, "episode": 261, "duration": 0.10579750000000132, "episode_steps": 10, "sps": 94.52019187598833, "episode_reward": 10.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4, "action_min": 0, "action_max": 1, "obs_mean": 0.1275516187222609, "obs_min": -0.9973570808287127, "obs_max": 1.630026927082179, "loss": 1.8906265497207642, "mae": 5.264632225036621, "mean_q": 9.762406349182129, "_runtime": 30.372915029525757, "_timestamp": 1582186211.6765869, "_step": 260}
{"step": 2836, "episode": 262, "duration": 0.07772130000000033, "episode_steps": 13, "sps": 167.26431493039803, "episode_reward": 13.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5384615384615384, "action_min": 0, "action_max": 1, "obs_mean": 0.08998181998757539, "obs_min": -1.0043480080046823, "obs_max": 1.5115455405158518, "loss": 2.1567957401275635, "mae": 5.314934253692627, "mean_q": 9.73727798461914, "_runtime": 30.46663761138916, "_timestamp": 1582186211.7703094, "_step": 261}
{"step": 2850, "episode": 263, "duration": 0.12064609999999476, "episode_steps": 14, "sps": 116.04187785598215, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5714285714285714, "action_min": 0, "action_max": 1, "obs_mean": 0.09703204508912588, "obs_min": -0.7906129464724518, "obs_max": 1.30125537302886, "loss": 1.4147928953170776, "mae": 5.446917533874512, "mean_q": 10.204862594604492, "_runtime": 30.607253789901733, "_timestamp": 1582186211.9109256, "_step": 262}
{"step": 2878, "episode": 264, "duration": 0.28762130000000496, "episode_steps": 28, "sps": 97.35023101557331, "episode_reward": 28.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": 0.0913298321146803, "obs_min": -0.9926557178839264, "obs_max": 1.3818429647125177, "loss": 2.1042542457580566, "mae": 5.355439186096191, "mean_q": 9.90056324005127, "_runtime": 30.90410804748535, "_timestamp": 1582186212.20778, "_step": 263}
{"step": 2892, "episode": 265, "duration": 0.08260620000000074, "episode_steps": 14, "sps": 169.4788042544007, "episode_reward": 14.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": 0.09900035818352666, "obs_min": -0.8349159599528388, "obs_max": 1.298971270765201, "loss": 1.8437031507492065, "mae": 5.33269739151001, "mean_q": 9.847742080688477, "_runtime": 31.013476133346558, "_timestamp": 1582186212.317148, "_step": 264}
{"step": 2909, "episode": 266, "duration": 0.10262620000000311, "episode_steps": 17, "sps": 165.64970738465894, "episode_reward": 17.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47058823529411764, "action_min": 0, "action_max": 1, "obs_mean": 0.09999403255449374, "obs_min": -0.9716223810329723, "obs_max": 1.446977994032148, "loss": 1.995464563369751, "mae": 5.322895050048828, "mean_q": 9.875190734863281, "_runtime": 31.122859239578247, "_timestamp": 1582186212.426531, "_step": 265}
{"step": 2947, "episode": 267, "duration": 0.24202410000000185, "episode_steps": 38, "sps": 157.00915735251039, "episode_reward": 38.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": 0.062486011561012224, "obs_min": -0.7946314888057429, "obs_max": 1.1025860170138648, "loss": 1.5735807418823242, "mae": 5.359414577484131, "mean_q": 9.987374305725098, "_runtime": 31.388466835021973, "_timestamp": 1582186212.6921387, "_step": 266}
{"step": 2963, "episode": 268, "duration": 0.13278600000000296, "episode_steps": 16, "sps": 120.49463045802753, "episode_reward": 16.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5, "action_min": 0, "action_max": 1, "obs_mean": 0.09154349879387835, "obs_min": -0.7879115078426266, "obs_max": 1.1800149271383804, "loss": 2.1093344688415527, "mae": 5.385088920593262, "mean_q": 9.925209045410156, "_runtime": 31.529064893722534, "_timestamp": 1582186212.8327367, "_step": 267}
{"step": 2994, "episode": 269, "duration": 0.2056009000000003, "episode_steps": 31, "sps": 150.77755009827268, "episode_reward": 31.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5483870967741935, "action_min": 0, "action_max": 1, "obs_mean": 0.10202401062194831, "obs_min": -0.8029541624739617, "obs_max": 1.179534420724998, "loss": 1.7364249229431152, "mae": 5.395387172698975, "mean_q": 10.020489692687988, "_runtime": 31.747798204421997, "_timestamp": 1582186213.05147, "_step": 268}
{"step": 3054, "episode": 270, "duration": 0.38367900000000077, "episode_steps": 60, "sps": 156.38072451189635, "episode_reward": 60.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.48333333333333334, "action_min": 0, "action_max": 1, "obs_mean": 0.1843072461500112, "obs_min": -0.7339062750602007, "obs_max": 2.2828946278526017, "loss": 1.9985451698303223, "mae": 5.4537811279296875, "mean_q": 10.054282188415527, "_runtime": 32.15403985977173, "_timestamp": 1582186213.4577117, "_step": 269}
{"step": 3087, "episode": 271, "duration": 0.2106116, "episode_steps": 33, "sps": 156.68652628820064, "episode_reward": 33.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.48484848484848486, "action_min": 0, "action_max": 1, "obs_mean": -0.1294915107696941, "obs_min": -0.9602289589909572, "obs_max": 0.5794345721988542, "loss": 1.697641134262085, "mae": 5.391362190246582, "mean_q": 9.99923324584961, "_runtime": 32.37275695800781, "_timestamp": 1582186213.6764288, "_step": 270}
{"step": 3126, "episode": 272, "duration": 0.27457569999999976, "episode_steps": 39, "sps": 142.03733250975972, "episode_reward": 39.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46153846153846156, "action_min": 0, "action_max": 1, "obs_mean": -0.09885982921631423, "obs_min": -0.8219574773011269, "obs_max": 0.6049351197510658, "loss": 1.435336947441101, "mae": 5.445566177368164, "mean_q": 10.208528518676758, "_runtime": 32.66960954666138, "_timestamp": 1582186213.9732814, "_step": 271}
{"step": 3169, "episode": 273, "duration": 0.2811645000000027, "episode_steps": 43, "sps": 152.93538124478584, "episode_reward": 43.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46511627906976744, "action_min": 0, "action_max": 1, "obs_mean": -0.11435800445948975, "obs_min": -0.8704269779614707, "obs_max": 0.5476762134818451, "loss": 1.6932733058929443, "mae": 5.406854152679443, "mean_q": 10.047839164733887, "_runtime": 32.96646571159363, "_timestamp": 1582186214.2701375, "_step": 272}
{"step": 3196, "episode": 274, "duration": 0.2619459999999947, "episode_steps": 27, "sps": 103.07467951410042, "episode_reward": 27.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4444444444444444, "action_min": 0, "action_max": 1, "obs_mean": -0.11916030186780838, "obs_min": -0.7052572664299801, "obs_max": 0.36465431740481724, "loss": 2.136502504348755, "mae": 5.480899333953857, "mean_q": 10.162312507629395, "_runtime": 33.24771428108215, "_timestamp": 1582186214.551386, "_step": 273}
{"step": 3232, "episode": 275, "duration": 0.2878181999999967, "episode_steps": 36, "sps": 125.0789560910339, "episode_reward": 36.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5277777777777778, "action_min": 0, "action_max": 1, "obs_mean": 0.11346454441397988, "obs_min": -0.7959602028468391, "obs_max": 0.744497385058825, "loss": 1.4872633218765259, "mae": 5.450082302093506, "mean_q": 10.172693252563477, "_runtime": 33.544548749923706, "_timestamp": 1582186214.8482206, "_step": 274}
{"step": 3268, "episode": 276, "duration": 0.2749062999999978, "episode_steps": 36, "sps": 130.95371040969334, "episode_reward": 36.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5277777777777778, "action_min": 0, "action_max": 1, "obs_mean": 0.09583726323153524, "obs_min": -0.2346181265603815, "obs_max": 0.7053661055038929, "loss": 1.6200612783432007, "mae": 5.497997283935547, "mean_q": 10.253047943115234, "_runtime": 33.82579851150513, "_timestamp": 1582186215.1294703, "_step": 275}
{"step": 3294, "episode": 277, "duration": 0.2441139000000021, "episode_steps": 26, "sps": 106.50765892478788, "episode_reward": 26.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5384615384615384, "action_min": 0, "action_max": 1, "obs_mean": 0.11291417836887853, "obs_min": -0.4315334282609481, "obs_max": 0.7476883435130097, "loss": 1.4941197633743286, "mae": 5.5249552726745605, "mean_q": 10.337530136108398, "_runtime": 34.09138631820679, "_timestamp": 1582186215.3950582, "_step": 276}
{"step": 3328, "episode": 278, "duration": 0.26900369999999896, "episode_steps": 34, "sps": 126.39231356297378, "episode_reward": 34.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5294117647058824, "action_min": 0, "action_max": 1, "obs_mean": 0.12732725323827057, "obs_min": -0.15881683220905848, "obs_max": 0.6065684366086537, "loss": 1.5053374767303467, "mae": 5.525792598724365, "mean_q": 10.320658683776855, "_runtime": 34.37263584136963, "_timestamp": 1582186215.6763077, "_step": 277}
{"step": 3395, "episode": 279, "duration": 0.5293259999999975, "episode_steps": 67, "sps": 126.57606087741829, "episode_reward": 67.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47761194029850745, "action_min": 0, "action_max": 1, "obs_mean": -0.059814921462367776, "obs_min": -0.7243630984337474, "obs_max": 0.7052465754950563, "loss": 1.8188323974609375, "mae": 5.636701583862305, "mean_q": 10.46776008605957, "_runtime": 34.91945672035217, "_timestamp": 1582186216.2231286, "_step": 278}
{"step": 3450, "episode": 280, "duration": 0.3699982999999989, "episode_steps": 55, "sps": 148.6493316320647, "episode_reward": 55.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4727272727272727, "action_min": 0, "action_max": 1, "obs_mean": -0.12461368016223713, "obs_min": -0.8372315168485136, "obs_max": 0.47948836079845725, "loss": 1.4226081371307373, "mae": 5.606716156005859, "mean_q": 10.472749710083008, "_runtime": 35.31005096435547, "_timestamp": 1582186216.6137228, "_step": 279}
{"step": 3485, "episode": 281, "duration": 0.24227680000000618, "episode_steps": 35, "sps": 144.462862312855, "episode_reward": 35.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.45714285714285713, "action_min": 0, "action_max": 1, "obs_mean": -0.12436742474676744, "obs_min": -0.8039621480571356, "obs_max": 0.2476884038421599, "loss": 1.6074634790420532, "mae": 5.750816345214844, "mean_q": 10.76988697052002, "_runtime": 35.56003546714783, "_timestamp": 1582186216.8637073, "_step": 280}
{"step": 3645, "episode": 282, "duration": 1.0872715, "episode_steps": 160, "sps": 147.15735674116354, "episode_reward": 160.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4875, "action_min": 0, "action_max": 1, "obs_mean": -0.03298028842465129, "obs_min": -0.7350619304686705, "obs_max": 0.5313971903698782, "loss": 1.7809956073760986, "mae": 5.853346347808838, "mean_q": 10.922612190246582, "_runtime": 36.6693320274353, "_timestamp": 1582186217.9730039, "_step": 281}
{"step": 3699, "episode": 283, "duration": 0.3094324000000057, "episode_steps": 54, "sps": 174.51307620016198, "episode_reward": 54.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46296296296296297, "action_min": 0, "action_max": 1, "obs_mean": -0.13444173022995112, "obs_min": -0.7800776339099043, "obs_max": 0.34173845995236685, "loss": 1.8179352283477783, "mae": 5.90737247467041, "mean_q": 10.976898193359375, "_runtime": 36.98182654380798, "_timestamp": 1582186218.2854984, "_step": 282}
{"step": 3818, "episode": 284, "duration": 0.7536117000000004, "episode_steps": 119, "sps": 157.90625331321147, "episode_reward": 119.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.48739495798319327, "action_min": 0, "action_max": 1, "obs_mean": -0.07837116604858028, "obs_min": -0.7355470106914122, "obs_max": 0.5338114084029858, "loss": 1.8541988134384155, "mae": 6.012404441833496, "mean_q": 11.216642379760742, "_runtime": 37.76302623748779, "_timestamp": 1582186219.066698, "_step": 283}
{"step": 3877, "episode": 285, "duration": 0.3905602999999971, "episode_steps": 59, "sps": 151.0650212015928, "episode_reward": 59.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4576271186440678, "action_min": 0, "action_max": 1, "obs_mean": -0.13462260057242229, "obs_min": -0.8837410274032509, "obs_max": 0.49197188019890026, "loss": 1.8128366470336914, "mae": 6.1438069343566895, "mean_q": 11.49869155883789, "_runtime": 38.169262409210205, "_timestamp": 1582186219.4729342, "_step": 284}
{"step": 3959, "episode": 286, "duration": 0.6585131000000004, "episode_steps": 82, "sps": 124.52295937620671, "episode_reward": 82.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.47560975609756095, "action_min": 0, "action_max": 1, "obs_mean": -0.0985881982916561, "obs_min": -0.7754042305398949, "obs_max": 0.4818260830368501, "loss": 1.7751039266586304, "mae": 6.2473225593566895, "mean_q": 11.721295356750488, "_runtime": 38.841076612472534, "_timestamp": 1582186220.1447484, "_step": 285}
{"step": 4036, "episode": 287, "duration": 0.6672417999999993, "episode_steps": 77, "sps": 115.40044403692946, "episode_reward": 77.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4675324675324675, "action_min": 0, "action_max": 1, "obs_mean": -0.1132753949002678, "obs_min": -0.9578885106357131, "obs_max": 0.5431362314512209, "loss": 1.9868565797805786, "mae": 6.261960983276367, "mean_q": 11.665596961975098, "_runtime": 39.528528451919556, "_timestamp": 1582186220.8322003, "_step": 286}
{"step": 4105, "episode": 288, "duration": 0.5341994999999997, "episode_steps": 69, "sps": 129.16522759755492, "episode_reward": 69.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5217391304347826, "action_min": 0, "action_max": 1, "obs_mean": 0.06489588663155475, "obs_min": -0.5570974565866186, "obs_max": 0.6409259406672063, "loss": 1.6298869848251343, "mae": 6.490444183349609, "mean_q": 12.227288246154785, "_runtime": 40.07538056373596, "_timestamp": 1582186221.3790524, "_step": 287}
{"step": 4140, "episode": 289, "duration": 0.2933608000000021, "episode_steps": 35, "sps": 119.30701034357607, "episode_reward": 35.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5428571428571428, "action_min": 0, "action_max": 1, "obs_mean": 0.13361060493800916, "obs_min": -0.36313613196898786, "obs_max": 0.8467542187809554, "loss": 2.3719632625579834, "mae": 6.63280725479126, "mean_q": 12.366050720214844, "_runtime": 40.38782453536987, "_timestamp": 1582186221.6914964, "_step": 288}
{"step": 4201, "episode": 290, "duration": 0.45187930000000165, "episode_steps": 61, "sps": 134.99179980140664, "episode_reward": 61.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5245901639344263, "action_min": 0, "action_max": 1, "obs_mean": 0.09991570744830743, "obs_min": -0.4166578713352921, "obs_max": 0.6771867076634533, "loss": 1.9884307384490967, "mae": 6.582776069641113, "mean_q": 12.301243782043457, "_runtime": 40.85655188560486, "_timestamp": 1582186222.1602237, "_step": 289}
{"step": 4279, "episode": 291, "duration": 0.5472583000000029, "episode_steps": 78, "sps": 142.52867430242645, "episode_reward": 78.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5128205128205128, "action_min": 0, "action_max": 1, "obs_mean": 0.22079975644722963, "obs_min": -0.5685615663268119, "obs_max": 1.4972263564781048, "loss": 2.2946879863739014, "mae": 6.645878791809082, "mean_q": 12.356162071228027, "_runtime": 41.41900300979614, "_timestamp": 1582186222.7226748, "_step": 290}
{"step": 4348, "episode": 292, "duration": 0.4622102999999953, "episode_steps": 69, "sps": 149.28269664263368, "episode_reward": 69.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.463768115942029, "action_min": 0, "action_max": 1, "obs_mean": -0.15026376254637466, "obs_min": -0.9334691476318151, "obs_max": 0.266778211055545, "loss": 2.1597352027893066, "mae": 6.691596984863281, "mean_q": 12.496191024780273, "_runtime": 41.90335249900818, "_timestamp": 1582186223.2070243, "_step": 291}
{"step": 4394, "episode": 293, "duration": 0.28104600000000346, "episode_steps": 46, "sps": 163.6742739622675, "episode_reward": 46.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5217391304347826, "action_min": 0, "action_max": 1, "obs_mean": 0.1115030060277107, "obs_min": -0.36008701893289363, "obs_max": 0.7904783271840499, "loss": 1.9583914279937744, "mae": 6.780541896820068, "mean_q": 12.69942855834961, "_runtime": 42.20021414756775, "_timestamp": 1582186223.503886, "_step": 292}
{"step": 4436, "episode": 294, "duration": 0.33544570000000107, "episode_steps": 42, "sps": 125.20655354950105, "episode_reward": 42.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5476190476190477, "action_min": 0, "action_max": 1, "obs_mean": 0.13184860197307316, "obs_min": -0.34560718691994136, "obs_max": 0.7923911128499102, "loss": 2.098531723022461, "mae": 6.954819679260254, "mean_q": 13.007010459899902, "_runtime": 42.54392719268799, "_timestamp": 1582186223.847599, "_step": 293}
{"step": 4483, "episode": 295, "duration": 0.3359359999999967, "episode_steps": 47, "sps": 139.9076014478962, "episode_reward": 47.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46808510638297873, "action_min": 0, "action_max": 1, "obs_mean": -0.15329954588043815, "obs_min": -0.783938629371365, "obs_max": 0.2054864447351179, "loss": 2.0578184127807617, "mae": 6.783680438995361, "mean_q": 12.666909217834473, "_runtime": 42.90331053733826, "_timestamp": 1582186224.2069824, "_step": 294}
{"step": 4535, "episode": 296, "duration": 0.3619660999999965, "episode_steps": 52, "sps": 143.65986206995765, "episode_reward": 52.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.46153846153846156, "action_min": 0, "action_max": 1, "obs_mean": -0.14068460811996986, "obs_min": -0.7450457102901102, "obs_max": 0.19037181369895512, "loss": 2.136888027191162, "mae": 6.945174694061279, "mean_q": 13.013270378112793, "_runtime": 43.27826809883118, "_timestamp": 1582186224.58194, "_step": 295}
{"step": 4624, "episode": 297, "duration": 0.6071945999999997, "episode_steps": 89, "sps": 146.57574359192267, "episode_reward": 89.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5056179775280899, "action_min": 0, "action_max": 1, "obs_mean": 0.09388670191810004, "obs_min": -0.5476791098818674, "obs_max": 0.8327461382237178, "loss": 2.087541103363037, "mae": 7.023202419281006, "mean_q": 13.179204940795898, "_runtime": 43.90321207046509, "_timestamp": 1582186225.206884, "_step": 296}
{"step": 4672, "episode": 298, "duration": 0.3784581999999972, "episode_steps": 48, "sps": 126.83038708105771, "episode_reward": 48.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5416666666666666, "action_min": 0, "action_max": 1, "obs_mean": 0.15340111825016298, "obs_min": -0.35037416478434, "obs_max": 0.9573445550092385, "loss": 2.3709280490875244, "mae": 7.212306976318359, "mean_q": 13.517341613769531, "_runtime": 44.29380393028259, "_timestamp": 1582186225.5974758, "_step": 297}
{"step": 4731, "episode": 299, "duration": 0.4356591000000023, "episode_steps": 59, "sps": 135.4269886707283, "episode_reward": 59.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.4576271186440678, "action_min": 0, "action_max": 1, "obs_mean": -0.08511131783310424, "obs_min": -0.8738437920015588, "obs_max": 0.42440347535550577, "loss": 1.988411545753479, "mae": 7.119731903076172, "mean_q": 13.399466514587402, "_runtime": 44.74690818786621, "_timestamp": 1582186226.05058, "_step": 298}
{"step": 4868, "episode": 300, "duration": 0.9865385000000018, "episode_steps": 137, "sps": 138.86939029748942, "episode_reward": 137.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.5182481751824818, "action_min": 0, "action_max": 1, "obs_mean": 0.06784344498603123, "obs_min": -0.4326549377067293, "obs_max": 0.9484316042117553, "loss": 2.13999605178833, "mae": 7.398347854614258, "mean_q": 13.91569709777832, "_runtime": 45.74682927131653, "_timestamp": 1582186227.050501, "_step": 299}
{"step": 4936, "episode": 301, "duration": 0.4936216999999985, "episode_steps": 68, "sps": 137.75731496407107, "episode_reward": 68.0, "reward_mean": 1.0, "reward_min": 1.0, "reward_max": 1.0, "action_mean": 0.45588235294117646, "action_min": 0, "action_max": 1, "obs_mean": -0.1367336138088723, "obs_min": -1.0407559105291988, "obs_max": 0.43856977422672966, "loss": 2.2060420513153076, "mae": 7.571995258331299, "mean_q": 14.244810104370117, "_runtime": 46.24680423736572, "_timestamp": 1582186227.550476, "_step": 300}
