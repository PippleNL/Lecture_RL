wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.8.27
    framework: keras
    is_jupyter_run: false
    python_version: 3.7.6
agent:
  desc: null
  value:
    _DQNAgent__policy: <rl.policy.EpsGreedyQPolicy object at 0x0000028948BB9A08>
    _DQNAgent__test_policy: <rl.policy.GreedyQPolicy object at 0x0000028948BDDB48>
    batch_size: 32
    compiled: true
    custom_model_objects: {}
    delta_clip: .inf
    dueling_type: avg
    enable_double_dqn: false
    enable_dueling_network: false
    gamma: 0.99
    memory: <rl.memory.SequentialMemory object at 0x0000028948BD5288>
    memory_interval: 1
    model: <keras.engine.sequential.Sequential object at 0x0000028948B163C8>
    nb_actions: 2
    nb_steps_warmup: 10
    processor: null
    recent_action: null
    recent_observation: null
    step: 0
    target_model: <keras.engine.sequential.Sequential object at 0x0000028948BE6748>
    target_model_update: 0.01
    train_interval: 1
    trainable_model: <keras.engine.training.Model object at 0x0000028949D107C8>
    training: true
env:
  desc: null
  value:
    _elapsed_steps: null
    _max_episode_steps: 200
    action_space: Discrete(2)
    env: <CartPoleEnv<CartPole-v0>>
    metadata:
      render.modes:
      - human
      - rgb_array
      video.frames_per_second: 50
    observation_space: Box(4,)
    reward_range:
    - -.inf
    - .inf
env.env:
  desc: null
  value:
    action_space: Discrete(2)
    force_mag: 10.0
    gravity: 9.8
    kinematics_integrator: euler
    length: 0.5
    masscart: 1.0
    masspole: 0.1
    np_random: RandomState(MT19937)
    observation_space: Box(4,)
    polemass_length: 0.05
    spec: EnvSpec(CartPole-v0)
    state: null
    steps_beyond_done: null
    tau: 0.02
    theta_threshold_radians: 0.20943951023931953
    total_mass: 1.1
    viewer: null
    x_threshold: 2.4
env.env.spec:
  desc: null
  value:
    _env_name: CartPole
    _kwargs: {}
    entry_point: gym.envs.classic_control:CartPoleEnv
    id: CartPole-v0
    max_episode_steps: 200
    nondeterministic: false
    reward_threshold: 195.0
params:
  desc: null
  value:
    nb_steps: 5000
